{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating alternative skipped exon experiments\n",
    "\n",
    "\n",
    "### Simulation model\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, each file is a different RBP motif as a position frequency matrix.  So, the first step is to compile all of these files into a suitable database.  In particular, we can parse each motifs (position frequency matrix) from each file in motifpath (downloaded top10align_motifs folder), create a database (list of arrays), and save as binary format (motif.list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a motif database for drosophila melanogaster\n",
    "\n",
    "The data comes from Ray et al. \"A compendium of RNA-binding motifs for decoding gene regulation\" (http://www.nature.com/nature/journal/v499/n7457/abs/nature12311.html). The link to the motifs I downloaded is here: \n",
    "\n",
    "\\$ wget http://hugheslab.ccbr.utoronto.ca/supplementary-data/RNAcompete_eukarya/top10align_motifs.tar.gz\n",
    "\n",
    "\\$ tar xzvf top10align_motifs.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load motifs\n",
    "motiflist = 'motif.pickle'  \n",
    "if os.path.isfile(motiflist):\n",
    "\n",
    "    # load motif list from file\n",
    "    f = open(motiflist, 'rb')\n",
    "    motif_set = cPickle.load(f)\n",
    "    f.close()\n",
    "\n",
    "else:\n",
    "    # download motifs\n",
    "    motifpath = 'top10align_motifs/'   # directory where motif files are located\n",
    "\n",
    "    # get all motif files in motifpath directory\n",
    "    listdir = os.listdir(motifpath)\n",
    "\n",
    "    # parse motifs\n",
    "    motif_set = []\n",
    "    for files in listdir:\n",
    "        df = pd.read_table(os.path.join(motifpath,files))\n",
    "        motif_set.append(df.iloc[0::,1::].transpose())\n",
    "\n",
    "    # save motifs    \n",
    "    f = open(motiflist, 'wb')\n",
    "    cPickle.dump(motif_set, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation procedure\n",
    "\n",
    "### Setup motif model for each alternative exon event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup motif code \n",
    "max_motifs_exon = 7\n",
    "num_models = 10      # number of regulatory grammars\n",
    "distance_rate = 10\n",
    "interaction_rate = 10\n",
    "distance_offset = 3\n",
    "motif_range = [0, 40]\n",
    "exon_size = 100\n",
    "intron_size = 150\n",
    "region_size = np.array([exon_size, intron_size, \n",
    "                 intron_size, exon_size, \n",
    "                 exon_size, intron_size, \n",
    "                 intron_size, exon_size])\n",
    "\n",
    "motif_model = []\n",
    "for i in range(num_models):\n",
    "    exon_model = []\n",
    "    for k in range(8):\n",
    "        status = True\n",
    "        while status:\n",
    "            # simulate number of motifs for each region\n",
    "            num_motifs = np.ceil(np.random.randint(1, max_motifs_exon)).astype(int)\n",
    "\n",
    "            # simulate position offset from border\n",
    "            start_offset = np.ceil(np.random.exponential(scale=distance_rate)).astype(int) + distance_offset\n",
    "\n",
    "            # exponential separation rate between motifs\n",
    "            distance_scale = (region_size[k]-start_offset)/num_motifs/10\n",
    "\n",
    "            # simulate distance between motifs \n",
    "            separation = np.ceil(np.random.exponential(scale=interaction_rate, size=num_motifs)) + distance_offset\n",
    "\n",
    "            # randomly select motifs from top10align\n",
    "            motif_index = np.random.randint(motif_range[0], motif_range[1], size=num_motifs)\n",
    "\n",
    "            # build position weight matrix model\n",
    "            if (k%2) == 0:\n",
    "                reverse = True\n",
    "            else:\n",
    "                reverse = False\n",
    "                \n",
    "            pwm = np.ones((4, start_offset))/4\n",
    "            for j in range(num_motifs):\n",
    "                if reverse:\n",
    "                    pwm = np.hstack([np.ones((4,separation[j]))/4, motif_set[motif_index[j]], pwm])\n",
    "                else:\n",
    "                    pwm = np.hstack([pwm, motif_set[motif_index[j]], np.ones((4,separation[j]))/4])\n",
    "            remainder = region_size[k]-pwm.shape[1]\n",
    "            if remainder > 0:\n",
    "                if reverse:\n",
    "                    pwm = np.hstack((np.ones((4,remainder))/4, pwm))\n",
    "                else:\n",
    "                    pwm = np.hstack((pwm, np.ones((4,remainder))/4))\n",
    "                status = False\n",
    "\n",
    "        model = {'pwm': pwm,\n",
    "                 'num_motifs': num_motifs, \n",
    "                 'start_offset': start_offset, \n",
    "                 'distance_scale': distance_scale, \n",
    "                 'separation': separation, \n",
    "                 'motif_index': motif_index}\n",
    "        exon_model.append(model)\n",
    "    motif_model.append(exon_model)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create gene expression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup cell type gene expression profiles\n",
    "num_cell_types = 200\n",
    "num_genes = 5000\n",
    "\n",
    "# random gene states\n",
    "on_state = 4\n",
    "on_std = 1.5\n",
    "off_state = 0\n",
    "off_std = 1\n",
    "pop_frac = .85\n",
    "\n",
    "gene_expression_model = []\n",
    "for i in range(num_cell_types):\n",
    "    gene_state = np.random.binomial(1, pop_frac, num_genes)\n",
    "\n",
    "    on_index = np.where(gene_state==1)[0]\n",
    "    off_index = np.where(gene_state==0)[0]\n",
    "    num_on = len(on_index)\n",
    "    num_off = len(off_index)\n",
    "    \n",
    "    Z_off = np.random.normal(off_state, off_std, num_off)\n",
    "    Z_on = np.random.normal(on_state, on_std, num_on)\n",
    "\n",
    "    Z = np.zeros((num_genes))\n",
    "    Z[on_index] = Z_on\n",
    "    Z[off_index] = Z_off\n",
    "\n",
    "    model = {'gene_expression': Z,\n",
    "             'gene_state': gene_state,\n",
    "             'on_index': on_index,\n",
    "             'off_index': off_index,\n",
    "             'num_off': num_off,\n",
    "             'num_on': num_on\n",
    "             }\n",
    "    gene_expression_model.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup interaction model\n",
    "\n",
    "Get a list of unique motifs within alternative exon model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get list of unique motifs\n",
    "motif_index = []\n",
    "for exon_model in motif_model:\n",
    "    for model in exon_model:\n",
    "        motif_index.append(model['motif_index'])\n",
    "        \n",
    "motifs = np.hstack(motif_index)\n",
    "unique_motifs = np.unique(motifs)\n",
    "num_unique = len(unique_motifs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count number of motifs for each exon model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get motif count for each exon model\n",
    "motif_count = np.zeros((num_models, num_unique))\n",
    "for i in range(num_models):\n",
    "    exon_model = motif_model[i]\n",
    "    for model in exon_model:\n",
    "        motif_count[i, unique_motifs[model['motif_index']]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate each RBP's with multiple motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup rbp interaction code - associate rbps to multiple motifs\n",
    "num_rbp = 100\n",
    "interaction_rate = 6\n",
    "rbp_code = []\n",
    "for i in range(num_rbp):\n",
    "    num_interactions = min(np.ceil(np.random.exponential(interaction_rate)).astype(int), num_unique)\n",
    "    rbp_interaction = np.random.permutation(range(num_unique))[:num_interactions]\n",
    "    interaction_state = np.random.randint(0,2,num_interactions)\n",
    "    model = {'rbp_interaction': rbp_interaction,\n",
    "             'num_interactions': num_interactions,\n",
    "             'interaction_state': interaction_state,\n",
    "             }\n",
    "    rbp_code.append(model)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reverse of the previous step: get a catalogue of each RBP interaction for each motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get catalogue of rbp interactions with each motif\n",
    "motif_interactions = []\n",
    "for motif in unique_motifs:\n",
    "    \n",
    "    # loop through each rbp to see if it regulates the motif\n",
    "    rbp_players = []\n",
    "    for i in range(num_rbp):\n",
    "        code = rbp_code[i]\n",
    "        rbp_interaction = code['rbp_interaction'] # <-- list of motifs that rbp interacts with\n",
    "        match_index = np.where(motif == rbp_interaction)[0] # <-- find which rbp regulate current motif\n",
    "\n",
    "        if len(match_index) > 0: \n",
    "            # rbp interaction type (enhancer or silencer)\n",
    "            interaction_type = code['interaction_state'][match_index] \n",
    "            rbp_players.append([i, interaction_type])\n",
    "    motif_interactions.append(np.array(rbp_players))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine percentage spliced in based on gene expression levels of RBP, which motifs are present, and the state that the RBP works on the given motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# figure out psi for each motif_model based on gene_expression of each rbp and their effect on state\n",
    "psi = np.zeros((num_cell_types, num_models))\n",
    "for i in range(num_cell_types):\n",
    "    gene_expression = gene_expression_model[i]['gene_expression']\n",
    "\n",
    "    for j in range(num_models):\n",
    "        motifs = unique_motifs[motif_count[j] > 1]\n",
    "        count = motif_count[j][motif_count[j] > 1]\n",
    "\n",
    "        rbp = []\n",
    "        state = []\n",
    "        for motif in motifs:\n",
    "            rbp.append(motif_interactions[motif][:,0])\n",
    "            state.append(motif_interactions[motif][:,1])\n",
    "\n",
    "        rbp = np.hstack(rbp)\n",
    "        state = np.hstack(state)\n",
    "        tpm = np.exp(gene_expression[rbp])\n",
    "        tpm /= sum(tpm)\n",
    "        psi[i,j] =sum(tpm*state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the position weight matrices into a realized simulated sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simulate_sequences(pwm, num_sequenes):\n",
    "    cum_pwm = pwm.cumsum(axis=0)\n",
    "    sequence = []\n",
    "    for i in range(num_sequences):\n",
    "        Z = np.random.uniform(0, 1, cum_pwm.shape[1])\n",
    "        sequence.append(np.argmin((cum_pwm - Z)**2, axis=0))\n",
    "    return sequence\n",
    "\n",
    "def simulate_skipped_exon_sequences(exon_model, num_sequences):\n",
    "    pwm_up_exon = np.hstack([exon_model[0]['pwm'], exon_model[1]['pwm']])\n",
    "    pwm_ae_exon_1 = np.hstack([exon_model[1]['pwm'], exon_model[2]['pwm']])\n",
    "    pwm_ae_exon_2 = np.hstack([exon_model[2]['pwm'], exon_model[3]['pwm']])\n",
    "    pwm_down_exon = np.hstack([exon_model[3]['pwm'], exon_model[4]['pwm']])\n",
    "\n",
    "    up_exon_seq = simulate_sequences(pwm_up_exon, num_sequenes)\n",
    "    ae_exon_seq_1 = simulate_sequences(pwm_ae_exon_1, num_sequenes)\n",
    "    ae_exon_seq_2 = simulate_sequences(pwm_ae_exon_2, num_sequenes)\n",
    "    down_exon_seq = simulate_sequences(pwm_down_exon, num_sequenes)\n",
    "\n",
    "    return up_exon_seq, ae_exon_seq_1, ae_exon_seq_2, down_exon_seq\n",
    "\n",
    "up_exon_seq, ae_exon_seq_1, ae_exon_seq_2, down_exon_seq = \n",
    "                    simulate_skipped_exon_sequences(exon_model, num_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Split data and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_one_hot(seq):\n",
    "    \"\"\"convert a sequence into a 1-hot representation\"\"\"\n",
    "    \n",
    "    nucleotide = 'ACGU'\n",
    "    N = len(seq)\n",
    "    one_hot_seq = np.zeros((4,N))\n",
    "    for i in xrange(200):         \n",
    "        #for j in range(4):\n",
    "        #    if seq[i] == nucleotide[j]:\n",
    "        #        one_hot_seq[j,i] = 1\n",
    "        index = [j for j in xrange(4) if seq[i] == nucleotide[j]]\n",
    "        one_hot_seq[index,i] = 1\n",
    "        \n",
    "    return one_hot_seq\n",
    "\n",
    "\n",
    "def subset_data(data, label, sub_index):\n",
    "    \"\"\"returns a subset of the data and labels based on sub_index\"\"\"\n",
    "    \n",
    "    num_labels = len(np.unique(label))\n",
    "    num_sub = len(sub_index)\n",
    "    \n",
    "    sub_set = np.zeros((num_sub, 4, len(data[0])))\n",
    "    sub_set_label = np.zeros((num_sub, num_labels))\n",
    "    \n",
    "    k = 0;\n",
    "    for index in sub_index:\n",
    "        sub_set[k] = convert_one_hot(data[index])\n",
    "        sub_set_label[k,label[index]] = 1\n",
    "        k += 1\n",
    "\n",
    "    sub_set_label = sub_set_label.astype(np.uint8)\n",
    "    \n",
    "    return (sub_set, sub_set_label)\n",
    "\n",
    "def split_data(data, label, split_size):\n",
    "    \"\"\"split data into train set, cross-validation set, and test set\"\"\"\n",
    "    \n",
    "    # number of labels\n",
    "    num_labels = len(np.unique(label))\n",
    "\n",
    "    # determine indices of each dataset\n",
    "    N = len(data)\n",
    "    cum_index = np.cumsum(np.multiply([0, split_size[0], split_size[1], split_size[2]],N)).astype(int) \n",
    "\n",
    "    # shuffle data\n",
    "    shuffle = np.random.permutation(N)\n",
    "\n",
    "    # training dataset\n",
    "    train_index = shuffle[range(cum_index[0], cum_index[1])]\n",
    "    cross_validation_index = shuffle[range(cum_index[1], cum_index[2])]\n",
    "    test_index = shuffle[range(cum_index[2], cum_index[3])]\n",
    "\n",
    "    # create subsets of data based on indices \n",
    "    train = subset_data(data, label, train_index)\n",
    "    cross_validation = subset_data(data, label, cross_validation_index)\n",
    "    test = subset_data(data, label, test_index)\n",
    "    \n",
    "    return train, cross_validation, test\n",
    "\n",
    "# percentage for each dataset\n",
    "train_size = 0.7\n",
    "cross_validation_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "\n",
    "# get indices for each dataset\n",
    "print \"Splitting dataset into train, cross-validation, and test\"\n",
    "split_size = [train_size, cross_validation_size, test_size]\n",
    "train, cross_validation, test = split_data(data, label, split_size)\n",
    "\n",
    "# save training dataset in one-hot representation\n",
    "print \"Saving dataset\"\n",
    "f = open(filename+'_data.pickle', 'wb')\n",
    "cPickle.dump(train, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "cPickle.dump(cross_validation, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "cPickle.dump(test, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n",
    "\n",
    "# save training dataset in one-hot representation\n",
    "print \"Saving model\"\n",
    "f = open(filename+'_model.pickle', 'wb')\n",
    "cPickle.dump(options, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "cPickle.dump(model, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "cPickle.dump(seq_model, f, protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we are ready to build and test our deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# load training data\n",
    "filename = 'train_data_10000_200_10_20.pickle'\n",
    "f = open(filename, 'rb')\n",
    "train = cPickle.load(f)\n",
    "cross_validation = cPickle.load(f)\n",
    "test = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# separate data\n",
    "train_set, train_set_label = train\n",
    "cross_validation_set, cross_validation_set_label = cross_validation\n",
    "test_set, test_set_label = test\n",
    "\n",
    "# munge data for deep learning\n",
    "train_set = munge_data(train_set)\n",
    "cross_validation_set = munge_data(cross_validation_set)\n",
    "test_set = munge_data(test_set)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "outdir = 'data'\n",
    "if not os.path.isdir(outdir):\n",
    "    os.mkdir(outdir)\n",
    "    print \"making directory: \" + outdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle\n",
    "\n",
    "# load motif list from file\n",
    "filename = 'model_10000_200_10_20.pickle'\n",
    "f = open(filename, 'rb')\n",
    "model = cPickle.load(f)\n",
    "options = cPickle.load(f)\n",
    "seq_model = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# options = [motif_set, M, G, interaction_rate, distance_scale, offset, maxMotif]\n",
    "# model [motifs, grammar, distance]\n",
    "# seq_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
