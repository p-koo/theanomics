{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import os, sys, urllib, gzip, matplotlib\n",
    "sys.setrecursionlimit(10000)\n",
    "%matplotlib inline\n",
    "matplotlib.use('Agg') # Change matplotlib backend, in case we have no X server running..\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Image as IPImage\n",
    "from PIL import Image\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "from lasagne import layers\n",
    "from lasagne.layers import get_output, get_output_shape, get_all_layers, get_all_params\n",
    "from lasagne.layers import get_all_param_values, set_all_param_values\n",
    "from lasagne import nonlinearities\n",
    "from lasagne import updates \n",
    "from lasagne import objectives \n",
    "from lasagne import init \n",
    "import theano.tensor as T\n",
    "import theano\n",
    "\n",
    "sys.path.append('..')\n",
    "from src import NeuralNet\n",
    "from src import train as fit\n",
    "from src import make_directory \n",
    "from models import load_model\n",
    "from data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from: /home/peter/Data/SequenceMotif/N=100000_S=200_M=10_G=20_data.pickle\n",
      "loading train data\n",
      "loading cross-validation data\n",
      "loading test data\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "name = 'Basset' # 'DeepSea'\n",
    "datapath = '/home/peter/Data/'+name\n",
    "options = {\"class_range\": range(3)}# \n",
    "train, valid, test = load_data(name, datapath, options)\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = np.round(train[1].shape[1])\n",
    "\n",
    "\"\"\"\n",
    "name = 'MotifSimulation_binary'\n",
    "datapath = '/home/peter/Data/SequenceMotif'\n",
    "filepath = os.path.join(datapath, 'N=100000_S=200_M=10_G=20_data.pickle')\n",
    "train, valid, test = load_data(name, filepath)\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = np.round(train[1].shape[1])\n",
    "#\"\"\"\n",
    "\n",
    "def batch_generator(X, y, N):\n",
    "    while True:\n",
    "        idx = np.random.choice(len(y), N)\n",
    "        yield X[idx].astype('float32'), y[idx].astype('float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "input_var = T.tensor4('input')\n",
    "\n",
    "l_in = layers.InputLayer(shape=shape, input_var=input_var, name='input')\n",
    "l_conv1 = layers.Conv2DLayer(l_in, num_filters=200, filter_size=(8,1), W=init.GlorotUniform(), \n",
    "                             nonlinearity=None, b=None, pad='valid', name='conv1')\n",
    "l_norm1 = layers.BatchNormLayer(l_conv1)\n",
    "l_bias1 = layers.BiasLayer(l_norm1, b=init.Constant(0.05))\n",
    "l_nonlin1 = layers.NonlinearityLayer(l_bias1, nonlinearity=nonlinearities.rectify)\n",
    "l_pool1 = layers.MaxPool2DLayer(l_nonlin1, pool_size=(4,1))\n",
    "\n",
    "l_conv3 = layers.Conv2DLayer(l_pool1, num_filters=200, filter_size=(8,1), W=init.GlorotUniform(), \n",
    "                             nonlinearity=None, b=None, pad='valid', name='conv1')\n",
    "l_norm3 = layers.BatchNormLayer(l_conv3)\n",
    "l_bias3 = layers.BiasLayer(l_norm3, b=init.Constant(0.05))\n",
    "l_nonlin3 = layers.NonlinearityLayer(l_bias3, nonlinearity=nonlinearities.rectify)\n",
    "l_pool3 = layers.MaxPool2DLayer(l_nonlin3, pool_size=(4,1))\n",
    "l_drop3 = layers.DropoutLayer(l_pool3, p=0.3)\n",
    "\n",
    "l_dense3 = layers.DenseLayer(l_drop3, num_units=200, W=init.GlorotUniform(), name='inter')\n",
    "l_norm4 = layers.BatchNormLayer(l_dense3)\n",
    "l_bias3 = layers.BiasLayer(l_norm4, init.Constant(0.05))\n",
    "l_nonlin3 = layers.NonlinearityLayer(l_bias3, nonlinearity=nonlinearities.sigmoid)\n",
    "l_drop4 = layers.DropoutLayer(l_nonlin3, p=0.5)\n",
    "\n",
    "l_dense4 = layers.DenseLayer(l_drop4, num_units=20, W=init.GlorotUniform(), name='inter')\n",
    "l_bias4 = layers.BiasLayer(l_dense4, init.Constant(0.05))\n",
    "l_nonlin4 = layers.NonlinearityLayer(l_bias4, nonlinearity=nonlinearities.sigmoid)\n",
    "\n",
    "l_enc = layers.NonlinearityLayer(l_nonlin4, nonlinearity=None)\n",
    "\n",
    "l_dec5 = layers.InverseLayer(l_enc, l_dense4, name='decode')\n",
    "l_bias5 = layers.BiasLayer(l_dec5, init.Constant(0.05))\n",
    "l_nonlin5 = layers.NonlinearityLayer(l_bias5, nonlinearity=nonlinearities.sigmoid)\n",
    "\n",
    "l_dec6 = layers.InverseLayer(l_nonlin5, l_dense3, name='decode')\n",
    "l_norm6 = layers.BatchNormLayer(l_dec6)\n",
    "l_bias6 = layers.BiasLayer(l_norm6, init.Constant(0.05))\n",
    "l_nonlin6 = layers.NonlinearityLayer(l_bias6, nonlinearity=nonlinearities.sigmoid)\n",
    "\n",
    "l_depool9 = layers.InverseLayer(l_nonlin6, l_pool3, name='depool')\n",
    "l_deconv9 = layers.InverseLayer(l_depool9, l_conv3, name='deconv')\n",
    "l_norm9 = layers.BatchNormLayer(l_deconv9)\n",
    "l_bias9 = layers.BiasLayer(l_norm9, init.Constant(0.05))\n",
    "l_nonlin9 = layers.NonlinearityLayer(l_bias9, nonlinearity=nonlinearities.rectify)\n",
    "                           \n",
    "l_depool8 = layers.InverseLayer(l_nonlin9, l_pool1, name='depool')\n",
    "l_deconv8 = layers.InverseLayer(l_depool8, l_conv1, name='deconv')\n",
    "l_norm8 = layers.BatchNormLayer(l_deconv8)\n",
    "l_bias8 = layers.BiasLayer(l_norm8, init.Constant(0.05))\n",
    "l_out = layers.NonlinearityLayer(l_bias8, nonlinearity=nonlinearities.rectify)\n",
    "\n",
    "\n",
    "prediction = get_output(l_out)\n",
    "train_loss = objectives.squared_error(prediction, input_var)\n",
    "train_loss = train_loss.mean()\n",
    "\n",
    "valid_prediction = get_output(l_out, deterministic=True)\n",
    "valid_loss = objectives.squared_error(valid_prediction, input_var)\n",
    "valid_loss = valid_loss.mean()\n",
    "\n",
    "params = get_all_params(l_out, trainable=True)\n",
    "update_op = updates.adam(train_loss, params)\n",
    "\n",
    "train_function = theano.function([input_var], train_loss, updates=update_op)\n",
    "valid_function = theano.function([input_var], valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.004879\n",
      "train: 0.003433\n",
      "train: 0.002892\n",
      "train: 0.002520\n",
      "train: 0.002515\n",
      "train: 0.002492\n",
      "train: 0.002357\n",
      "train: 0.002450\n",
      "train: 0.002502\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6ec26f23d293>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "num_train_batches = len(train[0]) // batch_size\n",
    "train_batches = batch_generator(train[0], train[1], batch_size)\n",
    "\n",
    "n_epochs = 15\n",
    "for e in range(n_epochs):\n",
    "    for index in range(num_train_batches):\n",
    "        X_batch, y_batch = next(train_batches)\n",
    "        train_loss = train_function(X_batch)\n",
    "    print(\"train: %f\" % train_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = theano.function([input_var], layers.get_output(l_out), allow_input_downcast=True)\n",
    "encode = theano.function([input_var], layers.get_output(l_enc), allow_input_downcast=True)\n",
    "\n",
    "target_var = T.dmatrix('codes')\n",
    "out_expr = layers.get_output(l_out, {l_enc:target_var})\n",
    "fn = theano.function([target_var, l_in.input_var], out_expr, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8265124   0.92895764  0.53943282  0.71296102  0.7897808   0.7608757\n",
      "  0.56352985  0.78462529  0.44714594  0.53536981  0.96264875  0.76974922\n",
      "  0.73713291  0.55756795  0.53973943  0.99704713  0.99407142  0.99282891\n",
      "  0.93909556  0.93308097]\n",
      "Reconstruction with Image = Original Image\n",
      "Full pass through Autoencoder\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f386ef12f10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAAoCAYAAAAbporbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3867470810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAAoCAYAAAAbporbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5T5GFXkVFRWV+xhV5FVUVFTuY/4ffXqz7aJXHxIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3870632950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAAoCAYAAAAbporbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nieQuRhp5iUQiuYv5v9VSs97mGZneAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f386e963690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 2\n",
    "orig_image = np.expand_dims(train[0][index], axis=0) \n",
    "#zero_image=np.random.rand((1,1,28,28))\n",
    "\n",
    "# reconstruction from encoding layer\n",
    "code = encode(orig_image)\n",
    "print(str(np.squeeze(code)))\n",
    "encode_image = fn(code, orig_image)\n",
    "\n",
    "# full pass\n",
    "#full_image = full(orig_image)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(orig_image), cmap='gray')\n",
    "\n",
    "#print(\"Reconstruction with Image = Zeros\")\n",
    "#plt.figure()\n",
    "#plt.imshow(np.squeeze(fn(code,zero_image)), cmap='gray')\n",
    "\n",
    "print(\"Reconstruction with Image = Original Image\")\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(encode_image), cmap='gray')\n",
    "\n",
    "print(\"Full pass through Autoencoder\")\n",
    "plt.figure()\n",
    "plt.imshow(np.squeeze(full(orig_image)), cmap='gray')\n",
    "\n",
    "#plt.figure()\n",
    "#plt.imshow(np.squeeze(full_image), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_params = get_all_param_values(l_nonlin4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = T.tensor4('input')\n",
    "target_var = T.dmatrix('output')\n",
    "\n",
    "net = []\n",
    "net = layers.InputLayer(shape=shape, input_var=input_var, name='input')\n",
    "net = layers.Conv2DLayer(net, num_filters=200, filter_size=(8,1), W=init.GlorotUniform(), \n",
    "                             nonlinearity=None, b=None, pad='valid', name='conv1')\n",
    "net = layers.BatchNormLayer(net)\n",
    "net = layers.BiasLayer(net, b=init.Constant(0.05))\n",
    "net = layers.NonlinearityLayer(net, nonlinearity=nonlinearities.rectify)\n",
    "net = layers.MaxPool2DLayer(net, pool_size=(4,1))\n",
    "\n",
    "net = layers.Conv2DLayer(net, num_filters=200, filter_size=(8,1), W=init.GlorotUniform(), \n",
    "                             nonlinearity=None, b=None, pad='valid', name='conv1')\n",
    "net = layers.BatchNormLayer(net)\n",
    "net = layers.BiasLayer(net, b=init.Constant(0.05))\n",
    "net = layers.NonlinearityLayer(net, nonlinearity=nonlinearities.rectify)\n",
    "net = layers.MaxPool2DLayer(net, pool_size=(4,1))\n",
    "#net = layers.DropoutLayer(net, p=0.3)\n",
    "\n",
    "net = layers.DenseLayer(net, num_units=200, W=init.GlorotUniform(), name='inter')\n",
    "net = layers.BatchNormLayer(net)\n",
    "net = layers.BiasLayer(net, init.Constant(0.05))\n",
    "net = layers.NonlinearityLayer(net, nonlinearity=nonlinearities.sigmoid)\n",
    "#net = layers.DropoutLayer(net, p=0.5)\n",
    "\n",
    "net = layers.DenseLayer(net, num_units=20, W=init.GlorotUniform(), name='inter')\n",
    "net = layers.BiasLayer(net, init.Constant(0.05))\n",
    "net = layers.NonlinearityLayer(net, nonlinearity=nonlinearities.sigmoid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_all_param_values(net, all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = get_output(net)\n",
    "train_loss = objectives.binary_crossentropy(prediction, target_var)\n",
    "train_loss = train_loss.mean()\n",
    "\n",
    "valid_prediction = get_output(net, deterministic=True)\n",
    "valid_loss = objectives.binary_crossentropy(valid_prediction, target_var)\n",
    "valid_loss = valid_loss.mean()\n",
    "\n",
    "valid_acc = objectives.binary_accuracy(valid_prediction, target_var)\n",
    "valid_acc = valid_acc.mean()\n",
    "\n",
    "params = get_all_params(net, trainable=True)\n",
    "update_op = updates.adam(train_loss, params)\n",
    "\n",
    "train_fn = theano.function([input_var, target_var], train_loss, updates=update_op, allow_input_downcast=True)\n",
    "val_fn = theano.function([input_var, target_var], [valid_loss, valid_acc], allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.640928\n",
      "valid: 0.517883\n",
      "accuracy: 0.954063\n",
      "train: 0.449153\n",
      "valid: 0.390563\n",
      "accuracy: 0.954010\n",
      "train: 0.343769\n",
      "valid: 0.305715\n",
      "accuracy: 0.957979\n",
      "train: 0.277016\n",
      "valid: 0.254072\n",
      "accuracy: 0.958330\n",
      "train: 0.234525\n",
      "valid: 0.218843\n",
      "accuracy: 0.959589\n",
      "train: 0.205561\n",
      "valid: 0.196030\n",
      "accuracy: 0.960116\n",
      "train: 0.187256\n",
      "valid: 0.182145\n",
      "accuracy: 0.959959\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1436d2569fbd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mave_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mave_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "num_train_batches = len(train[0]) // batch_size\n",
    "train_batches = batch_generator(train[0], train[1], batch_size)\n",
    "\n",
    "num_valid_batches = len(valid[0]) // batch_size\n",
    "valid_batches = batch_generator(valid[0], valid[1], batch_size)\n",
    "\n",
    "n_epochs = 10\n",
    "for e in range(n_epochs):\n",
    "    ave_loss = 0\n",
    "    for index in range(num_train_batches):\n",
    "        X_batch, y_batch = next(train_batches)\n",
    "        train_loss = train_fn(X_batch, y_batch)\n",
    "        ave_loss += train_loss\n",
    "    print(\"train: %f\" % float(ave_loss/num_train_batches))\n",
    "\n",
    "    ave_loss = 0\n",
    "    ave_acc = 0\n",
    "    for index in range(num_valid_batches):\n",
    "        X_batch, y_batch = next(valid_batches)\n",
    "        valid_loss, valid_acc = val_fn(X_batch, y_batch)\n",
    "        ave_loss += valid_loss\n",
    "        ave_acc += valid_acc\n",
    "    print(\"valid: %f\" % float(ave_loss/num_valid_batches))\n",
    "    print(\"accuracy: %f\" % float(ave_acc/num_valid_batches))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 0.603613\n",
      "valid: 0.506383\n",
      "accuracy: 0.957385\n",
      "train: 0.437341\n",
      "valid: 0.378542\n",
      "accuracy: 0.957225\n",
      "train: 0.335457\n",
      "valid: 0.299383\n",
      "accuracy: 0.957348\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b0abe48dbf59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mave_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train: %f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mave_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_var = T.tensor4('input')\n",
    "target_var = T.dmatrix('output')\n",
    "\n",
    "net = []\n",
    "net = layers.InputLayer(shape=shape, input_var=input_var, name='input')\n",
    "net = layers.Conv2DLayer(net, num_filters=200, filter_size=(8,1), W=init.GlorotUniform(), \n",
    "                             nonlinearity=None, b=None, pad='valid', name='conv1')\n",
    "net = layers.BatchNormLayer(net)\n",
    "net = layers.BiasLayer(net, b=init.Constant(0.05))\n",
    "net = layers.NonlinearityLayer(net, nonlinearity=nonlinearities.rectify)\n",
    "net = layers.MaxPool2DLayer(net, pool_size=(4,1))\n",
    "\n",
    "net = layers.Conv2DLayer(net, num_filters=200, filter_size=(8,1), W=init.GlorotUniform(), \n",
    "                             nonlinearity=None, b=None, pad='valid', name='conv1')\n",
    "net = layers.BatchNormLayer(net)\n",
    "net = layers.BiasLayer(net, b=init.Constant(0.05))\n",
    "net = layers.NonlinearityLayer(net, nonlinearity=nonlinearities.rectify)\n",
    "net = layers.MaxPool2DLayer(net, pool_size=(4,1))\n",
    "#net = layers.DropoutLayer(net, p=0.3)\n",
    "\n",
    "net = layers.DenseLayer(net, num_units=200, W=init.GlorotUniform(), name='inter')\n",
    "net = layers.BatchNormLayer(net)\n",
    "net = layers.BiasLayer(net, init.Constant(0.05))\n",
    "net = layers.NonlinearityLayer(net, nonlinearity=nonlinearities.sigmoid)\n",
    "#net = layers.DropoutLayer(net, p=0.5)\n",
    "\n",
    "net = layers.DenseLayer(net, num_units=20, W=init.GlorotUniform(), name='inter')\n",
    "net = layers.BiasLayer(net, init.Constant(0.05))\n",
    "net = layers.NonlinearityLayer(net, nonlinearity=nonlinearities.sigmoid)\n",
    "\n",
    "prediction = get_output(net)\n",
    "train_loss = objectives.binary_crossentropy(prediction, target_var)\n",
    "train_loss = train_loss.mean()\n",
    "\n",
    "valid_prediction = get_output(net, deterministic=True)\n",
    "valid_loss = objectives.binary_crossentropy(valid_prediction, target_var)\n",
    "valid_loss = valid_loss.mean()\n",
    "\n",
    "valid_acc = objectives.binary_accuracy(valid_prediction, target_var)\n",
    "valid_acc = valid_acc.mean()\n",
    "\n",
    "params = get_all_params(net, trainable=True)\n",
    "update_op = updates.adam(train_loss, params)\n",
    "\n",
    "train_fn = theano.function([input_var, target_var], train_loss, updates=update_op, allow_input_downcast=True)\n",
    "val_fn = theano.function([input_var, target_var], [valid_loss, valid_acc], allow_input_downcast=True)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "num_train_batches = len(train[0]) // batch_size\n",
    "train_batches = batch_generator(train[0], train[1], batch_size)\n",
    "\n",
    "num_valid_batches = len(valid[0]) // batch_size\n",
    "valid_batches = batch_generator(valid[0], valid[1], batch_size)\n",
    "\n",
    "n_epochs = 10\n",
    "for e in range(n_epochs):\n",
    "    ave_loss = 0\n",
    "    for index in range(num_train_batches):\n",
    "        X_batch, y_batch = next(train_batches)\n",
    "        train_loss = train_fn(X_batch, y_batch)\n",
    "        ave_loss += train_loss\n",
    "    print(\"train: %f\" % float(ave_loss/num_train_batches))\n",
    "\n",
    "    ave_loss = 0\n",
    "    ave_acc = 0\n",
    "    for index in range(num_valid_batches):\n",
    "        X_batch, y_batch = next(valid_batches)\n",
    "        valid_loss, valid_acc = val_fn(X_batch, y_batch)\n",
    "        ave_loss += valid_loss\n",
    "        ave_acc += valid_acc\n",
    "    print(\"valid: %f\" % float(ave_loss/num_valid_batches))\n",
    "    print(\"accuracy: %f\" % float(ave_acc/num_valid_batches))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
