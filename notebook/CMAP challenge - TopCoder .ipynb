{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import os, sys, gzip\n",
    "import cPickle as pickle\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1004)   # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from lasagne import layers, nonlinearities, updates, objectives, init, regularization\n",
    "from lasagne.layers import get_output, get_output_shape, get_all_params\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "#from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datapath='/home/peter/Data/CMAP/training.csv'\n",
    "savepath='/home/peter/Data/CMAP/dataset.hd5f'\n",
    "\n",
    "f = h5py.File(savepath, \"w\")\n",
    "batch_size = 20000\n",
    "shuffle_index = np.random.permutation(100000)\n",
    "for i in range(0,5):\n",
    "    batch_index =range(i*batch_size, (i+1)*batch_size)\n",
    "    data = pd.read_csv(datapath, usecols=shuffle_index[batch_index], header=None, dtype=np.float32)\n",
    "    genes = data.as_matrix()\n",
    "    num_landmark = 970\n",
    "    num_nonlandmark = 11350\n",
    "    num_samples = genes.shape[1]\n",
    "    landmark = genes[:970,:]\n",
    "    nonlandmark = genes[970:,:]\n",
    "    del genes\n",
    "\n",
    "    dset = f.create_dataset(\"landmark\"+str(i), data=landmark)\n",
    "    dset = f.create_dataset(\"nonlandmark\"+str(i), data=nonlandmark)\n",
    "    del landmark\n",
    "    del nonlandmark\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_data(landmark, nonlandmark, mean_landmark, std_landmark, mean_nonlandmark, std_nonlandmark, num_samples):\n",
    "    landmark = (landmark - np.outer(mean_landmark,np.ones(num_samples)))/np.outer(std_landmark,np.ones(num_samples))\n",
    "    nonlandmark = (nonlandmark - np.outer(mean_nonlandmark,np.ones(num_samples)))/np.outer(std_nonlandmark,np.ones(num_samples))\n",
    "    landmark = landmark.transpose([1,0])\n",
    "    nonlandmark = nonlandmark.transpose([1,0])\n",
    "\n",
    "    return landmark, nonlandmark\n",
    "\n",
    "\n",
    "filepath='/home/peter/Data/CMAP/dataset.hd5f'\n",
    "trainmat = h5py.File(filepath, 'r')\n",
    "landmark= np.array(trainmat['landmark1']).astype(np.float32)\n",
    "nonlandmark = np.array(trainmat['nonlandmark1']).astype(np.float32)\n",
    "\n",
    "num_files = 5\n",
    "mean_landmark = 0\n",
    "std_landmark = 0\n",
    "mean_nonlandmark = 0\n",
    "std_nonlandmark = 0\n",
    "for i in range(num_files):\n",
    "    landmark= np.array(trainmat['landmark'+str(i)]).astype(np.float32)\n",
    "    nonlandmark = np.array(trainmat['nonlandmark'+str(i)]).astype(np.float32)\n",
    "    mean_landmark += np.mean(landmark, axis=1)\n",
    "    std_landmark += np.std(landmark,axis=1)\n",
    "    mean_nonlandmark += np.mean(nonlandmark, axis=1)\n",
    "    std_nonlandmark += np.std(nonlandmark, axis=1)\n",
    "\n",
    "mean_landmark /= num_files\n",
    "std_landmark /= num_files\n",
    "mean_nonlandmark /= num_files\n",
    "std_nonlandmark /= num_files\n",
    "\n",
    "savepath='/home/peter/Data/CMAP/dataset_norm.hd5f'\n",
    "f = h5py.File(savepath, \"w\")\n",
    "batch_size = 20000\n",
    "for i in range(0,5):\n",
    "    landmark = np.array(trainmat['landmark'+str(i)]).astype(np.float32)\n",
    "    nonlandmark = np.array(trainmat['nonlandmark'+str(i)]).astype(np.float32)\n",
    "    landmark, nonlandmark = normalize_data(landmark, nonlandmark, mean_landmark, std_landmark, mean_nonlandmark, std_nonlandmark, num_samples)\n",
    "    dset = f.create_dataset(\"landmark\"+str(i), data=landmark)\n",
    "    dset = f.create_dataset(\"nonlandmark\"+str(i), data=nonlandmark)\n",
    "dset = f.create_dataset(\"mean_landmark\", data=mean_landmark)\n",
    "dset = f.create_dataset(\"std_landmark\", data=std_landmark)\n",
    "dset = f.create_dataset(\"mean_nonlandmark\", data=mean_nonlandmark)\n",
    "dset = f.create_dataset(\"std_nonlandmark\", data=std_nonlandmark)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath='/home/peter/Data/CMAP/dataset_norm.hd5f'\n",
    "trainmat = h5py.File(filepath, 'r')\n",
    "landmark= np.array(trainmat['landmark4']).astype(np.float32)\n",
    "nonlandmark = np.array(trainmat['nonlandmark4']).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = 2\n",
    "plt.hist(landmark[:,index]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = np.cov(nonlandmark.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(C)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = T.dmatrix('inputs')\n",
    "shape = (None, landmark.shape[1])\n",
    "net = {}\n",
    "net['input'] = layers.InputLayer(shape=shape, input_var=input_var)\n",
    "net['dense1'] = layers.DenseLayer(net['input'], num_units=nonlandmark.shape[1], W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=None)\n",
    "net['dense1_active'] = layers.NonlinearityLayer(net['dense1'], nonlinearity=nonlinearities.linear)\n",
    "net['output'] = net['dense1_active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_var = T.dmatrix('inputs')\n",
    "prediction = get_output(net['output'], deterministic=False )\n",
    "loss = objectives.squared_error(target_var, prediction)\n",
    "loss = objectives.aggregate(loss, mode='mean')\n",
    "\n",
    "# ADAM updates\n",
    "params = get_all_params(net['output'], trainable=True)\n",
    "update_op = updates.adam(loss, params, learning_rate=1e-3)\n",
    "\n",
    "train_fun = theano.function([input_var, target_var], loss , updates=update_op, allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size=128):\n",
    "    for start_idx in range(0, len(X)-batch_size+1, batch_size):\n",
    "        excerpt = slice(start_idx, start_idx+batch_size)\n",
    "        yield X[excerpt], y[excerpt]\n",
    "\n",
    "batch_size = 100        \n",
    "num_samples = 20000\n",
    "num_files = 5        \n",
    "num_epochs = 60    \n",
    "num_batches = num_samples // batch_size\n",
    "for epoch in range(num_epochs):\n",
    "    sys.stdout.write(\"\\rEpoch %d \\n\"%(epoch+1))\n",
    "\n",
    "    train_loss = 0\n",
    "    for i in range(num_files):\n",
    "        sys.stdout.write(\"\\r  File %d \\n\"%(i+1))\n",
    "        landmark= np.array(trainmat['landmark'+str(i)]).astype(np.float32)\n",
    "        nonlandmark = np.array(trainmat['nonlandmark'+str(i)]).astype(np.float32)\n",
    "        batches = batch_generator(landmark, nonlandmark, batch_size)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(num_batches):\n",
    "            X, y = next(batches)\n",
    "            loss += train_fun(X, y)\n",
    "        print(\"    training loss:\\t\\t{:.6f}\".format(loss/num_batches))    \n",
    "        train_loss += loss/num_batches              \n",
    "    train_loss /= num_files\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1 \n",
    "  File 1 \n",
    "    training loss:\t\t0.588965\n",
    "  File 2 \n",
    "    training loss:\t\t0.599399\n",
    "  File 3 \n",
    "    training loss:\t\t0.509065\n",
    "  File 4 \n",
    "    training loss:\t\t0.578905\n",
    "  File 5 \n",
    "    training loss:\t\t0.566761\n",
    "  training loss:\t\t0.568619\n",
    "Epoch 2 \n",
    "  File 1 \n",
    "    training loss:\t\t0.464421\n",
    "  File 2 \n",
    "    training loss:\t\t0.486734\n",
    "  File 3 \n",
    "    training loss:\t\t0.432946\n",
    "  File 4 \n",
    "    training loss:\t\t0.476401\n",
    "  File 5 \n",
    "    training loss:\t\t0.494727\n",
    "  training loss:\t\t0.471046\n",
    "Epoch 3 \n",
    "  File 1 \n",
    "    training loss:\t\t0.448270\n",
    "  File 2 \n",
    "    training loss:\t\t0.484055\n",
    "  File 3 \n",
    "    training loss:\t\t0.431769\n",
    "  File 4 \n",
    "    training loss:\t\t0.487850\n",
    "  File 5 \n",
    "    training loss:\t\t0.504944\n",
    "  training loss:\t\t0.471378"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_encode=100\n",
    "\n",
    "input_var = T.dmatrix('inputs')\n",
    "shape = (None, landmark.shape[1])\n",
    "net = {}\n",
    "net['input'] = layers.InputLayer(shape=shape, input_var=input_var)\n",
    "net['dense1'] = layers.DenseLayer(net['input'], num_units=5000, W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=None)\n",
    "net['dense1_active'] = layers.NonlinearityLayer(net['dense1'], nonlinearity=nonlinearities.rectify)\n",
    "#net['dense1_active'] = layers.ParametricRectifierLayer(net['dense1_norm'])\n",
    "#net['dense1_droput'] = layers.DropoutLayer(net['dense1_active'], p=0.5)\n",
    "\n",
    "\n",
    "net['dense2'] = layers.DenseLayer(net['dense1_active'], num_units=nonlandmark.shape[1], W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=None)\n",
    "net['dense2_active'] = layers.NonlinearityLayer(net['dense2'], nonlinearity=nonlinearities.linear)\n",
    "#net['dense2_active'] = layers.ParametricRectifierLayer(net['dense2_norm'])\n",
    "#net['dense2_droput'] = layers.DropoutLayer(net['dense2_active'], p=0.5)\n",
    "\n",
    "net['output'] = net['dense2_active']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_var = T.dmatrix('inputs')\n",
    "prediction = get_output(net['output'], deterministic=False )\n",
    "loss = objectives.squared_error(target_var, prediction)\n",
    "loss = objectives.aggregate(loss, mode='mean')\n",
    "\n",
    "#l1_penalty = regularization.regularize_network_params(net, regularization.l1) * 1e-5\n",
    "#loss += l1_penalty\n",
    "#l2_penalty = regularization.regularize_network_params(net, regularization.l2) * 1e-6    \n",
    "#loss += l2_penalty \n",
    "    \n",
    "# ADAM updates\n",
    "params = get_all_params(net['output'], trainable=True)\n",
    "update_op = updates.adam(loss, params, learning_rate=1e-3)\n",
    "\n",
    "train_fun = theano.function([input_var, target_var], loss , updates=update_op, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size=128):\n",
    "    for start_idx in range(0, len(X)-batch_size+1, batch_size):\n",
    "        excerpt = slice(start_idx, start_idx+batch_size)\n",
    "        yield X[excerpt], y[excerpt]\n",
    "\n",
    "batch_size = 100        \n",
    "num_samples = 20000\n",
    "num_files = 5        \n",
    "num_epochs = 60    \n",
    "num_batches = num_samples // batch_size\n",
    "for epoch in range(num_epochs):\n",
    "    sys.stdout.write(\"\\rEpoch %d \\n\"%(epoch+1))\n",
    "\n",
    "    train_loss = 0\n",
    "    for i in range(num_files):\n",
    "        sys.stdout.write(\"\\r  File %d \\n\"%(i+1))\n",
    "        landmark= np.array(trainmat['landmark'+str(i)]).astype(np.float32)\n",
    "        nonlandmark = np.array(trainmat['nonlandmark'+str(i)]).astype(np.float32)\n",
    "        batches = batch_generator(landmark, nonlandmark, batch_size)\n",
    "        \n",
    "        loss = 0\n",
    "        for i in range(num_batches):\n",
    "            X, y = next(batches)\n",
    "            loss += train_fun(X, y)\n",
    "        print(\"    training loss:\\t\\t{:.6f}\".format(loss/num_batches))    \n",
    "        train_loss += loss/num_batches              \n",
    "    train_loss /= num_files\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# denoising autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var = T.dmatrix('inputs')\n",
    "shape = (None, landmark.shape[1])\n",
    "net = {}\n",
    "net['input'] = layers.InputLayer(shape=shape, input_var=input_var)\n",
    "\n",
    "# encode layer 1\n",
    "net['corrupt1'] = layers.GaussianNoiseLayer(net['input'], sigma=0.1)\n",
    "net['encode1'] = layers.DenseLayer(net['corrupt1'], num_units=2000, W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=None)\n",
    "net['encode1_active'] = layers.NonlinearityLayer(net['encode1'], nonlinearity=nonlinearities.rectify)\n",
    "\n",
    "# encode layer 2\n",
    "net['corrupt2'] = layers.GaussianNoiseLayer(net['encode1_active'], sigma=0.1)\n",
    "net['encode2'] = layers.DenseLayer(net['corrupt2'], num_units=4000, W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=None)\n",
    "net['encode2_active'] = layers.NonlinearityLayer(net['encode2'], nonlinearity=nonlinearities.rectify)\n",
    "\n",
    "# encode layer\n",
    "net['encode'] = layers.DenseLayer(net['encode2_active'], num_units=nonlandmark.shape[1], W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=None)\n",
    "net['encode_active'] = layers.NonlinearityLayer(net['encode'], nonlinearity=nonlinearities.linear)\n",
    "\n",
    "# decode layer\n",
    "net['decode'] = layers.DenseLayer(net['encode_active'], num_units=4000, W=net['encode'].W.T, \n",
    "                                  b=init.Constant(.0), nonlinearity=None)\n",
    "net['decode_active'] = layers.NonlinearityLayer(net['decode'], nonlinearity=nonlinearities.rectify)\n",
    "\n",
    "# decode layer 1\n",
    "net['decode1'] = layers.DenseLayer(net['decode_active'], num_units=2000, W=net['encode2'].W.T, \n",
    "                                  b=init.Constant(.0), nonlinearity=None)\n",
    "net['decode1_active'] = layers.NonlinearityLayer(net['decode1'], nonlinearity=nonlinearities.rectify)\n",
    "\n",
    "# decode layer 2\n",
    "net['decode2'] = layers.DenseLayer(net['decode1_active'], num_units=landmark.shape[1], W=net['encode1'].W.T, \n",
    "                                  b=init.Constant(.0), nonlinearity=None)\n",
    "net['decode2_active'] = layers.NonlinearityLayer(net['decode2'], nonlinearity=nonlinearities.linear)\n",
    "net['output'] = net['decode2_active']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = get_output(net['output'], deterministic=False )\n",
    "loss1 = objectives.squared_error(input_var, prediction)\n",
    "loss1 = objectives.aggregate(loss1, mode='mean')\n",
    "\n",
    "target_var = T.dmatrix('inputs')\n",
    "prediction = get_output(net['encode_active'], deterministic=False )\n",
    "loss2 = objectives.squared_error(target_var, prediction)\n",
    "loss2 = objectives.aggregate(loss2, mode='mean')\n",
    "\n",
    "loss = loss1 + loss2\n",
    "\n",
    "#l1_penalty = regularization.regularize_network_params(net, regularization.l1) * 1e-5\n",
    "#loss += l1_penalty\n",
    "#l2_penalty = regularization.regularize_network_params(net, regularization.l2) * 1e-6    \n",
    "#loss += l2_penalty \n",
    "    \n",
    "# ADAM updates\n",
    "params = get_all_params(net['output'], trainable=True)\n",
    "update_op = updates.adam(loss, params, learning_rate=1e-3)\n",
    "\n",
    "train_fun = theano.function([input_var, target_var], loss , updates=update_op, allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size=128):\n",
    "    for start_idx in range(0, len(X)-batch_size+1, batch_size):\n",
    "        excerpt = slice(start_idx, start_idx+batch_size)\n",
    "        yield X[excerpt], y[excerpt]\n",
    "\n",
    "batch_size = 100        \n",
    "num_samples = 20000\n",
    "num_files = 5        \n",
    "num_epochs = 60    \n",
    "num_batches = num_samples // batch_size\n",
    "for epoch in range(num_epochs):\n",
    "    sys.stdout.write(\"\\rEpoch %d \\n\"%(epoch+1))\n",
    "\n",
    "    train_loss = 0\n",
    "    for i in range(num_files):\n",
    "        sys.stdout.write(\"\\r  File %d \\n\"%(i+1))\n",
    "        landmark= np.array(trainmat['landmark'+str(i)]).astype(np.float32)\n",
    "        nonlandmark = np.array(trainmat['nonlandmark'+str(i)]).astype(np.float32)\n",
    "        batches = batch_generator(landmark, nonlandmark, batch_size)\n",
    "        \n",
    "        loss = 0\n",
    "        for j in range(num_batches):\n",
    "            X, y = next(batches)\n",
    "            loss += train_fun(X, y)\n",
    "        print(\"    training loss:\\t\\t{:.6f}\".format(loss/num_batches))    \n",
    "        train_loss += loss/num_batches              \n",
    "    train_loss /= num_files\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "savepath='/home/peter/Data/CMAP/dataset_norm.hd5f'\n",
    "trainmat = h5py.File(savepath, 'r')\n",
    "mean_landmark = np.array(trainmat['mean_landmark']).astype(np.float32)\n",
    "std_landmark = np.array(trainmat['std_landmark']).astype(np.float32)\n",
    "mean_nonlandmark = np.array(trainmat['mean_nonlandmark']).astype(np.float32)\n",
    "std_nonlandmark = np.array(trainmat['std_nonlandmark']).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(970, 1000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarkpath='/home/peter/Data/CMAP/test/landmarks.csv'\n",
    "data = pd.read_csv(landmarkpath, header=None, dtype=np.float32)\n",
    "landmark = data.as_matrix()\n",
    "landmark.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11350, 1000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlandmarkpath='/home/peter/Data/CMAP/test/truth.csv'\n",
    "data = pd.read_csv(nonlandmarkpath, header=None, dtype=np.float32)\n",
    "nonlandmark = data.as_matrix()\n",
    "nonlandmark.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_data(landmark, nonlandmark, mean_landmark, std_landmark, mean_nonlandmark, std_nonlandmark, num_samples):\n",
    "    landmark = (landmark - np.outer(mean_landmark,np.ones(num_samples)))/np.outer(std_landmark,np.ones(num_samples))\n",
    "    nonlandmark = (nonlandmark - np.outer(mean_nonlandmark,np.ones(num_samples)))/np.outer(std_nonlandmark,np.ones(num_samples))\n",
    "    landmark = landmark.transpose([1,0])\n",
    "    nonlandmark = nonlandmark.transpose([1,0])\n",
    "\n",
    "    return landmark, nonlandmark\n",
    "\n",
    "landmark, nonlandmark = normalize_data(landmark, nonlandmark, mean_landmark, std_landmark, mean_nonlandmark, std_nonlandmark, landmark.shape[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append('..')\n",
    "from src import NeuralNet\n",
    "\n",
    "# build model\n",
    "model_name = \"CMAP_model\"\n",
    "nnmodel = NeuralNet(model_name, shape=[], num_labels=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weightpath = '/home/peter/Data/CMAP/Results/LinearRegression_epoch_0.pickle'\n",
    "nnmodel.set_parameters_from_file(weightpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dense1': <lasagne.layers.dense.DenseLayer at 0x7f06003f4d90>,\n",
       " 'dense1_active': <lasagne.layers.special.NonlinearityLayer at 0x7f06003f4d10>,\n",
       " 'input': <lasagne.layers.input.InputLayer at 0x7f06003f4c90>,\n",
       " 'output': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nnmodel.network\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_var = nnmodel.input_var\n",
    "prediction = get_output(network['dense1_active'], deterministic=True)\n",
    "\n",
    "get_prediction = theano.function([input_var], prediction, allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = get_prediction(landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66719473471025448"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = []\n",
    "for i in range(prediction.shape[1]):\n",
    "    R.append(stats.spearmanr(prediction[:,i], nonlandmark[:,i])[0])\n",
    "    \n",
    "np.mean(R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEACAYAAAC+gnFaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEEhS4wwCSWqcQSBJjft/58jR8imCaEoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05ec0ddcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(R,bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 11350)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = prediction.transpose([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_samples = prediction.shape[1]\n",
    "prediction = (prediction*np.outer(std_nonlandmark,np.ones(num_samples))) + np.outer(mean_nonlandmark,np.ones(num_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.70000000e+01,   9.30000000e+01,   4.21000000e+02,\n",
       "          4.11410000e+04,   1.09059360e+07,   3.95344000e+05,\n",
       "          6.43200000e+03,   5.04000000e+02,   8.20000000e+01,\n",
       "          1.00000000e+01]),\n",
       " array([-21.10741553, -16.49719339, -11.88697125,  -7.27674911,\n",
       "         -2.66652697,   1.94369517,   6.55391731,  11.16413945,\n",
       "         15.7743616 ,  20.38458374,  24.99480588]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEGCAYAAACevtWaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05e968f350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(nonlandmark.reshape([-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11350, 1000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2.to_csv('/home/peter/Data/CMAP/test/prediction_ols.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rscript cmap_scoring_function.R --inf_ds prediction_ols.csv \\\n",
    "    --truth_ds truth.csv \\\n",
    "    --reference_scores refScores.csv \\\n",
    "    --out here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path='/home/peter/Data/CMAP/test/prediction.csv'\n",
    "data = pd.read_csv(path, header=None, dtype=np.float32)\n",
    "test = data.as_matrix()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11350, 1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nonlandmarkpath='/home/peter/Data/CMAP/test/truth.csv'\n",
    "data = pd.read_csv(nonlandmarkpath, header=None, dtype=np.float32)\n",
    "truth = data.as_matrix()\n",
    "truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69230810242910368"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = []\n",
    "for i in range(prediction.shape[1]):\n",
    "    R.append(stats.spearmanr(prediction[i,:], truth[i,:])[0])\n",
    "np.mean(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
