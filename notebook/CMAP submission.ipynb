{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import os, sys, gzip\n",
    "import cPickle as pickle\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1004)   # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy import stats\n",
    "from lasagne import layers, nonlinearities, updates, objectives, init, regularization\n",
    "from lasagne.layers import get_output, get_output_shape, get_all_params\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "\n",
    "from six.moves import cPickle\n",
    "\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "import lasagne as nn\n",
    "from lasagne import layers, init, nonlinearities, utils, regularization, objectives, updates\n",
    "from lasagne.layers.base import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BatchNormLayer(Layer):\n",
    "    def __init__(self, incoming, axes='auto', epsilon=1e-4, alpha=0.1,\n",
    "                 beta=init.Constant(0), gamma=init.Constant(1),\n",
    "                 mean=init.Constant(0), inv_std=init.Constant(1), **kwargs):\n",
    "        super(BatchNormLayer, self).__init__(incoming, **kwargs)\n",
    "\n",
    "        if axes == 'auto':\n",
    "            # default: normalize over all but the second axis\n",
    "            axes = (0,) + tuple(range(2, len(self.input_shape)))\n",
    "        elif isinstance(axes, int):\n",
    "            axes = (axes,)\n",
    "        self.axes = axes\n",
    "\n",
    "        self.epsilon = utils.floatX(epsilon)\n",
    "        self.alpha = utils.floatX(alpha)\n",
    "\n",
    "        # create parameters, ignoring all dimensions in axes\n",
    "        shape = [size for axis, size in enumerate(self.input_shape)\n",
    "                 if axis not in self.axes]\n",
    "        if any(size is None for size in shape):\n",
    "            raise ValueError(\"BatchNormLayer needs specified input sizes for \"\n",
    "                             \"all axes not normalized over.\")\n",
    "        if beta is None:\n",
    "            self.beta = None\n",
    "        else:\n",
    "            self.beta = self.add_param(beta, shape, 'beta',\n",
    "                                       trainable=True, regularizable=False)\n",
    "        if gamma is None:\n",
    "            self.gamma = None\n",
    "        else:\n",
    "            self.gamma = self.add_param(gamma, shape, 'gamma',\n",
    "                                        trainable=True, regularizable=False)\n",
    "        self.mean = self.add_param(mean, shape, 'mean',\n",
    "                                   trainable=False, regularizable=False)\n",
    "        self.inv_std = self.add_param(inv_std, shape, 'inv_std',\n",
    "                                      trainable=False, regularizable=False)\n",
    "\n",
    "        self.beta = T.cast(self.beta, dtype='floatX')\n",
    "        self.gamma = T.cast(self.gamma, dtype='floatX')\n",
    "        self.mean = T.cast(self.mean, dtype='floatX')\n",
    "        self.inv_std = T.cast(self.inv_std, dtype='floatX')\n",
    "\n",
    "    def get_output_for(self, input, deterministic=False,\n",
    "                       batch_norm_use_averages=None,\n",
    "                       batch_norm_update_averages=None, **kwargs):\n",
    "        input_mean = input.mean(self.axes)\n",
    "        input_inv_std = T.inv(T.sqrt(input.var(self.axes) + self.epsilon))\n",
    "\n",
    "        # Decide whether to use the stored averages or mini-batch statistics\n",
    "        if batch_norm_use_averages is None:\n",
    "            batch_norm_use_averages = deterministic\n",
    "        use_averages = batch_norm_use_averages\n",
    "\n",
    "        if use_averages:\n",
    "            mean = self.mean\n",
    "            inv_std = self.inv_std\n",
    "        else:\n",
    "            mean = input_mean\n",
    "            inv_std = input_inv_std\n",
    "\n",
    "        # Decide whether to update the stored averages\n",
    "        if batch_norm_update_averages is None:\n",
    "            batch_norm_update_averages = not deterministic\n",
    "        update_averages = batch_norm_update_averages\n",
    "\n",
    "        if update_averages:\n",
    "            # Trick: To update the stored statistics, we create memory-aliased\n",
    "            # clones of the stored statistics:\n",
    "            running_mean = theano.clone(self.mean, share_inputs=False)\n",
    "            running_inv_std = theano.clone(self.inv_std, share_inputs=False)\n",
    "            # set a default update for them:\n",
    "            running_mean.default_update = ((1 - self.alpha) * running_mean +\n",
    "                                           self.alpha * input_mean)\n",
    "            running_inv_std.default_update = ((1 - self.alpha) *\n",
    "                                              running_inv_std +\n",
    "                                              self.alpha * input_inv_std)\n",
    "            # and make sure they end up in the graph without participating in\n",
    "            # the computation (this way their default_update will be collected\n",
    "            # and applied, but the computation will be optimized away):\n",
    "            mean += 0 * running_mean\n",
    "            inv_std += 0 * running_inv_std\n",
    "\n",
    "        # prepare dimshuffle pattern inserting broadcastable axes as needed\n",
    "        param_axes = iter(range(input.ndim - len(self.axes)))\n",
    "        pattern = ['x' if input_axis in self.axes\n",
    "                   else next(param_axes)\n",
    "                   for input_axis in range(input.ndim)]\n",
    "\n",
    "        # apply dimshuffle pattern to all parameters\n",
    "        beta = 0 if self.beta is None else self.beta.dimshuffle(pattern)\n",
    "        gamma = 1 if self.gamma is None else self.gamma.dimshuffle(pattern)\n",
    "        mean = mean.dimshuffle(pattern)\n",
    "        inv_std = inv_std.dimshuffle(pattern)\n",
    "\n",
    "        # normalize\n",
    "        normalized = (input - mean) * (gamma * inv_std) + beta\n",
    "        return normalized\n",
    "\n",
    "class GaussianSampleLayer(layers.MergeLayer):\n",
    "    def __init__(self, incoming_mu, incoming_logsigma, **kwargs):\n",
    "        super(GaussianSampleLayer, self).__init__(incomings=[incoming_mu, incoming_logsigma], **kwargs)\n",
    "        self.srng = RandomStreams(seed=234)\n",
    "\n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        return input_shapes[0]\n",
    "\n",
    "    def get_output_for(self, inputs, deterministic=False, **kwargs):\n",
    "        mu, logsigma = inputs\n",
    "        shape=(self.input_shapes[0][0] or inputs[0].shape[0],\n",
    "                self.input_shapes[0][1] or inputs[0].shape[1])\n",
    "        if deterministic:\n",
    "            return mu\n",
    "        return mu + T.exp(logsigma) * self.srng.normal(shape, avg=0.0, std=1).astype(theano.config.floatX)\n",
    "\n",
    "\n",
    "def vae_model(input_var):\n",
    "    net = {}\n",
    "    net['input'] = layers.InputLayer(shape=(None, 970), input_var=input_var)\n",
    "\n",
    "    # encode layer 1\n",
    "    net['encode1'] = layers.DenseLayer(net['input'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=None)\n",
    "    net['encode1_norm'] = BatchNormLayer(net['encode1'])\n",
    "    net['encode1_active'] = layers.NonlinearityLayer(net['encode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "    net['encode1_dropout'] = layers.DropoutLayer(net['encode1_active'],p=0.5)\n",
    "\n",
    "    # encode layer\n",
    "    net['Z_mu'] = layers.DenseLayer(net['encode1_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    \n",
    "    net['Z_logsigma'] = layers.DenseLayer(net['encode1_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    net['Z'] = GaussianSampleLayer(net['Z_mu'], net['Z_logsigma'])\n",
    "\n",
    "    # encode layer 1\n",
    "    net['decode1'] = layers.DenseLayer(net['Z'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=None)\n",
    "    net['decode1_norm'] = BatchNormLayer(net['decode1'])\n",
    "    net['decode1_active'] = layers.NonlinearityLayer(net['decode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "    net['decode1_dropout'] = layers.DropoutLayer(net['decode1_active'],p=0.5)\n",
    "\n",
    "\n",
    "    # encode layer\n",
    "    net['X_mu'] = layers.DenseLayer(net['decode1_dropout'], num_units=970, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    net['X_logsigma'] = layers.DenseLayer(net['decode1_dropout'], num_units=970, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    net['X'] = GaussianSampleLayer(net['X_mu'], net['X_logsigma'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_prediction(best_path, landmark, mean_nonlandmark, std_nonlandmark):\n",
    "    class MultiplicativeGatingLayer(nn.layers.MergeLayer):\n",
    "        \"\"\"\n",
    "        Generic layer that combines its 3 inputs t, h1, h2 as follows:\n",
    "        y = t * h1 + (1 - t) * h2\n",
    "        \"\"\"\n",
    "        def __init__(self, gate, input1, input2, **kwargs):\n",
    "            incomings = [gate, input1, input2]\n",
    "            super(MultiplicativeGatingLayer, self).__init__(incomings, **kwargs)\n",
    "            assert gate.output_shape == input1.output_shape == input2.output_shape\n",
    "\n",
    "        def get_output_shape_for(self, input_shapes):\n",
    "            return input_shapes[0]\n",
    "\n",
    "        def get_output_for(self, inputs, **kwargs):\n",
    "            return inputs[0] * inputs[1] + (1 - inputs[0]) * inputs[2]\n",
    "    def mlp_model(input_var):\n",
    "        net = {}\n",
    "        net['input'] = layers.InputLayer(shape=(None, 970), input_var=input_var)\n",
    "\n",
    "        # encode layer 1\n",
    "        net['encode1'] = layers.DenseLayer(net['input'], num_units=1000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode1_norm'] = BatchNormLayer(net['encode1'])\n",
    "        net['encode1_active'] = layers.NonlinearityLayer(net['encode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode1_dropout'] = layers.DropoutLayer(net['encode1_active'],p=0.5)\n",
    "\n",
    "        # encode layer 2\n",
    "        net['encode2'] = layers.DenseLayer(net['encode1_dropout'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode2_norm'] = BatchNormLayer(net['encode2'])\n",
    "        net['encode2_active'] = layers.NonlinearityLayer(net['encode2_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode2_dropout'] = layers.DropoutLayer(net['encode2_active'],p=0.5)\n",
    "\n",
    "        # encode layer\n",
    "        net['output'] = layers.DenseLayer(net['encode2_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "        return net\n",
    "    def dae_model(input_var):\n",
    "        net = {}\n",
    "        net['input'] = layers.InputLayer(shape=(None, 970), input_var=input_var)\n",
    "\n",
    "        # encode layer 1\n",
    "        net['encode1'] = layers.DenseLayer(net['input'], num_units=1000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode1_norm'] = BatchNormLayer(net['encode1'])\n",
    "        net['encode1_active'] = layers.NonlinearityLayer(net['encode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode1_dropout'] = layers.DropoutLayer(net['encode1_active'],p=0.5)\n",
    "\n",
    "        # encode layer 2\n",
    "        net['encode2'] = layers.DenseLayer(net['encode1_dropout'], num_units=2000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode2_norm'] = BatchNormLayer(net['encode2'])\n",
    "        net['encode2_active'] = layers.NonlinearityLayer(net['encode2_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode2_dropout'] = layers.DropoutLayer(net['encode2_active'],p=0.5)\n",
    "\n",
    "        # encode layer 2\n",
    "        net['encode3'] = layers.DenseLayer(net['encode2_dropout'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode3_norm'] = BatchNormLayer(net['encode3'])\n",
    "        net['encode3_active'] = layers.NonlinearityLayer(net['encode3_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode3_dropout'] = layers.DropoutLayer(net['encode3_active'],p=0.5)\n",
    "\n",
    "        # encode layer\n",
    "        net['encode'] = layers.DenseLayer(net['encode3_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['output'] = layers.NonlinearityLayer(net['encode'], nonlinearity=nonlinearities.linear)\n",
    "        return net\n",
    "\n",
    "    def highway_dense(incoming, Wh=init.Orthogonal(), bh=init.Constant(0.0),\n",
    "                      Wt=init.Orthogonal(), bt=init.Constant(-4.0),\n",
    "                      nonlinearity=nonlinearities.rectify, **kwargs):\n",
    "        num_inputs = int(np.prod(incoming.output_shape[1:]))\n",
    "        # regular layer\n",
    "        l_h = layers.DenseLayer(incoming, num_units=num_inputs, W=Wh, b=bh,\n",
    "                                   nonlinearity=nonlinearity)\n",
    "        # gate layer\n",
    "        l_t = layers.DenseLayer(incoming, num_units=num_inputs, W=Wt, b=bt,\n",
    "                                   nonlinearity=T.nnet.sigmoid)\n",
    "\n",
    "        return MultiplicativeGatingLayer(gate=l_t, input1=l_h, input2=incoming)\n",
    "\n",
    "    def build_model(input_var, batch_size=100,\n",
    "                    num_hidden_units=500, num_hidden_layers=50):\n",
    "\n",
    "        l_in = layers.InputLayer(shape=(batch_size, 970), input_var=input_var)\n",
    "\n",
    "        # first, project it down to the desired number of units per layer\n",
    "        l_hidden1 = layers.DenseLayer(l_in, num_units=num_hidden_units)\n",
    "\n",
    "        # then stack highway layers on top of this\n",
    "        l_current = l_hidden1\n",
    "        for k in range(num_hidden_layers - 1):\n",
    "            l_current = highway_dense(l_current)\n",
    "\n",
    "\n",
    "        l_hidden2 = layers.DenseLayer(l_current, num_units=2000)\n",
    "\n",
    "        # finally add an output layer\n",
    "        l_out = layers.DenseLayer( l_hidden2, num_units=11350, nonlinearity=nonlinearities.linear)\n",
    "\n",
    "        return l_out\n",
    "\n",
    "\n",
    "    # setup model\n",
    "    input_var = T.dmatrix('landmark')\n",
    "    #network = build_model(input_var, batch_size=100, num_hidden_units=500, num_hidden_layers=50)\n",
    "    #network = build_model(input_var)\n",
    "    network = build_model(input_var)\n",
    "    \n",
    "    f = open(best_path, 'rb')\n",
    "    best_parameters = cPickle.load(f)\n",
    "    f.close()\n",
    "    layers.set_all_param_values(network, best_parameters)\n",
    "\n",
    "\n",
    "    prediction = layers.get_output(network, deterministic=True)\n",
    "\n",
    "    get_prediction = theano.function([input_var], prediction, allow_input_downcast=True)\n",
    "    prediction = get_prediction(landmark)\n",
    "\n",
    "    prediction = prediction.transpose([1,0]).astype(np.float64)\n",
    "    num_samples = prediction.shape[1]\n",
    "    prediction = (prediction*std_nonlandmark) + mean_nonlandmark\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970, 1000)\n"
     ]
    }
   ],
   "source": [
    "landmarkpath='/home/peter/Data/CMAP/test/landmarks.csv'\n",
    "data = pd.read_csv(landmarkpath, header=None, dtype=np.float32)\n",
    "landmark = data.as_matrix()\n",
    "\n",
    "nonlandmarkpath='/home/peter/Data/CMAP/test/truth.csv'\n",
    "data = pd.read_csv(nonlandmarkpath, header=None, dtype=np.float32)\n",
    "nonlandmark = data.as_matrix()\n",
    "\n",
    "def normalize_data(landmark, mean_landmark, std_landmark, num_samples):\n",
    "    landmark = (landmark - mean_landmark)/std_landmark\n",
    "    landmark = landmark.transpose([1,0])\n",
    "    return landmark\n",
    "print landmark.shape\n",
    "mean_landmark = np.mean(landmark)\n",
    "std_landmark = np.std(landmark)\n",
    "landmark = normalize_data(landmark, mean_landmark, std_landmark, landmark.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_path = '/home/peter/Data/CMAP/Results/highway_corr2epoch_3.pickle'\n",
    "prediction = model_prediction(best_path, landmark,  mean_landmark, std_landmark)\n",
    "\n",
    "df2 = pd.DataFrame(prediction)\n",
    "df2.to_csv('/home/peter/Data/CMAP/test/prediction_ff.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77851194316691108"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/home/peter/Data/CMAP/test/prediction_ff.csv'\n",
    "data = pd.read_csv(path, header=None, dtype=np.float32)\n",
    "test = data.as_matrix()\n",
    "test.shape\n",
    "\n",
    "nonlandmarkpath='/home/peter/Data/CMAP/test/truth.csv'\n",
    "data = pd.read_csv(nonlandmarkpath, header=None, dtype=np.float32)\n",
    "truth = data.as_matrix()\n",
    "truth.shape\n",
    "\n",
    "R = []\n",
    "for i in range(prediction.shape[1]):\n",
    "    R.append(stats.spearmanr(prediction[i,:], truth[i,:])[0])\n",
    "np.mean(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2.,    0.,    1.,    0.,    2.,    3.,    8.,    8.,   10.,\n",
       "          11.,   19.,   13.,   18.,   11.,   17.,   26.,   23.,   21.,\n",
       "          25.,   19.,   35.,   31.,   50.,   66.,   87.,  124.,  158.,\n",
       "         120.,   72.,   20.]),\n",
       " array([ 0.17687296,  0.20330537,  0.22973778,  0.25617019,  0.28260261,\n",
       "         0.30903502,  0.33546743,  0.36189984,  0.38833225,  0.41476467,\n",
       "         0.44119708,  0.46762949,  0.4940619 ,  0.52049431,  0.54692672,\n",
       "         0.57335914,  0.59979155,  0.62622396,  0.65265637,  0.67908878,\n",
       "         0.7055212 ,  0.73195361,  0.75838602,  0.78481843,  0.81125084,\n",
       "         0.83768326,  0.86411567,  0.89054808,  0.91698049,  0.9434129 ,\n",
       "         0.96984532]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIwx8SeqI/w9LcgD3BgP1AwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f499139d510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(R,bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rscript cmap_scoring_function.R --inf_ds prediction_ff.csv \\\n",
    "     --truth_ds truth.csv \\\n",
    "     --reference_scores refScores.csv \\\n",
    "     --out here\n",
    "\n",
    "\n",
    "java ConnectivityMap prediction_ff.csv truth.csv refScores.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "landmarkpath='/home/peter/Data/CMAP/test/testData.csv'\n",
    "data = pd.read_csv(landmarkpath, header=None, dtype=np.float32)\n",
    "landmark = data.as_matrix()\n",
    "\n",
    "\n",
    "def normalize_data(landmark, mean_landmark, std_landmark, num_samples):\n",
    "    landmark = (landmark - mean_landmark)/std_landmark\n",
    "    landmark = landmark.transpose([1,0])\n",
    "    return landmark\n",
    "\n",
    "mean_landmark = np.mean(landmark)\n",
    "std_landmark = np.std(landmark)\n",
    "landmark = normalize_data(landmark, mean_landmark, std_landmark, landmark.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "best_path = '/home/peter/Data/CMAP/Results/highway_corr2epoch_3.pickle'\n",
    "prediction = model_prediction(best_path, landmark, mean_landmark, std_landmark)\n",
    "\n",
    "filename = 'submission2.csv'\n",
    "df2 = pd.DataFrame(prediction)\n",
    "df2.to_csv('/home/peter/Data/CMAP/test/'+filename, header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
