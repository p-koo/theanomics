{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, gzip\n",
    "import cPickle as pickle\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1004)   # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy import stats\n",
    "from lasagne import layers, nonlinearities, updates, objectives, init, regularization\n",
    "from lasagne.layers import get_output, get_output_shape, get_all_params\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "\n",
    "from six.moves import cPickle\n",
    "\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "import lasagne as nn\n",
    "from lasagne import layers, init, nonlinearities, utils, regularization, objectives, updates\n",
    "from lasagne.layers.base import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BatchNormLayer(Layer):\n",
    "    def __init__(self, incoming, axes='auto', epsilon=1e-4, alpha=0.1,\n",
    "                 beta=init.Constant(0), gamma=init.Constant(1),\n",
    "                 mean=init.Constant(0), inv_std=init.Constant(1), **kwargs):\n",
    "        super(BatchNormLayer, self).__init__(incoming, **kwargs)\n",
    "\n",
    "        if axes == 'auto':\n",
    "            # default: normalize over all but the second axis\n",
    "            axes = (0,) + tuple(range(2, len(self.input_shape)))\n",
    "        elif isinstance(axes, int):\n",
    "            axes = (axes,)\n",
    "        self.axes = axes\n",
    "\n",
    "        self.epsilon = utils.floatX(epsilon)\n",
    "        self.alpha = utils.floatX(alpha)\n",
    "\n",
    "        # create parameters, ignoring all dimensions in axes\n",
    "        shape = [size for axis, size in enumerate(self.input_shape)\n",
    "                 if axis not in self.axes]\n",
    "        if any(size is None for size in shape):\n",
    "            raise ValueError(\"BatchNormLayer needs specified input sizes for \"\n",
    "                             \"all axes not normalized over.\")\n",
    "        if beta is None:\n",
    "            self.beta = None\n",
    "        else:\n",
    "            self.beta = self.add_param(beta, shape, 'beta',\n",
    "                                       trainable=True, regularizable=False)\n",
    "        if gamma is None:\n",
    "            self.gamma = None\n",
    "        else:\n",
    "            self.gamma = self.add_param(gamma, shape, 'gamma',\n",
    "                                        trainable=True, regularizable=False)\n",
    "        self.mean = self.add_param(mean, shape, 'mean',\n",
    "                                   trainable=False, regularizable=False)\n",
    "        self.inv_std = self.add_param(inv_std, shape, 'inv_std',\n",
    "                                      trainable=False, regularizable=False)\n",
    "\n",
    "        self.beta = T.cast(self.beta, dtype='floatX')\n",
    "        self.gamma = T.cast(self.gamma, dtype='floatX')\n",
    "        self.mean = T.cast(self.mean, dtype='floatX')\n",
    "        self.inv_std = T.cast(self.inv_std, dtype='floatX')\n",
    "\n",
    "    def get_output_for(self, input, deterministic=False,\n",
    "                       batch_norm_use_averages=None,\n",
    "                       batch_norm_update_averages=None, **kwargs):\n",
    "        input_mean = input.mean(self.axes)\n",
    "        input_inv_std = T.inv(T.sqrt(input.var(self.axes) + self.epsilon))\n",
    "\n",
    "        # Decide whether to use the stored averages or mini-batch statistics\n",
    "        if batch_norm_use_averages is None:\n",
    "            batch_norm_use_averages = deterministic\n",
    "        use_averages = batch_norm_use_averages\n",
    "\n",
    "        if use_averages:\n",
    "            mean = self.mean\n",
    "            inv_std = self.inv_std\n",
    "        else:\n",
    "            mean = input_mean\n",
    "            inv_std = input_inv_std\n",
    "\n",
    "        # Decide whether to update the stored averages\n",
    "        if batch_norm_update_averages is None:\n",
    "            batch_norm_update_averages = not deterministic\n",
    "        update_averages = batch_norm_update_averages\n",
    "\n",
    "        if update_averages:\n",
    "            # Trick: To update the stored statistics, we create memory-aliased\n",
    "            # clones of the stored statistics:\n",
    "            running_mean = theano.clone(self.mean, share_inputs=False)\n",
    "            running_inv_std = theano.clone(self.inv_std, share_inputs=False)\n",
    "            # set a default update for them:\n",
    "            running_mean.default_update = ((1 - self.alpha) * running_mean +\n",
    "                                           self.alpha * input_mean)\n",
    "            running_inv_std.default_update = ((1 - self.alpha) *\n",
    "                                              running_inv_std +\n",
    "                                              self.alpha * input_inv_std)\n",
    "            # and make sure they end up in the graph without participating in\n",
    "            # the computation (this way their default_update will be collected\n",
    "            # and applied, but the computation will be optimized away):\n",
    "            mean += 0 * running_mean\n",
    "            inv_std += 0 * running_inv_std\n",
    "\n",
    "        # prepare dimshuffle pattern inserting broadcastable axes as needed\n",
    "        param_axes = iter(range(input.ndim - len(self.axes)))\n",
    "        pattern = ['x' if input_axis in self.axes\n",
    "                   else next(param_axes)\n",
    "                   for input_axis in range(input.ndim)]\n",
    "\n",
    "        # apply dimshuffle pattern to all parameters\n",
    "        beta = 0 if self.beta is None else self.beta.dimshuffle(pattern)\n",
    "        gamma = 1 if self.gamma is None else self.gamma.dimshuffle(pattern)\n",
    "        mean = mean.dimshuffle(pattern)\n",
    "        inv_std = inv_std.dimshuffle(pattern)\n",
    "\n",
    "        # normalize\n",
    "        normalized = (input - mean) * (gamma * inv_std) + beta\n",
    "        return normalized\n",
    "\n",
    "class GaussianSampleLayer(layers.MergeLayer):\n",
    "    def __init__(self, incoming_mu, incoming_logsigma, **kwargs):\n",
    "        super(GaussianSampleLayer, self).__init__(incomings=[incoming_mu, incoming_logsigma], **kwargs)\n",
    "        self.srng = RandomStreams(seed=234)\n",
    "\n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        return input_shapes[0]\n",
    "\n",
    "    def get_output_for(self, inputs, deterministic=False, **kwargs):\n",
    "        mu, logsigma = inputs\n",
    "        shape=(self.input_shapes[0][0] or inputs[0].shape[0],\n",
    "                self.input_shapes[0][1] or inputs[0].shape[1])\n",
    "        if deterministic:\n",
    "            return mu\n",
    "        return mu + T.exp(logsigma) * self.srng.normal(shape, avg=0.0, std=1).astype(theano.config.floatX)\n",
    "\n",
    "\n",
    "def vae_model(input_var):\n",
    "    net = {}\n",
    "    net['input'] = layers.InputLayer(shape=(None, 970), input_var=input_var)\n",
    "\n",
    "    # encode layer 1\n",
    "    net['encode1'] = layers.DenseLayer(net['input'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=None)\n",
    "    net['encode1_norm'] = BatchNormLayer(net['encode1'])\n",
    "    net['encode1_active'] = layers.NonlinearityLayer(net['encode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "    net['encode1_dropout'] = layers.DropoutLayer(net['encode1_active'],p=0.5)\n",
    "\n",
    "    # encode layer\n",
    "    net['Z_mu'] = layers.DenseLayer(net['encode1_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    \n",
    "    net['Z_logsigma'] = layers.DenseLayer(net['encode1_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    net['Z'] = GaussianSampleLayer(net['Z_mu'], net['Z_logsigma'])\n",
    "\n",
    "    # encode layer 1\n",
    "    net['decode1'] = layers.DenseLayer(net['Z'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=None)\n",
    "    net['decode1_norm'] = BatchNormLayer(net['decode1'])\n",
    "    net['decode1_active'] = layers.NonlinearityLayer(net['decode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "    net['decode1_dropout'] = layers.DropoutLayer(net['decode1_active'],p=0.5)\n",
    "\n",
    "\n",
    "    # encode layer\n",
    "    net['X_mu'] = layers.DenseLayer(net['decode1_dropout'], num_units=970, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    net['X_logsigma'] = layers.DenseLayer(net['decode1_dropout'], num_units=970, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    net['X'] = GaussianSampleLayer(net['X_mu'], net['X_logsigma'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_prediction(best_path, landmark, mean_nonlandmark, std_nonlandmark):\n",
    "    class MultiplicativeGatingLayer(nn.layers.MergeLayer):\n",
    "        \"\"\"\n",
    "        Generic layer that combines its 3 inputs t, h1, h2 as follows:\n",
    "        y = t * h1 + (1 - t) * h2\n",
    "        \"\"\"\n",
    "        def __init__(self, gate, input1, input2, **kwargs):\n",
    "            incomings = [gate, input1, input2]\n",
    "            super(MultiplicativeGatingLayer, self).__init__(incomings, **kwargs)\n",
    "            assert gate.output_shape == input1.output_shape == input2.output_shape\n",
    "\n",
    "        def get_output_shape_for(self, input_shapes):\n",
    "            return input_shapes[0]\n",
    "\n",
    "        def get_output_for(self, inputs, **kwargs):\n",
    "            return inputs[0] * inputs[1] + (1 - inputs[0]) * inputs[2]\n",
    "    def mlp_model(input_var):\n",
    "        net = {}\n",
    "        net['input'] = layers.InputLayer(shape=(None, 970), input_var=input_var)\n",
    "\n",
    "        # encode layer 1\n",
    "        net['encode1'] = layers.DenseLayer(net['input'], num_units=1000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode1_norm'] = BatchNormLayer(net['encode1'])\n",
    "        net['encode1_active'] = layers.NonlinearityLayer(net['encode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode1_dropout'] = layers.DropoutLayer(net['encode1_active'],p=0.5)\n",
    "\n",
    "        # encode layer 2\n",
    "        net['encode2'] = layers.DenseLayer(net['encode1_dropout'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode2_norm'] = BatchNormLayer(net['encode2'])\n",
    "        net['encode2_active'] = layers.NonlinearityLayer(net['encode2_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode2_dropout'] = layers.DropoutLayer(net['encode2_active'],p=0.5)\n",
    "\n",
    "        # encode layer\n",
    "        net['output'] = layers.DenseLayer(net['encode2_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "        return net\n",
    "    def dae_model(input_var):\n",
    "        net = {}\n",
    "        net['input'] = layers.InputLayer(shape=(None, 970), input_var=input_var)\n",
    "\n",
    "        # encode layer 1\n",
    "        net['encode1'] = layers.DenseLayer(net['input'], num_units=1000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode1_norm'] = BatchNormLayer(net['encode1'])\n",
    "        net['encode1_active'] = layers.NonlinearityLayer(net['encode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode1_dropout'] = layers.DropoutLayer(net['encode1_active'],p=0.5)\n",
    "\n",
    "        # encode layer 2\n",
    "        net['encode2'] = layers.DenseLayer(net['encode1_dropout'], num_units=2000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode2_norm'] = BatchNormLayer(net['encode2'])\n",
    "        net['encode2_active'] = layers.NonlinearityLayer(net['encode2_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode2_dropout'] = layers.DropoutLayer(net['encode2_active'],p=0.5)\n",
    "\n",
    "        # encode layer 2\n",
    "        net['encode3'] = layers.DenseLayer(net['encode2_dropout'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode3_norm'] = BatchNormLayer(net['encode3'])\n",
    "        net['encode3_active'] = layers.NonlinearityLayer(net['encode3_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode3_dropout'] = layers.DropoutLayer(net['encode3_active'],p=0.5)\n",
    "\n",
    "        # encode layer\n",
    "        net['encode'] = layers.DenseLayer(net['encode3_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['output'] = layers.NonlinearityLayer(net['encode'], nonlinearity=nonlinearities.linear)\n",
    "        return net\n",
    "\n",
    "    def highway_dense(incoming, Wh=init.Orthogonal(), bh=init.Constant(0.0),\n",
    "                      Wt=init.Orthogonal(), bt=init.Constant(-4.0),\n",
    "                      nonlinearity=nonlinearities.rectify, **kwargs):\n",
    "        num_inputs = int(np.prod(incoming.output_shape[1:]))\n",
    "        # regular layer\n",
    "        l_h = layers.DenseLayer(incoming, num_units=num_inputs, W=Wh, b=bh,\n",
    "                                   nonlinearity=nonlinearity)\n",
    "        # gate layer\n",
    "        l_t = layers.DenseLayer(incoming, num_units=num_inputs, W=Wt, b=bt,\n",
    "                                   nonlinearity=T.nnet.sigmoid)\n",
    "\n",
    "        return MultiplicativeGatingLayer(gate=l_t, input1=l_h, input2=incoming)\n",
    "\n",
    "    def build_model(input_var, batch_size=100,\n",
    "                    num_hidden_units=500, num_hidden_layers=50):\n",
    "\n",
    "        l_in = layers.InputLayer(shape=(batch_size, 970), input_var=input_var)\n",
    "\n",
    "        # first, project it down to the desired number of units per layer\n",
    "        l_hidden1 = layers.DenseLayer(l_in, num_units=num_hidden_units)\n",
    "\n",
    "        # then stack highway layers on top of this\n",
    "        l_current = l_hidden1\n",
    "        for k in range(num_hidden_layers - 1):\n",
    "            l_current = highway_dense(l_current)\n",
    "\n",
    "\n",
    "        l_hidden2 = layers.DenseLayer(l_current, num_units=2000)\n",
    "\n",
    "        # finally add an output layer\n",
    "        l_out = layers.DenseLayer( l_hidden2, num_units=11350, nonlinearity=nonlinearities.linear)\n",
    "\n",
    "        return l_out\n",
    "\n",
    "\n",
    "    # setup model\n",
    "    input_var = T.dmatrix('landmark')\n",
    "    #network = build_model(input_var, batch_size=100, num_hidden_units=500, num_hidden_layers=50)\n",
    "    #network = build_model(input_var)\n",
    "    network = mlp_model(input_var)\n",
    "    \n",
    "    f = open(best_path, 'rb')\n",
    "    best_parameters = cPickle.load(f)\n",
    "    f.close()\n",
    "    layers.set_all_param_values(network['output'], best_parameters)\n",
    "\n",
    "\n",
    "    prediction = layers.get_output(network['output'], deterministic=True)\n",
    "\n",
    "    get_prediction = theano.function([input_var], prediction, allow_input_downcast=True)\n",
    "    prediction = get_prediction(landmark)\n",
    "\n",
    "    prediction = prediction.transpose([1,0]).astype(np.float64)\n",
    "    num_samples = prediction.shape[1]\n",
    "    prediction = (prediction*np.outer(std_nonlandmark,np.ones(num_samples))) + np.outer(mean_nonlandmark,np.ones(num_samples))\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970, 1000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "savepath='/home/peter/Data/CMAP/data_set_norm.hd5f'\n",
    "trainmat = h5py.File(savepath, 'r')\n",
    "mean_landmark = np.array(trainmat['mean_landmark']).astype(np.float32)\n",
    "std_landmark = np.array(trainmat['std_landmark']).astype(np.float32)\n",
    "mean_nonlandmark = np.array(trainmat['mean_nonlandmark']).astype(np.float32)\n",
    "std_nonlandmark = np.array(trainmat['std_nonlandmark']).astype(np.float32)\n",
    "\n",
    "\n",
    "landmarkpath='/home/peter/Data/CMAP/test/landmarks.csv'\n",
    "data = pd.read_csv(landmarkpath, header=None, dtype=np.float32)\n",
    "landmark = data.as_matrix()\n",
    "\n",
    "nonlandmarkpath='/home/peter/Data/CMAP/test/truth.csv'\n",
    "data = pd.read_csv(nonlandmarkpath, header=None, dtype=np.float32)\n",
    "nonlandmark = data.as_matrix()\n",
    "\n",
    "def normalize_data(landmark, mean_landmark, std_landmark, num_samples):\n",
    "    landmark = (landmark - np.outer(mean_landmark,np.ones(num_samples)))/np.outer(std_landmark,np.ones(num_samples))\n",
    "    landmark = landmark.transpose([1,0])\n",
    "    return landmark\n",
    "print landmark.shape\n",
    "landmark = normalize_data(landmark, np.mean(landmark,axis=1), np.std(landmark,axis=1), landmark.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_path = '/home/peter/Data/CMAP/Results/2hidden2_epoch_17.pickle'\n",
    "prediction = model_prediction(best_path, landmark, mean_nonlandmark, std_nonlandmark)\n",
    "\n",
    "df2 = pd.DataFrame(prediction)\n",
    "df2.to_csv('/home/peter/Data/CMAP/test/prediction_ff.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75354709169183554"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/home/peter/Data/CMAP/test/prediction_ff.csv'\n",
    "data = pd.read_csv(path, header=None, dtype=np.float32)\n",
    "test = data.as_matrix()\n",
    "test.shape\n",
    "\n",
    "nonlandmarkpath='/home/peter/Data/CMAP/test/truth.csv'\n",
    "data = pd.read_csv(nonlandmarkpath, header=None, dtype=np.float32)\n",
    "truth = data.as_matrix()\n",
    "truth.shape\n",
    "\n",
    "R = []\n",
    "for i in range(prediction.shape[1]):\n",
    "    R.append(stats.spearmanr(prediction[i,:], truth[i,:])[0])\n",
    "np.mean(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2.,    1.,    3.,    5.,   12.,    7.,    5.,   17.,   16.,\n",
       "          15.,   14.,   12.,   25.,   18.,   15.,   24.,   28.,   16.,\n",
       "          32.,   31.,   35.,   49.,   76.,   74.,  108.,  120.,   97.,\n",
       "          86.,   36.,   21.]),\n",
       " array([ 0.29638048,  0.3176928 ,  0.33900513,  0.36031746,  0.38162978,\n",
       "         0.40294211,  0.42425443,  0.44556676,  0.46687908,  0.48819141,\n",
       "         0.50950373,  0.53081606,  0.55212838,  0.57344071,  0.59475304,\n",
       "         0.61606536,  0.63737769,  0.65869001,  0.68000234,  0.70131466,\n",
       "         0.72262699,  0.74393931,  0.76525164,  0.78656396,  0.80787629,\n",
       "         0.82918862,  0.85050094,  0.87181327,  0.89312559,  0.91443792,\n",
       "         0.93575024]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83afa71d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(R,bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rscript cmap_scoring_function.R --inf_ds prediction_ff.csv \\\n",
    "     --truth_ds truth.csv \\\n",
    "     --reference_scores refScores.csv \\\n",
    "     --out here\n",
    "\n",
    "\n",
    "java ConnectivityMap prediction_ff.csv truth.csv refScores.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savepath='/home/peter/Data/CMAP/data_set_norm.hd5f'\n",
    "trainmat = h5py.File(savepath, 'r')\n",
    "mean_landmark = np.array(trainmat['mean_landmark']).astype(np.float32)\n",
    "std_landmark = np.array(trainmat['std_landmark']).astype(np.float32)\n",
    "mean_nonlandmark = np.array(trainmat['mean_nonlandmark']).astype(np.float32)\n",
    "std_nonlandmark = np.array(trainmat['std_nonlandmark']).astype(np.float32)\n",
    "\n",
    "landmarkpath='/home/peter/Data/CMAP/test/testData.csv'\n",
    "data = pd.read_csv(landmarkpath, header=None, dtype=np.float32)\n",
    "landmark = data.as_matrix()\n",
    "\n",
    "def normalize_data(landmark, mean_landmark, std_landmark, num_samples):\n",
    "    landmark = (landmark - np.outer(mean_landmark,np.ones(num_samples)))/np.outer(std_landmark,np.ones(num_samples))\n",
    "    landmark = landmark.transpose([1,0])\n",
    "    return landmark\n",
    "\n",
    "landmark = normalize_data(landmark, np.mean(landmark,axis=1), np.std(landmark,axis=1), landmark.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "best_path = '/home/peter/Data/CMAP/Results/2hidden2_epoch_17.pickle'\n",
    "prediction = model_prediction(best_path, landmark, mean_nonlandmark, std_nonlandmark)\n",
    "\n",
    "filename = 'submission17.csv'\n",
    "df2 = pd.DataFrame(prediction)\n",
    "df2.to_csv('/home/peter/Data/CMAP/test/'+filename, header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
