{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import os, sys, gzip\n",
    "import cPickle as pickle\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1004)   # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "import pandas as pd\n",
    "from lasagne import layers, nonlinearities, updates, objectives, init \n",
    "from lasagne.layers import get_output, get_output_shape, get_all_params\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "#from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datapath='/media/peter/storage/data/geneexpression/Network_1/Network_1_Configuration_9_knockouts.tsv'\n",
    "df = pd.read_csv(datapath, delimiter='\\t')\n",
    "knockouts = df.as_matrix()\n",
    "\n",
    "datapath='/media/peter/storage/data/geneexpression/Network_1/Network_1_Configuration_9_wildtype.tsv'\n",
    "df = pd.read_csv(datapath, delimiter='\\t')\n",
    "wildtype = df.as_matrix()\n",
    "\n",
    "genes = np.vstack([wildtype[:,0:-1], knockouts[:,0:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_data, num_genes = genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_train = 4000\n",
    "indices = np.arange(num_data)\n",
    "np.random.shuffle(indices)\n",
    "X_train = genes[indices[:num_train],:]\n",
    "X_valid = genes[indices[num_train:],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VariationalSampleLayer(layers.MergeLayer):\n",
    "    def __init__(self, incoming_mu, incoming_logsigma, **kwargs):\n",
    "        super(VariationalSampleLayer, self).__init__(incomings=[incoming_mu, incoming_logsigma], **kwargs)\n",
    "        self.srng = RandomStreams(seed=234)\n",
    "\n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        return input_shapes[0]\n",
    "\n",
    "    def get_output_for(self, inputs, deterministic=False, **kwargs):\n",
    "        mu, logsigma = inputs\n",
    "        shape=(self.input_shapes[0][0] or inputs[0].shape[0],\n",
    "                self.input_shapes[0][1] or inputs[0].shape[1])\n",
    "        if deterministic:\n",
    "            return mu\n",
    "        return mu + T.exp(logsigma) * self.srng.normal(shape, avg=0.0, std=1).astype(theano.config.floatX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_units1=1000\n",
    "num_units2 = 500\n",
    "num_encode=20\n",
    "\n",
    "\n",
    "input_var = T.dmatrix('inputs')\n",
    "shape = (None, num_genes)\n",
    "net = {}\n",
    "net['input'] = layers.InputLayer(shape=shape, input_var=input_var)\n",
    "net['encode1'] = layers.DenseLayer(net['input'], num_units=num_units1, W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=nonlinearities.softplus)\n",
    "net['encode2'] = layers.DenseLayer(net['encode1'], num_units=num_units2, W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=nonlinearities.softplus)\n",
    "net['encode_mu'] = layers.DenseLayer(net['encode2'], num_units=num_encode, W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=nonlinearities.linear)\n",
    "net['encode_logsigma'] = layers.DenseLayer(net['encode2'], num_units=num_encode, W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=nonlinearities.linear)\n",
    "net['Z'] = VariationalSampleLayer(net['encode_mu'], net['encode_logsigma'])\n",
    "\n",
    "net['decode1'] = layers.DenseLayer(net['Z'], num_units=num_units2, W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=nonlinearities.softplus)\n",
    "net['decode2'] = layers.DenseLayer(net['decode1'], num_units=num_units1, W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=nonlinearities.softplus)\n",
    "net['X'] = layers.DenseLayer(net['decode2'], num_units=num_genes,  W=init.GlorotUniform(), \n",
    "                                  b=init.Constant(.0), nonlinearity=nonlinearities.sigmoid)\n",
    "#net['decode_logsigma'] = layers.DenseLayer(net['decode2'], num_units=x_dim, nonlinearity=nonlinearities.linear)\n",
    "#net['X'] = VariationalSampleLayer(net['decode_mu'], net['decode_logsigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(net, target_var, deterministic):\n",
    "    \n",
    "    z_mu = get_output(net['encode_mu'], deterministic=deterministic)\n",
    "    z_logsigma = get_output(net['encode_logsigma'], deterministic=deterministic)\n",
    "    x_mu = get_output(net['X'], deterministic=deterministic)\n",
    "    x_mu = T.clip(x_mu, 1e-7, 1-1e-7)\n",
    "    x_logsigma = T.log(T.sqrt(x_mu*(1-x_mu)))\n",
    "    kl_divergence = 0.5*T.sum(1 + 2*z_logsigma - T.sqr(z_mu) - T.exp(2*z_logsigma), axis=1)\n",
    "    log_likelihood = T.sum(-0.5*T.log(2*np.float32(np.pi))- x_logsigma - 0.5*T.sqr(target_var-x_mu)/T.exp(2*x_logsigma),axis=1)\n",
    "    variational_lower_bound = -log_likelihood - kl_divergence\n",
    "    prediction = x_mu\n",
    "    return variational_lower_bound.mean()\n",
    "train_loss = build_loss(net, input_var, deterministic=False)\n",
    "test_loss = build_loss(net, input_var, deterministic=True)\n",
    "\n",
    "# ADAM updates\n",
    "params = get_all_params(net['X'], trainable=True)\n",
    "update_op = updates.adam(train_loss, params, learning_rate=1e-3)\n",
    "train_fun = theano.function([input_var], train_loss , updates=update_op)\n",
    "valid_fun = theano.function([input_var], test_loss)\n",
    "\n",
    "def batch_generator(X, batch_size=128, shuffle=True):\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(X)-batch_size+1, batch_size):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx+batch_size]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx+batch_size)\n",
    "        yield X[excerpt].astype(np.float32)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 60\n",
      "  training loss:\t\t973.463435\n",
      "  validation loss:\t\t743.341968\n",
      "Epoch 2 of 60\n",
      "  training loss:\t\t704.919015\n",
      "  validation loss:\t\t714.051122\n",
      "Epoch 3 of 60\n",
      "  training loss:\t\t837.803673\n",
      "  validation loss:\t\t681.909363\n",
      "Epoch 4 of 60\n",
      "  training loss:\t\t683.400683\n",
      "  validation loss:\t\t720.202736\n",
      "Epoch 5 of 60\n",
      "  training loss:\t\t674.629131\n",
      "  validation loss:\t\t688.601350\n",
      "Epoch 6 of 60\n",
      "  training loss:\t\t667.905179\n",
      "  validation loss:\t\t691.479349\n",
      "Epoch 7 of 60\n",
      "  training loss:\t\t668.496330\n",
      "  validation loss:\t\t675.682626\n",
      "Epoch 8 of 60\n",
      "  training loss:\t\t669.071701\n",
      "  validation loss:\t\t690.728518\n",
      "Epoch 9 of 60\n",
      "  training loss:\t\t667.141443\n",
      "  validation loss:\t\t682.124462\n",
      "Epoch 10 of 60\n",
      "  training loss:\t\t666.449878\n",
      "  validation loss:\t\t696.147109\n",
      "Epoch 11 of 60\n",
      "  training loss:\t\t666.970032\n",
      "  validation loss:\t\t675.412615\n",
      "Epoch 12 of 60\n",
      "  training loss:\t\t667.482353\n",
      "  validation loss:\t\t692.836424\n",
      "Epoch 13 of 60\n",
      "  training loss:\t\t665.307615\n",
      "  validation loss:\t\t685.476601\n",
      "Epoch 14 of 60\n",
      "  training loss:\t\t665.519221\n",
      "  validation loss:\t\t684.830651\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d5954dac0b91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_train_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 60\n",
    "batch_size = 64\n",
    "num_train_batches = X_train.shape[0] // batch_size\n",
    "num_valid_batches = X_valid.shape[0] // batch_size\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    train_batches = batch_generator(X_train, batch_size, shuffle=True)\n",
    "    valid_batches = batch_generator(X_valid, batch_size, shuffle=False)\n",
    "\n",
    "    train_loss = 0\n",
    "    for index in range(num_train_batches):\n",
    "        loss = train_fun(next(train_batches))\n",
    "        train_loss += loss\n",
    "        \n",
    "    valid_loss = 0\n",
    "    for index in range(num_valid_batches):\n",
    "        loss = valid_fun(next(valid_batches))\n",
    "        valid_loss += loss\n",
    "\n",
    "    print(\"Epoch {} of {}\".format(epoch+1, num_epochs))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_loss/num_train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(valid_loss/num_valid_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def statistics(net, target_var):\n",
    "    z_mu = get_output(net['encode_mu'], deterministic=True)\n",
    "    z_logsigma = get_output(net['encode_logsigma'], deterministic=True)\n",
    "    x_mu = get_output(net['X'], deterministic=True)\n",
    "    x_mu = T.clip(x_mu, 1e-7, 1-1e-7)\n",
    "    x_logsigma = T.log(T.sqrt(x_mu*(1-x_mu)))\n",
    "    kl_divergence = 0.5*(1 + 2*z_logsigma - T.sqr(z_mu) - T.exp(2*z_logsigma))\n",
    "    log_likelihood = -0.5*T.log(2*np.float32(np.pi))- x_logsigma - 0.5*T.sqr(target_var-x_mu)/T.exp(2*x_logsigma)\n",
    "    return kl_divergence, log_likelihood\n",
    "kl_divergence, log_likelihood = statistics(net, input_var)\n",
    "\n",
    "statistics_fun = theano.function([input_var],[kl_divergence, log_likelihood])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "num_test_batches = X_valid.shape[0] // batch_size\n",
    "test_batches = batch_generator(X_valid, batch_size, shuffle=False)\n",
    "\n",
    "kldiv = []\n",
    "logL = []\n",
    "for index in range(num_test_batches):\n",
    "    stats = statistics_fun(next(test_batches))\n",
    "    kldiv.append(stats[0])\n",
    "    logL.append(stats[1])\n",
    "\n",
    "kldiv = np.array(kldiv).reshape([-1,stats[0].shape[1]])\n",
    "logL = np.array(logL).reshape([-1,stats[1].shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEfCAYAAABmsjC7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBYqIiETi/wObTMwD0DXB3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabe87e6b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure\n",
    "plt.errorbar(range(num_encode),-np.mean(kldiv,axis=0),np.std(kldiv,axis=0), fmt='o', markersize=12)\n",
    "plt.xlim([-.3, num_encode-.7])\n",
    "plt.xlabel('z', fontsize=18)\n",
    "plt.ylabel('-KLD', fontsize=18)\n",
    "#plt.yticks([0, 1, 2, 3], fontsize = 18)\n",
    "plt.xticks(fontsize = 18)\n",
    "plt.savefig('Genes_vae_kldivergence_'+ str(num_encode) +'.eps', format='eps', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
