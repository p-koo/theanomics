{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "#/bin/python\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from src import NeuralNet\n",
    "from src import train as fit\n",
    "from src import make_directory \n",
    "from models import load_model\n",
    "from data import load_data\n",
    "from six.moves import cPickle\n",
    "np.random.seed(247) # for reproducibility\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne import layers, objectives, updates, regularization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = 'MotifSimulation_correlated'\n",
    "datapath = '/home/peter/Data/SequenceMotif'\n",
    "filepath = os.path.join(datapath, 'synthetic_correlated_motifs_100000.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, valid, test = load_data(name, filepath)\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = np.round(train[1].shape[1])\n",
    "\n",
    "# calculate correlations\n",
    "labels = np.vstack([train[1], valid[1]])\n",
    "N = labels.shape[0]\n",
    "rho = np.zeros((num_labels, num_labels))\n",
    "for i in range(num_labels):\n",
    "    p_i = np.sum(labels[:,i])/N\n",
    "    for j in range(i):\n",
    "        p_j = np.sum(labels[:,j])/N    \n",
    "        p_ij = np.sum(labels[:,i]*labels[:,j])/N\n",
    "        norm = np.sqrt(p_i*(1-p_i)) * np.sqrt(p_j*(1-p_j))\n",
    "        rho[i,j] = (p_ij - p_i*p_j)/norm\n",
    "f = open('/home/peter/Code/Deepomics/examples/rho.pickle','wb')\n",
    "cPickle.dump(rho, f)\n",
    "f.close()\n",
    "\n",
    "plt.imshow(optimization[\"rho\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"binary_genome_motif_model\"\n",
    "network, input_var, target_var, optimization = load_model(model_name, shape, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_loss(prediction, target_var, optimization):\n",
    "    loss = -(target_var*T.log(prediction) + (1.0-target_var)*T.log(1.0-prediction))\n",
    "    \n",
    "    prediction = T.clip(prediction, 1e-7, 1-1e-7)\n",
    "    u = (target_var - prediction)/T.sqrt(prediction*(1-prediction))\n",
    "    diag = T.diag(T.dot(optimization[\"rho\"], u.T).dot(u))\n",
    "    loss += T.log(1+T.sum(diag[1:]))\n",
    "    return loss.mean(), diag, u\n",
    "\n",
    "\n",
    "# build loss function\n",
    "prediction = layers.get_output(network['output'], deterministic=False)\n",
    "loss, diag, u = build_loss(target_var, prediction, optimization)\n",
    "\n",
    "# calculate and clip gradients\n",
    "params = layers.get_all_params(network['output'], trainable=True)    \n",
    "grad = T.grad(loss, params)\n",
    "\n",
    "# setup parameter updates\n",
    "update_op = updates.adam(grad, params, \n",
    "                        learning_rate=optimization['learning_rate'], \n",
    "                        beta1=optimization['beta1'], \n",
    "                        beta2=optimization['beta2'], \n",
    "                        epsilon=optimization['epsilon'])\n",
    "\n",
    "# test/validation set \n",
    "test_prediction = layers.get_output(network['output'], deterministic=True)\n",
    "test_loss, diag2, u2 = build_loss(target_var, test_prediction, optimization)\n",
    "\n",
    "# create theano function\n",
    "train_fun = theano.function([input_var, target_var], [loss, prediction, diag, u, grad], updates=update_op)\n",
    "test_fun = theano.function([input_var, target_var], [test_loss, test_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_generator(X, y, batch_size=128, shuffle=True):\n",
    "    \"\"\"python generator to get a randomized minibatch\"\"\"\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        idx = np.random.choice(len(y), N)\n",
    "        yield X[idx].astype('float32'), y[idx].astype('int32')\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(X)-batch_size+1, batch_size):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx+batch_size]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx+batch_size)\n",
    "        yield X[excerpt], y[excerpt]\n",
    "        \n",
    "batch_size = 100\n",
    "num_batches = train[0].shape[0] // batch_size\n",
    "batches = batch_generator(train[0], train[1], batch_size)\n",
    "value = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n"
     ]
    }
   ],
   "source": [
    "X, y = next(batches)\n",
    "loss, prediction, diag, u = train_fun(X, y)\n",
    "print loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.830082"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = -(y*np.log(prediction) + (1.0-y)*np.log(1.0-prediction))\n",
    "prediction = np.clip(prediction, 1e-7, 1-1e-7)\n",
    "u = (y - prediction)/np.sqrt(prediction*(1-prediction))\n",
    "diag = np.diag(np.dot(optimization[\"rho\"], u.T).dot(u))\n",
    "loss += np.log(1+np.sum(diag[1:]))\n",
    "loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "loss = objectives.aggregate(loss, mode='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
