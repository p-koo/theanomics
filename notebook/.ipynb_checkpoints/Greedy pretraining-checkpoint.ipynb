{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os, sys, urllib, gzip, matplotlib\n",
    "sys.setrecursionlimit(10000)\n",
    "%matplotlib inline\n",
    "matplotlib.use('Agg') # Change matplotlib backend, in case we have no X server running..\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import Image as IPImage\n",
    "from PIL import Image\n",
    "\n",
    "import cPickle as pickle\n",
    "\n",
    "from lasagne import layers\n",
    "from lasagne.layers import get_output, get_output_shape, get_all_layers, get_all_params\n",
    "from lasagne.layers import get_all_param_values, set_all_param_values\n",
    "from lasagne import nonlinearities\n",
    "from lasagne import updates \n",
    "from lasagne import objectives \n",
    "from lasagne import init \n",
    "import theano.tensor as T\n",
    "import theano\n",
    "\n",
    "sys.path.append('..')\n",
    "from src import NeuralNet\n",
    "from src import train as fit\n",
    "from src import make_directory \n",
    "from models import load_model\n",
    "from data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "name = 'Basset' # 'DeepSea'\n",
    "datapath = '/home/peter/Data/'+name\n",
    "options = {\"class_range\": range(3)}# \n",
    "train, valid, test = load_data(name, datapath, options)\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = np.round(train[1].shape[1])\n",
    "\n",
    "\"\"\"\n",
    "name = 'MotifSimulation_binary'\n",
    "datapath = '/home/peter/Data/SequenceMotif'\n",
    "filepath = os.path.join(datapath, 'N=100000_S=200_M=10_G=20_data.pickle')\n",
    "train, valid, test = load_data(name, filepath)\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = np.round(train[1].shape[1])\n",
    "#\"\"\"\n",
    "\n",
    "def batch_generator(X, y, N):\n",
    "    while True:\n",
    "        idx = np.random.choice(len(y), N)\n",
    "        yield X[idx].astype('float32'), y[idx].astype('float32')\n",
    "\n",
    "        \n",
    "def build_network(net, input_var):\n",
    "    prediction = get_output(net['output'])\n",
    "    train_loss = objectives.squared_error(prediction, input_var)\n",
    "    train_loss = train_loss.mean()\n",
    "\n",
    "    valid_prediction = get_output(net['output'], deterministic=True)\n",
    "    valid_loss = objectives.squared_error(valid_prediction, input_var)\n",
    "    valid_loss = valid_loss.mean()\n",
    "\n",
    "    params = get_all_params(net['output'], trainable=True)\n",
    "    update_op = updates.adam(train_loss, params, learning_rate=0.001)\n",
    "\n",
    "    train_function = theano.function([input_var], train_loss, updates=update_op)\n",
    "    valid_function = theano.function([input_var], valid_loss)\n",
    "    return train_function, valid_function\n",
    "\n",
    "\n",
    "def train_model(train, train_function, valid, valid_function, batch_size, num_epochs):\n",
    "    num_train_batches = len(train[0]) // batch_size\n",
    "    train_batches = batch_generator(train[0], train[1], batch_size)\n",
    "\n",
    "    num_valid_batches = len(valid[0]) // batch_size\n",
    "    valid_batches = batch_generator(valid[0], valid[1], batch_size)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for index in range(num_train_batches):\n",
    "            X_batch, y_batch = next(train_batches)\n",
    "            train_loss = train_function(X_batch)\n",
    "        print(\"train: %f\" % train_loss)\n",
    "        \n",
    "        for index in range(num_valid_batches):\n",
    "            X_batch, y_batch = next(valid_batches)\n",
    "            valid_loss = valid_function(X_batch)\n",
    "        print(\"valid: %f\" % valid_loss)\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# greedy 1st layer\n",
    "net = {}\n",
    "net['input'] = layers.InputLayer(shape=shape, input_var=input_var, name='input')\n",
    "\n",
    "# convolutional layer\n",
    "net['conv1'] = layers.Conv2DLayer(net['input'], num_filters=200, filter_size=(8,1), W=init.GlorotUniform(), \n",
    "                             nonlinearity=None, b=None, pad='valid', name='conv1')\n",
    "net['norm1'] = layers.BatchNormLayer(net['conv1'])\n",
    "net['bias1'] = layers.BiasLayer(net['norm1'], b=init.Constant(0.05))\n",
    "net['nonlin1'] = layers.NonlinearityLayer(net['bias1'], nonlinearity=nonlinearities.rectify)\n",
    "\n",
    "net['encode'] = layers.NonlinearityLayer(net['nonlin1'], nonlinearity=None)\n",
    "\n",
    "net['deconv1'] = layers.InverseLayer(net['encode'], l_dense4, name='decode')\n",
    "net['debias1'] = layers.BiasLayer(net['deconv1'], init.Constant(0.05))\n",
    "net['output'] = layers.NonlinearityLayer(net['debias1'], nonlinearity=nonlinearities.rectify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 15\n",
    "\n",
    "input_var = T.tensor4('input')\n",
    "train_function, valid_function = build_network(net, input_var)\n",
    "train_model(train, train_function, valid, valid_function, batch_size, num_epochs):\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# greedy 2nd layer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
