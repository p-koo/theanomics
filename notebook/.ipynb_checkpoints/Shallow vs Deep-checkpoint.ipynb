{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys, gzip\n",
    "import numpy as np\n",
    "from six.moves import cPickle\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "from lasagne import layers, nonlinearities, updates, objectives, init \n",
    "from lasagne.layers import get_output, get_output_shape, get_all_params\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from lasagne.layers import Conv2DLayer, DenseLayer, InputLayer, ExpressionLayer, BiasLayer\n",
    "from lasagne.layers import NonlinearityLayer, MaxPool2DLayer, DropoutLayer, BatchNormLayer\n",
    "\n",
    "sys.path.append('..')\n",
    "from src import NeuralNet\n",
    "from src import train as fit\n",
    "from src import make_directory \n",
    "from models import load_model\n",
    "from data import load_data\n",
    "\n",
    "from subprocess import call\n",
    "\n",
    "np.random.seed(247) # for reproducibility\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "datadir = '/home/peter/Data/SequenceMotif/networkcomparison'\n",
    "savedir = make_directory(datadir, 'unlocal_deep')\n",
    "\n",
    "from tsne import bh_sne\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = 'Unlocalized_N=100000_S=200_M=50_G=20_data.pickle'\n",
    "datapath = '/home/peter/Data/SequenceMotif'\n",
    "filepath = os.path.join(datapath, filename)\n",
    "\n",
    "# load training set\n",
    "print \"loading data from: \" + filepath\n",
    "f = open(filepath, 'rb')\n",
    "print \"loading train data\"\n",
    "train = cPickle.load(f)\n",
    "print \"loading cross-validation data\"\n",
    "cross_validation = cPickle.load(f)\n",
    "print \"loading test data\"\n",
    "test = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "X_train = train[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_train = train[1].astype(np.int32)\n",
    "X_val = cross_validation[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_val = cross_validation[1].astype(np.int32)\n",
    "X_test = test[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_test = test[1].astype(np.int32)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_val = np.expand_dims(X_val, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "train = (X_train, y_train, train[2])\n",
    "valid = (X_val, y_val, cross_validation[2])\n",
    "test = (X_test, y_test, test[2])\n",
    "\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = \"test_motif_model\"\n",
    "nnmodel = NeuralNet(model_name, shape, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnmodel = fit.train_minibatch(nnmodel, train, valid, batch_size=128, num_epochs=500, \n",
    "                        patience=3, verbose=1, filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save best model --> lowest cross-validation error\n",
    "min_loss, min_index = nnmodel.get_min_loss()\n",
    "savepath = filepath + \"_epoch_\" + str(min_index) + \".pickle\"\n",
    "nnmodel.set_parameters_from_file(savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test model\n",
    "nnmodel.test_model(test, 512, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network = nnmodel.network\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def seq_logo(pwm, height=100, nt_width=20, norm=0, rna=1, filepath='.'):\n",
    "    \"\"\"generate a sequence logo from a pwm\"\"\"\n",
    "    \n",
    "    def load_alphabet(filepath, rna):\n",
    "        \"\"\"load images of nucleotide alphabet \"\"\"\n",
    "        df = pd.read_table(os.path.join(filepath, 'A.txt'), header=None);\n",
    "        A_img = df.as_matrix()\n",
    "        A_img = np.reshape(A_img, [72, 65, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        df = pd.read_table(os.path.join(filepath, 'C.txt'), header=None);\n",
    "        C_img = df.as_matrix()\n",
    "        C_img = np.reshape(C_img, [76, 64, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        df = pd.read_table(os.path.join(filepath, 'G.txt'), header=None);\n",
    "        G_img = df.as_matrix()\n",
    "        G_img = np.reshape(G_img, [76, 67, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        if rna == 1:\n",
    "            df = pd.read_table(os.path.join(filepath, 'U.txt'), header=None);\n",
    "            T_img = df.as_matrix()\n",
    "            T_img = np.reshape(T_img, [74, 57, 3], order=\"F\").astype(np.uint8)\n",
    "        else:\n",
    "            df = pd.read_table(os.path.join(filepath, 'T.txt'), header=None);\n",
    "            T_img = df.as_matrix()\n",
    "            T_img = np.reshape(T_img, [72, 59, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        return A_img, C_img, G_img, T_img\n",
    "\n",
    "\n",
    "    def get_nt_height(pwm, height, norm):\n",
    "        \"\"\"get the heights of each nucleotide\"\"\"\n",
    "\n",
    "        def entropy(p):\n",
    "            \"\"\"calculate entropy of each nucleotide\"\"\"\n",
    "            s = 0\n",
    "            for i in range(4):\n",
    "                if p[i] > 0:\n",
    "                    s -= p[i]*np.log2(p[i])\n",
    "            return s\n",
    "\n",
    "        num_nt, num_seq = pwm.shape\n",
    "        heights = np.zeros((num_nt,num_seq));\n",
    "        for i in range(num_seq):\n",
    "            if norm == 1:\n",
    "                total_height = height\n",
    "            else:\n",
    "                total_height = (np.log2(4) - entropy(pwm[:, i]))*height;\n",
    "            heights[:,i] = np.floor(pwm[:,i]*total_height);\n",
    "        return heights.astype(int)\n",
    "\n",
    "    \n",
    "    # get the alphabet images of each nucleotide\n",
    "    A_img, C_img, G_img, T_img = load_alphabet(filepath='.', rna=1)\n",
    "    \n",
    "    \n",
    "    # get the heights of each nucleotide\n",
    "    heights = get_nt_height(pwm, height, norm)\n",
    "    \n",
    "    # resize nucleotide images for each base of sequence and stack\n",
    "    num_nt, num_seq = pwm.shape\n",
    "    width = np.ceil(nt_width*num_seq).astype(int)\n",
    "    \n",
    "    total_height = np.sum(heights,axis=0)\n",
    "    max_height = np.max(total_height)\n",
    "    logo = np.ones((height*2, width, 3)).astype(int)*255;\n",
    "    for i in range(num_seq):\n",
    "        remaining_height = total_height[i];\n",
    "        offset = max_height-remaining_height\n",
    "        nt_height = np.sort(heights[:,i]);\n",
    "        index = np.argsort(heights[:,i])\n",
    "\n",
    "        for j in range(num_nt):\n",
    "            if nt_height[j] > 0:\n",
    "                # resized dimensions of image\n",
    "                resize = (nt_height[j], nt_width)\n",
    "                if index[j] == 0:\n",
    "                    nt_img = imresize(A_img, resize)\n",
    "                elif index[j] == 1:\n",
    "                    nt_img = imresize(C_img, resize)\n",
    "                elif index[j] == 2:\n",
    "                    nt_img = imresize(G_img, resize)\n",
    "                elif index[j] == 3:\n",
    "                    nt_img = imresize(T_img, resize)\n",
    "\n",
    "                # determine location of image\n",
    "                height_range = range(remaining_height-nt_height[j], remaining_height)\n",
    "                width_range = range(i*nt_width, i*nt_width+nt_width)\n",
    "\n",
    "                # 'annoying' way to broadcast resized nucleotide image\n",
    "                if height_range:\n",
    "                    for k in range(3):\n",
    "                        for m in range(len(width_range)):\n",
    "                            logo[height_range+offset, width_range[m],k] = nt_img[:,m,k];\n",
    "\n",
    "                remaining_height -= nt_height[j]\n",
    "\n",
    "    return logo.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fig_options(plt, options):\n",
    "    if 'figsize' in options:\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(options['figsize'][0], options['figsize'][1], forward=True)\n",
    "    if 'ylim' in options:\n",
    "        plt.ylim(options['ylim'][0],options['ylim'][1])\n",
    "    if 'yticks' in options:\n",
    "        plt.yticks(options['yticks'])\n",
    "    if 'xticks' in options:\n",
    "        plt.xticks(options['xticks'])\n",
    "    if 'labelsize' in options:        \n",
    "        ax = plt.gca()\n",
    "        ax.tick_params(axis='x', labelsize=options['labelsize'])\n",
    "        ax.tick_params(axis='y', labelsize=options['labelsize'])\n",
    "    if 'axis' in options:\n",
    "        plt.axis(options['axis'])\n",
    "    if 'xlabel' in options:\n",
    "        plt.xlabel(options['xlabel'], fontsize=options['fontsize'])\n",
    "    if 'ylabel' in options:\n",
    "        plt.ylabel(options['ylabel'], fontsize=options['fontsize'])\n",
    "    if 'linewidth' in options:\n",
    "        plt.rc('axes', linewidth=options['linewidth'])\n",
    "        \n",
    "\n",
    "def subplot_grid(nrows, ncols):\n",
    "    grid= mpl.gridspec.GridSpec(nrows, ncols)\n",
    "    grid.update(wspace=0.2, hspace=0.2, left=0.1, right=0.2, bottom=0.1, top=0.2) \n",
    "    return grid\n",
    "\n",
    "\n",
    "def get_feature_maps(layer, X, input_var, batch_size=500):\n",
    "    \"\"\"get the feature maps of a given convolutional layer\"\"\"\n",
    "\n",
    "    # setup theano function to get feature map of a given layer\n",
    "    num_data = len(X)\n",
    "    feature_maps = theano.function([input_var], layers.get_output(layer, deterministic=True), allow_input_downcast=True)\n",
    "    map_shape = get_output_shape(layer)\n",
    "\n",
    "    # get feature maps in batches for speed (large batches may be too much memory for GPU)\n",
    "    num_batches = num_data // batch_size\n",
    "    shape = list(map_shape)\n",
    "    shape[0] = num_data\n",
    "    fmaps = np.empty(tuple(shape))\n",
    "    for i in range(num_batches):\n",
    "        index = range(i*batch_size, (i+1)*batch_size)    \n",
    "        fmaps[index] = feature_maps(X[index])\n",
    "\n",
    "    # get the rest of the feature maps\n",
    "    excess = num_data-num_batches*batch_size\n",
    "    index = range(num_data-excess, num_data)    \n",
    "    fmaps[index] = feature_maps(X[index])\n",
    "    \n",
    "    return fmaps\n",
    "\n",
    "\n",
    "\n",
    "def tSNE_plot(vis_data, labels):\n",
    "    \"\"\"scatter plot of tSNE 2D projections, with a color corresponding to labels\"\"\"\n",
    "    num_labels = max(labels)+1\n",
    "    vis_x = vis_data[:,0]\n",
    "    vis_y = vis_data[:,1]\n",
    "    plt.figure(figsize = (10,10))\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(50, 50, forward=True)\n",
    "    plt.scatter(vis_x, vis_y, c=labels, cmap=plt.cm.get_cmap(\"jet\", num_labels),  edgecolor = 'none')\n",
    "    plt.axis('off')\n",
    "    return plt\n",
    "\n",
    "\n",
    "\n",
    "def get_class_activation(fmaps, y, batch_size=512):\n",
    "    fmaps = np.squeeze(fmaps)\n",
    "    mean_activation = []\n",
    "    std_activation = []\n",
    "    for i in range(max(y)+1):\n",
    "        index = np.where(y == i)[0]\n",
    "        mean_activation.append(np.mean(fmaps[index], axis=0))\n",
    "        std_activation.append(np.std(fmaps[index], axis=0))\n",
    "    return np.array(mean_activation), np.array(std_activation)\n",
    "\n",
    "\n",
    "def plot_mean_activations(mean_activation, options):\n",
    "    num_labels = len(mean_activation)\n",
    "    nrows = np.ceil(np.sqrt(num_labels)).astype(int)\n",
    "    ncols = nrows\n",
    "\n",
    "    plt.figure()\n",
    "    grid = subplot_grid(nrows, ncols)\n",
    "    for i in range(num_labels):\n",
    "        plt.subplot(grid[i])\n",
    "        plt.plot(mean_activation[i].T)\n",
    "        fig_options(plt, options)\n",
    "    return plt\n",
    "\n",
    "\n",
    "def plot_conv_filter(layer,size):\n",
    "    W =  np.squeeze(layer.W.get_value())\n",
    "    num_filters = W.shape[0]\n",
    "\n",
    "    num_rows = int(np.ceil(np.sqrt(num_filters)))    \n",
    "    grid = mpl.gridspec.GridSpec(num_rows, num_rows)\n",
    "    grid.update(wspace=0.2, hspace=0.2, left=0.1, right=0.2, bottom=0.1, top=0.2) \n",
    "    \n",
    "    fig = plt.figure(figsize=size);\n",
    "    for i in range(num_filters):\n",
    "        MAX = np.max(W[i])\n",
    "        pwm = W[i]/MAX\n",
    "        pwm += .25\n",
    "        pwm[pwm<0] = 0\n",
    "        norm = np.outer(np.ones(4), np.sum(pwm, axis=0))\n",
    "        pwm = pwm/norm\n",
    "\n",
    "        logo = seq_logo(pwm, height=100, nt_width=25, norm=0, rna=1, filepath='.')\n",
    "        plt.subplot(grid[i]);\n",
    "        plt.imshow(logo);\n",
    "        plt.axis('off');\n",
    "    return fig, plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st shallow layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot convolution filters\n",
    "\n",
    "fig, plt = plot_conv_filter(network['conv1'],size=(100.,100.))\n",
    "fig.set_size_inches(100,100)\n",
    "outfile = os.path.join(savedir,'shallow_layer1_filters.pdf')\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot mean activation\n",
    "fmaps = get_feature_maps(network['conv1_pool'], train[0], nnmodel.input_var, batch_size=512) \n",
    "mean_activation, std_activation = get_class_activation(fmaps, np.argmax(train[1],axis=1))\n",
    "options = { 'xlim': [0, get_output_shape(network['conv1_pool'])[2]],\n",
    "            'ylim': [0, 3.3],\n",
    "            'xticks': [0, 5, 10],\n",
    "            'yticks': [1, 2, 3], \n",
    "            'labelsize': 18,\n",
    "            'figsize': (150,100)}\n",
    "plt = plot_mean_activations(mean_activation, options)\n",
    "outfile = os.path.join(savedir,'shallow_layer1_activation.pdf')\n",
    "plt.savefig(outfile, format='pdf', dpi=1000)    \n",
    "call(['pdfcrop', outfile, outfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot individual activations\n",
    "index = 0\n",
    "individual = np.squeeze(fmaps[index])\n",
    "plt.imshow(individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# t-SNE \n",
    "fmaps_flat = fmaps.reshape((len(fmaps),-1))\n",
    "fmaps_flat.shape\n",
    "\n",
    "# perform t-SNE embedding\n",
    "vis_cnn = bh_sne(fmaps_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options = {'figsize':(5,5), 'axis':'off'}\n",
    "plt = tSNE_plot(vis_cnn, np.argmax(train[1],axis=1))\n",
    "outfile = os.path.join(savedir,'shallow_layer1_tSNE.pdf')\n",
    "plt.savefig(outfile, format='eps', dpi=1000)    \n",
    "call(['pdfcrop', outfile, outfile])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd shallow layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer = network['conv2_pool']\n",
    "X = train[0]\n",
    "input_var = nnmodel.input_var\n",
    "batch_size = 512\n",
    "\n",
    "# setup theano function to get feature map of a given layer\n",
    "num_data = len(X)\n",
    "feature_maps = theano.function([input_var], layers.get_output(layer), allow_input_downcast=True)\n",
    "map_shape = get_output_shape(layer)\n",
    "\n",
    "# get feature maps in batches for speed (large batches may be too much memory for GPU)\n",
    "num_batches = num_data // batch_size\n",
    "shape = list(map_shape)\n",
    "shape[0] = num_data\n",
    "fmaps = np.empty(tuple(shape))\n",
    "for i in range(num_batches):\n",
    "    index = range(i*batch_size, (i+1)*batch_size)    \n",
    "    fmaps[index] = feature_maps(X[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t-SNE \n",
    "fmaps_flat = fmaps.reshape((len(fmaps),-1))\n",
    "fmaps_flat.shape\n",
    "\n",
    "# perform t-SNE embedding\n",
    "vis_cnn = bh_sne(fmaps_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options = {'figsize':(5,5), 'axis':'off'}\n",
    "plt = tSNE_plot(vis_cnn, np.argmax(train[1],axis=1))\n",
    "outfile = os.path.join(savedir,'shallow_layer2_tSNE.pdf')\n",
    "plt.savefig(outfile, format='eps', dpi=1000)    \n",
    "call(['pdfcrop', outfile, outfile])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3rd convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot mean activation\n",
    "fmaps = get_feature_maps(network['conv5_active'], train[0], nnmodel.input_var, batch_size=512) \n",
    "# t-SNE \n",
    "fmaps_flat = fmaps.reshape((len(fmaps),-1))\n",
    "fmaps_flat.shape\n",
    "\n",
    "# perform t-SNE embedding\n",
    "vis_cnn = bh_sne(fmaps_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options = {'figsize':(5,5), 'axis':'off'}\n",
    "plt = tSNE_plot(vis_cnn, np.argmax(train[1],axis=1))\n",
    "outfile = os.path.join(savedir,'shallow_layer3_tSNE.pdf')\n",
    "plt.savefig(outfile, format='eps', dpi=1000)    \n",
    "call(['pdfcrop', outfile, outfile])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot mean activation\n",
    "fmaps = get_feature_maps(network['dense1_active'], train[0], nnmodel.input_var, batch_size=512) \n",
    "# t-SNE \n",
    "fmaps_flat = fmaps.reshape((len(fmaps),-1))\n",
    "fmaps_flat.shape\n",
    "\n",
    "# perform t-SNE embedding\n",
    "vis_cnn = bh_sne(fmaps_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options = {'figsize':(5,5), 'axis':'off'}\n",
    "plt = tSNE_plot(vis_cnn, np.argmax(train[1],axis=1))\n",
    "outfile = os.path.join(savedir,'shallow_layer4_tSNE.pdf')\n",
    "plt.savefig(outfile, format='eps', dpi=1000)    \n",
    "call(['pdfcrop', outfile, outfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
