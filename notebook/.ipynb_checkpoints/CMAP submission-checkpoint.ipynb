{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import os, sys, gzip\n",
    "import cPickle as pickle\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1004)   # for reproducibility\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy import stats\n",
    "from lasagne import layers, nonlinearities, updates, objectives, init, regularization\n",
    "from lasagne.layers import get_output, get_output_shape, get_all_params\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "\n",
    "from six.moves import cPickle\n",
    "\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "import lasagne as nn\n",
    "from lasagne import layers, init, nonlinearities, utils, regularization, objectives, updates\n",
    "from lasagne.layers.base import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BatchNormLayer(Layer):\n",
    "    def __init__(self, incoming, axes='auto', epsilon=1e-4, alpha=0.1,\n",
    "                 beta=init.Constant(0), gamma=init.Constant(1),\n",
    "                 mean=init.Constant(0), inv_std=init.Constant(1), **kwargs):\n",
    "        super(BatchNormLayer, self).__init__(incoming, **kwargs)\n",
    "\n",
    "        if axes == 'auto':\n",
    "            # default: normalize over all but the second axis\n",
    "            axes = (0,) + tuple(range(2, len(self.input_shape)))\n",
    "        elif isinstance(axes, int):\n",
    "            axes = (axes,)\n",
    "        self.axes = axes\n",
    "\n",
    "        self.epsilon = utils.floatX(epsilon)\n",
    "        self.alpha = utils.floatX(alpha)\n",
    "\n",
    "        # create parameters, ignoring all dimensions in axes\n",
    "        shape = [size for axis, size in enumerate(self.input_shape)\n",
    "                 if axis not in self.axes]\n",
    "        if any(size is None for size in shape):\n",
    "            raise ValueError(\"BatchNormLayer needs specified input sizes for \"\n",
    "                             \"all axes not normalized over.\")\n",
    "        if beta is None:\n",
    "            self.beta = None\n",
    "        else:\n",
    "            self.beta = self.add_param(beta, shape, 'beta',\n",
    "                                       trainable=True, regularizable=False)\n",
    "        if gamma is None:\n",
    "            self.gamma = None\n",
    "        else:\n",
    "            self.gamma = self.add_param(gamma, shape, 'gamma',\n",
    "                                        trainable=True, regularizable=False)\n",
    "        self.mean = self.add_param(mean, shape, 'mean',\n",
    "                                   trainable=False, regularizable=False)\n",
    "        self.inv_std = self.add_param(inv_std, shape, 'inv_std',\n",
    "                                      trainable=False, regularizable=False)\n",
    "\n",
    "        self.beta = T.cast(self.beta, dtype='floatX')\n",
    "        self.gamma = T.cast(self.gamma, dtype='floatX')\n",
    "        self.mean = T.cast(self.mean, dtype='floatX')\n",
    "        self.inv_std = T.cast(self.inv_std, dtype='floatX')\n",
    "\n",
    "    def get_output_for(self, input, deterministic=False,\n",
    "                       batch_norm_use_averages=None,\n",
    "                       batch_norm_update_averages=None, **kwargs):\n",
    "        input_mean = input.mean(self.axes)\n",
    "        input_inv_std = T.inv(T.sqrt(input.var(self.axes) + self.epsilon))\n",
    "\n",
    "        # Decide whether to use the stored averages or mini-batch statistics\n",
    "        if batch_norm_use_averages is None:\n",
    "            batch_norm_use_averages = deterministic\n",
    "        use_averages = batch_norm_use_averages\n",
    "\n",
    "        if use_averages:\n",
    "            mean = self.mean\n",
    "            inv_std = self.inv_std\n",
    "        else:\n",
    "            mean = input_mean\n",
    "            inv_std = input_inv_std\n",
    "\n",
    "        # Decide whether to update the stored averages\n",
    "        if batch_norm_update_averages is None:\n",
    "            batch_norm_update_averages = not deterministic\n",
    "        update_averages = batch_norm_update_averages\n",
    "\n",
    "        if update_averages:\n",
    "            # Trick: To update the stored statistics, we create memory-aliased\n",
    "            # clones of the stored statistics:\n",
    "            running_mean = theano.clone(self.mean, share_inputs=False)\n",
    "            running_inv_std = theano.clone(self.inv_std, share_inputs=False)\n",
    "            # set a default update for them:\n",
    "            running_mean.default_update = ((1 - self.alpha) * running_mean +\n",
    "                                           self.alpha * input_mean)\n",
    "            running_inv_std.default_update = ((1 - self.alpha) *\n",
    "                                              running_inv_std +\n",
    "                                              self.alpha * input_inv_std)\n",
    "            # and make sure they end up in the graph without participating in\n",
    "            # the computation (this way their default_update will be collected\n",
    "            # and applied, but the computation will be optimized away):\n",
    "            mean += 0 * running_mean\n",
    "            inv_std += 0 * running_inv_std\n",
    "\n",
    "        # prepare dimshuffle pattern inserting broadcastable axes as needed\n",
    "        param_axes = iter(range(input.ndim - len(self.axes)))\n",
    "        pattern = ['x' if input_axis in self.axes\n",
    "                   else next(param_axes)\n",
    "                   for input_axis in range(input.ndim)]\n",
    "\n",
    "        # apply dimshuffle pattern to all parameters\n",
    "        beta = 0 if self.beta is None else self.beta.dimshuffle(pattern)\n",
    "        gamma = 1 if self.gamma is None else self.gamma.dimshuffle(pattern)\n",
    "        mean = mean.dimshuffle(pattern)\n",
    "        inv_std = inv_std.dimshuffle(pattern)\n",
    "\n",
    "        # normalize\n",
    "        normalized = (input - mean) * (gamma * inv_std) + beta\n",
    "        return normalized\n",
    "\n",
    "class GaussianSampleLayer(layers.MergeLayer):\n",
    "    def __init__(self, incoming_mu, incoming_logsigma, **kwargs):\n",
    "        super(GaussianSampleLayer, self).__init__(incomings=[incoming_mu, incoming_logsigma], **kwargs)\n",
    "        self.srng = RandomStreams(seed=234)\n",
    "\n",
    "    def get_output_shape_for(self, input_shapes):\n",
    "        return input_shapes[0]\n",
    "\n",
    "    def get_output_for(self, inputs, deterministic=False, **kwargs):\n",
    "        mu, logsigma = inputs\n",
    "        shape=(self.input_shapes[0][0] or inputs[0].shape[0],\n",
    "                self.input_shapes[0][1] or inputs[0].shape[1])\n",
    "        if deterministic:\n",
    "            return mu\n",
    "        return mu + T.exp(logsigma) * self.srng.normal(shape, avg=0.0, std=1).astype(theano.config.floatX)\n",
    "\n",
    "\n",
    "def vae_model(input_var):\n",
    "    net = {}\n",
    "    net['input'] = layers.InputLayer(shape=(None, 970), input_var=input_var)\n",
    "\n",
    "    # encode layer 1\n",
    "    net['encode1'] = layers.DenseLayer(net['input'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=None)\n",
    "    net['encode1_norm'] = BatchNormLayer(net['encode1'])\n",
    "    net['encode1_active'] = layers.NonlinearityLayer(net['encode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "    net['encode1_dropout'] = layers.DropoutLayer(net['encode1_active'],p=0.5)\n",
    "\n",
    "    # encode layer\n",
    "    net['Z_mu'] = layers.DenseLayer(net['encode1_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    \n",
    "    net['Z_logsigma'] = layers.DenseLayer(net['encode1_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    net['Z'] = GaussianSampleLayer(net['Z_mu'], net['Z_logsigma'])\n",
    "\n",
    "    # encode layer 1\n",
    "    net['decode1'] = layers.DenseLayer(net['Z'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=None)\n",
    "    net['decode1_norm'] = BatchNormLayer(net['decode1'])\n",
    "    net['decode1_active'] = layers.NonlinearityLayer(net['decode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "    net['decode1_dropout'] = layers.DropoutLayer(net['decode1_active'],p=0.5)\n",
    "\n",
    "\n",
    "    # encode layer\n",
    "    net['X_mu'] = layers.DenseLayer(net['decode1_dropout'], num_units=970, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    net['X_logsigma'] = layers.DenseLayer(net['decode1_dropout'], num_units=970, W=init.GlorotUniform(), \n",
    "                                      b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "    net['X'] = GaussianSampleLayer(net['X_mu'], net['X_logsigma'])\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_prediction(best_path, landmark, mean_nonlandmark, std_nonlandmark):\n",
    "    class MultiplicativeGatingLayer(nn.layers.MergeLayer):\n",
    "        \"\"\"\n",
    "        Generic layer that combines its 3 inputs t, h1, h2 as follows:\n",
    "        y = t * h1 + (1 - t) * h2\n",
    "        \"\"\"\n",
    "        def __init__(self, gate, input1, input2, **kwargs):\n",
    "            incomings = [gate, input1, input2]\n",
    "            super(MultiplicativeGatingLayer, self).__init__(incomings, **kwargs)\n",
    "            assert gate.output_shape == input1.output_shape == input2.output_shape\n",
    "\n",
    "        def get_output_shape_for(self, input_shapes):\n",
    "            return input_shapes[0]\n",
    "\n",
    "        def get_output_for(self, inputs, **kwargs):\n",
    "            return inputs[0] * inputs[1] + (1 - inputs[0]) * inputs[2]\n",
    "    def mlp_model(input_var):\n",
    "        net = {}\n",
    "        net['input'] = layers.InputLayer(shape=(None, 970), input_var=input_var)\n",
    "\n",
    "        # encode layer 1\n",
    "        net['encode1'] = layers.DenseLayer(net['input'], num_units=1000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode1_norm'] = BatchNormLayer(net['encode1'])\n",
    "        net['encode1_active'] = layers.NonlinearityLayer(net['encode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode1_dropout'] = layers.DropoutLayer(net['encode1_active'],p=0.5)\n",
    "\n",
    "        # encode layer 2\n",
    "        net['encode2'] = layers.DenseLayer(net['encode1_dropout'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode2_norm'] = BatchNormLayer(net['encode2'])\n",
    "        net['encode2_active'] = layers.NonlinearityLayer(net['encode2_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode2_dropout'] = layers.DropoutLayer(net['encode2_active'],p=0.5)\n",
    "\n",
    "        # encode layer\n",
    "        net['output'] = layers.DenseLayer(net['encode2_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=nonlinearities.linear)\n",
    "        return net\n",
    "    def dae_model(input_var):\n",
    "        net = {}\n",
    "        net['input'] = layers.InputLayer(shape=(None, 970), input_var=input_var)\n",
    "\n",
    "        # encode layer 1\n",
    "        net['encode1'] = layers.DenseLayer(net['input'], num_units=1000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode1_norm'] = BatchNormLayer(net['encode1'])\n",
    "        net['encode1_active'] = layers.NonlinearityLayer(net['encode1_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode1_dropout'] = layers.DropoutLayer(net['encode1_active'],p=0.5)\n",
    "\n",
    "        # encode layer 2\n",
    "        net['encode2'] = layers.DenseLayer(net['encode1_dropout'], num_units=2000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode2_norm'] = BatchNormLayer(net['encode2'])\n",
    "        net['encode2_active'] = layers.NonlinearityLayer(net['encode2_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode2_dropout'] = layers.DropoutLayer(net['encode2_active'],p=0.5)\n",
    "\n",
    "        # encode layer 2\n",
    "        net['encode3'] = layers.DenseLayer(net['encode2_dropout'], num_units=3000, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['encode3_norm'] = BatchNormLayer(net['encode3'])\n",
    "        net['encode3_active'] = layers.NonlinearityLayer(net['encode3_norm'], nonlinearity=nonlinearities.rectify)\n",
    "        net['encode3_dropout'] = layers.DropoutLayer(net['encode3_active'],p=0.5)\n",
    "\n",
    "        # encode layer\n",
    "        net['encode'] = layers.DenseLayer(net['encode3_dropout'], num_units=11350, W=init.GlorotUniform(), \n",
    "                                          b=init.Constant(0.05), nonlinearity=None)\n",
    "        net['output'] = layers.NonlinearityLayer(net['encode'], nonlinearity=nonlinearities.linear)\n",
    "        return net\n",
    "\n",
    "    def highway_dense(incoming, Wh=init.Orthogonal(), bh=init.Constant(0.0),\n",
    "                      Wt=init.Orthogonal(), bt=init.Constant(-4.0),\n",
    "                      nonlinearity=nonlinearities.rectify, **kwargs):\n",
    "        num_inputs = int(np.prod(incoming.output_shape[1:]))\n",
    "        # regular layer\n",
    "        l_h = layers.DenseLayer(incoming, num_units=num_inputs, W=Wh, b=bh,\n",
    "                                   nonlinearity=nonlinearity)\n",
    "        # gate layer\n",
    "        l_t = layers.DenseLayer(incoming, num_units=num_inputs, W=Wt, b=bt,\n",
    "                                   nonlinearity=T.nnet.sigmoid)\n",
    "\n",
    "        return MultiplicativeGatingLayer(gate=l_t, input1=l_h, input2=incoming)\n",
    "\n",
    "    def build_model(input_var, batch_size=100,\n",
    "                    num_hidden_units=500, num_hidden_layers=50):\n",
    "\n",
    "        l_in = layers.InputLayer(shape=(batch_size, 970), input_var=input_var)\n",
    "\n",
    "        # first, project it down to the desired number of units per layer\n",
    "        l_hidden1 = layers.DenseLayer(l_in, num_units=num_hidden_units)\n",
    "\n",
    "        # then stack highway layers on top of this\n",
    "        l_current = l_hidden1\n",
    "        for k in range(num_hidden_layers - 1):\n",
    "            l_current = highway_dense(l_current)\n",
    "\n",
    "\n",
    "        l_hidden2 = layers.DenseLayer(l_current, num_units=2000)\n",
    "\n",
    "        # finally add an output layer\n",
    "        l_out = layers.DenseLayer( l_hidden2, num_units=11350, nonlinearity=nonlinearities.linear)\n",
    "\n",
    "        return l_out\n",
    "\n",
    "\n",
    "    # setup model\n",
    "    input_var = T.dmatrix('landmark')\n",
    "    #network = build_model(input_var, batch_size=100, num_hidden_units=500, num_hidden_layers=50)\n",
    "    #network = build_model(input_var)\n",
    "    network = build_model(input_var)\n",
    "    \n",
    "    f = open(best_path, 'rb')\n",
    "    best_parameters = cPickle.load(f)\n",
    "    f.close()\n",
    "    layers.set_all_param_values(network, best_parameters)\n",
    "\n",
    "\n",
    "    prediction = layers.get_output(network, deterministic=True)\n",
    "\n",
    "    get_prediction = theano.function([input_var], prediction, allow_input_downcast=True)\n",
    "    prediction = get_prediction(landmark)\n",
    "\n",
    "    prediction = prediction.transpose([1,0]).astype(np.float64)\n",
    "    num_samples = prediction.shape[1]\n",
    "    prediction = (prediction*std_nonlandmark) + mean_nonlandmark\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3917357"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(std_landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0873799"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(landmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(970, 1000)\n"
     ]
    }
   ],
   "source": [
    "landmarkpath='/home/peter/Data/CMAP/test/landmarks.csv'\n",
    "data = pd.read_csv(landmarkpath, header=None, dtype=np.float32)\n",
    "landmark = data.as_matrix()\n",
    "\n",
    "nonlandmarkpath='/home/peter/Data/CMAP/test/truth.csv'\n",
    "data = pd.read_csv(nonlandmarkpath, header=None, dtype=np.float32)\n",
    "nonlandmark = data.as_matrix()\n",
    "\n",
    "def normalize_data(landmark, mean_landmark, std_landmark, num_samples):\n",
    "    landmark = (landmark - mean_landmark)/std_landmark\n",
    "    landmark = landmark.transpose([1,0])\n",
    "    return landmark\n",
    "print landmark.shape\n",
    "landmark = normalize_data(landmark, np.mean(landmark), np.std(landmark), landmark.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_path = '/home/peter/Data/CMAP/Results/highway_corr2epoch_1.pickle'\n",
    "prediction = model_prediction(best_path, landmark, np.mean(landmark), np.std(landmark))\n",
    "\n",
    "df2 = pd.DataFrame(prediction)\n",
    "df2.to_csv('/home/peter/Data/CMAP/test/prediction_ff.csv', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72821376516067882"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/home/peter/Data/CMAP/test/prediction_ff.csv'\n",
    "data = pd.read_csv(path, header=None, dtype=np.float32)\n",
    "test = data.as_matrix()\n",
    "test.shape\n",
    "\n",
    "nonlandmarkpath='/home/peter/Data/CMAP/test/truth.csv'\n",
    "data = pd.read_csv(nonlandmarkpath, header=None, dtype=np.float32)\n",
    "truth = data.as_matrix()\n",
    "truth.shape\n",
    "\n",
    "R = []\n",
    "for i in range(prediction.shape[1]):\n",
    "    R.append(stats.spearmanr(prediction[i,:], truth[i,:])[0])\n",
    "np.mean(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   1.,    1.,    1.,    3.,    3.,    8.,   14.,    8.,   11.,\n",
       "          14.,   18.,   16.,   14.,   19.,   19.,   18.,   17.,   30.,\n",
       "          20.,   43.,   32.,   49.,   62.,   95.,  112.,  126.,  103.,\n",
       "          86.,   41.,   16.]),\n",
       " array([ 0.12912826,  0.15654416,  0.18396006,  0.21137596,  0.23879186,\n",
       "         0.26620776,  0.29362366,  0.32103956,  0.34845546,  0.37587136,\n",
       "         0.40328726,  0.43070316,  0.45811906,  0.48553496,  0.51295086,\n",
       "         0.54036676,  0.56778266,  0.59519856,  0.62261446,  0.65003036,\n",
       "         0.67744626,  0.70486216,  0.73227806,  0.75969396,  0.78710986,\n",
       "         0.81452576,  0.84194166,  0.86935756,  0.89677346,  0.92418936,\n",
       "         0.95160526]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEACAYAAACwB81wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f498c4f1ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(R,bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rscript cmap_scoring_function.R --inf_ds prediction_ff.csv \\\n",
    "     --truth_ds truth.csv \\\n",
    "     --reference_scores refScores.csv \\\n",
    "     --out here\n",
    "\n",
    "\n",
    "java ConnectivityMap prediction_ff.csv truth.csv refScores.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savepath='/home/peter/Data/CMAP/data_set_norm.hd5f'\n",
    "trainmat = h5py.File(savepath, 'r')\n",
    "mean_landmark = np.array(trainmat['mean_landmark']).astype(np.float32)\n",
    "std_landmark = np.array(trainmat['std_landmark']).astype(np.float32)\n",
    "mean_nonlandmark = np.array(trainmat['mean_nonlandmark']).astype(np.float32)\n",
    "std_nonlandmark = np.array(trainmat['std_nonlandmark']).astype(np.float32)\n",
    "\n",
    "landmarkpath='/home/peter/Data/CMAP/test/testData.csv'\n",
    "data = pd.read_csv(landmarkpath, header=None, dtype=np.float32)\n",
    "landmark = data.as_matrix()\n",
    "\n",
    "\n",
    "def normalize_data(landmark, mean_landmark, std_landmark, num_samples):\n",
    "    landmark = (landmark - mean_landmark)/std_landmark\n",
    "    landmark = landmark.transpose([1,0])\n",
    "    return landmark\n",
    "\n",
    "landmark = normalize_data(landmark, np.mean(landmark), np.std(landmark), landmark.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "best_path = '/home/peter/Data/CMAP/Results/highway_corr2epoch_3.pickle'\n",
    "prediction = model_prediction(best_path, landmark, np.mean(landmark), np.std(landmark))\n",
    "\n",
    "filename = 'submission.csv'\n",
    "df2 = pd.DataFrame(prediction)\n",
    "df2.to_csv('/home/peter/Data/CMAP/test/'+filename, header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
