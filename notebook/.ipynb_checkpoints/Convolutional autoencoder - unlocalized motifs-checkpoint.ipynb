{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from src import NeuralNet\n",
    "from src import train as fit\n",
    "from src import make_directory \n",
    "from models import load_model\n",
    "from data import load_data\n",
    "from six.moves import cPickle\n",
    "from subprocess import call\n",
    "\n",
    "np.random.seed(247) # for reproducibility\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from lasagne import layers, nonlinearities, updates, objectives, init \n",
    "from lasagne.layers import Conv2DLayer, TransposedConv2DLayer, DenseLayer, InputLayer, ExpressionLayer, BiasLayer\n",
    "\n",
    "from lasagne.layers import get_output, get_output_shape, get_all_params\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "np.random.seed(247) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_data.pickle\n",
      "loading train data\n",
      "loading cross-validation data\n",
      "loading test data\n"
     ]
    }
   ],
   "source": [
    "filename = 'Unlocalized_N=100000_S=200_M=40_G=20_data.pickle'\n",
    "datapath = '/home/peter/Data/SequenceMotif'\n",
    "filepath = os.path.join(datapath, filename)\n",
    "\n",
    "# load training set\n",
    "print \"loading data from: \" + filepath\n",
    "f = open(filepath, 'rb')\n",
    "print \"loading train data\"\n",
    "train = cPickle.load(f)\n",
    "print \"loading cross-validation data\"\n",
    "cross_validation = cPickle.load(f)\n",
    "print \"loading test data\"\n",
    "test = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "X_train = train[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_train = train[1].astype(np.int32)\n",
    "X_val = cross_validation[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_val = cross_validation[1].astype(np.int32)\n",
    "X_test = test[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_test = test[1].astype(np.int32)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_val = np.expand_dims(X_val, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "train = (X_train, y_train, train[2])\n",
    "valid = (X_val, y_val, cross_validation[2])\n",
    "test = (X_test, y_test, test[2])\n",
    "\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle\n"
     ]
    }
   ],
   "source": [
    "filename = 'Unlocalized_N=100000_S=200_M=40_G=20_model.pickle'\n",
    "datapath = '/home/peter/Data/SequenceMotif'\n",
    "filepath = os.path.join(datapath, filename)\n",
    "\n",
    "# load training set\n",
    "print \"loading model from: \" + filepath\n",
    "f = open(filepath, 'rb')\n",
    "options = cPickle.load(f)\n",
    "model = cPickle.load(f)\n",
    "seq_model = cPickle.load(f)\n",
    "ground_truth = cPickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = \"genome_motif_model\"\n",
    "nnmodel = NeuralNet(model_name, shape, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7fdd4941b410>,\n",
       " 'conv1_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7fdd4941bc50>,\n",
       " 'conv1_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7fdd4941b690>,\n",
       " 'conv1_bias': <lasagne.layers.special.BiasLayer at 0x7fdd4941b450>,\n",
       " 'conv2': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7fdd4941b7d0>,\n",
       " 'conv2_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7fdd49377650>,\n",
       " 'conv2_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7fdd4941bf50>,\n",
       " 'conv2_bias': <lasagne.layers.special.BiasLayer at 0x7fdd4941bc90>,\n",
       " 'conv2_pool': <lasagne.layers.pool.MaxPool2DLayer at 0x7fdd49377110>,\n",
       " 'conv3': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7fdd49377690>,\n",
       " 'conv3_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7fdd4939e150>,\n",
       " 'conv3_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7fdd49377990>,\n",
       " 'conv3_bias': <lasagne.layers.special.BiasLayer at 0x7fdd49377850>,\n",
       " 'conv4': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7fdd49377b10>,\n",
       " 'conv4_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7fdd4939eb10>,\n",
       " 'conv4_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7fdd4939e450>,\n",
       " 'conv4_bias': <lasagne.layers.special.BiasLayer at 0x7fdd4939e190>,\n",
       " 'conv4_pool': <lasagne.layers.pool.MaxPool2DLayer at 0x7fdd4939e5d0>,\n",
       " 'conv5': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7fdd4939eb50>,\n",
       " 'conv5_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7fdd49390550>,\n",
       " 'conv5_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7fdd4939ee50>,\n",
       " 'conv5_bias': <lasagne.layers.special.BiasLayer at 0x7fdd4939ed10>,\n",
       " 'conv6': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7fdd4939efd0>,\n",
       " 'conv6_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7fdd49390f10>,\n",
       " 'conv6_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7fdd49390850>,\n",
       " 'conv6_bias': <lasagne.layers.special.BiasLayer at 0x7fdd49390590>,\n",
       " 'conv6_pool': <lasagne.layers.pool.MaxPool2DLayer at 0x7fdd493909d0>,\n",
       " 'conv7': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7fdd49390f50>,\n",
       " 'conv7_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7fdd49379950>,\n",
       " 'conv7_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7fdd49379290>,\n",
       " 'conv7_bias': <lasagne.layers.special.BiasLayer at 0x7fdd49379150>,\n",
       " 'conv7_pool': <lasagne.layers.pool.MaxPool2DLayer at 0x7fdd49379410>,\n",
       " 'dense1': <lasagne.layers.dense.DenseLayer at 0x7fdd49379990>,\n",
       " 'dense1_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7fdd49399390>,\n",
       " 'dense1_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7fdd49379c90>,\n",
       " 'dense1_bias': <lasagne.layers.special.BiasLayer at 0x7fdd49379b50>,\n",
       " 'dense1_dropout': <lasagne.layers.noise.DropoutLayer at 0x7fdd49379e10>,\n",
       " 'dense2': <lasagne.layers.dense.DenseLayer at 0x7fdd49377fd0>,\n",
       " 'dense2_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7fdd49399e50>,\n",
       " 'dense2_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7fdd49399710>,\n",
       " 'dense2_bias': <lasagne.layers.special.BiasLayer at 0x7fdd493995d0>,\n",
       " 'dense2_dropout': <lasagne.layers.noise.DropoutLayer at 0x7fdd493998d0>,\n",
       " 'input': <lasagne.layers.input.InputLayer at 0x7fdd4941b350>,\n",
       " 'output': <lasagne.layers.special.NonlinearityLayer at 0x7fdd49337250>,\n",
       " 'output_active': <lasagne.layers.special.NonlinearityLayer at 0x7fdd49337250>,\n",
       " 'output_bias': <lasagne.layers.special.BiasLayer at 0x7fdd49337110>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nnmodel.network\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.21252 -- accuracy=98.32%  \n",
      "  valid loss:\t\t0.18077\n",
      "  valid accuracy:\t0.98390+/-0.01593\n",
      "  valid auc-roc:\t0.97680+/-0.03269\n",
      "  valid auc-pr:\t\t0.78201+/-0.31533\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_0.pickle\n",
      "Epoch 2 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.16888 -- accuracy=98.42%  \n",
      "  valid loss:\t\t0.15240\n",
      "  valid accuracy:\t0.98492+/-0.01608\n",
      "  valid auc-roc:\t0.97720+/-0.03053\n",
      "  valid auc-pr:\t\t0.78504+/-0.32059\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_1.pickle\n",
      "Epoch 3 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.14553 -- accuracy=98.48%  \n",
      "  valid loss:\t\t0.13426\n",
      "  valid accuracy:\t0.98535+/-0.01611\n",
      "  valid auc-roc:\t0.98126+/-0.02693\n",
      "  valid auc-pr:\t\t0.80286+/-0.29633\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_2.pickle\n",
      "Epoch 4 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.12929 -- accuracy=98.54%  \n",
      "  valid loss:\t\t0.12189\n",
      "  valid accuracy:\t0.98618+/-0.01570\n",
      "  valid auc-roc:\t0.98254+/-0.02615\n",
      "  valid auc-pr:\t\t0.81134+/-0.29184\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_3.pickle\n",
      "Epoch 5 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.11869 -- accuracy=98.59%  \n",
      "  valid loss:\t\t0.11260\n",
      "  valid accuracy:\t0.98685+/-0.01546\n",
      "  valid auc-roc:\t0.98325+/-0.02541\n",
      "  valid auc-pr:\t\t0.80919+/-0.29843\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_4.pickle\n",
      "Epoch 6 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.11177 -- accuracy=98.62%  \n",
      "  valid loss:\t\t0.10841\n",
      "  valid accuracy:\t0.98649+/-0.01573\n",
      "  valid auc-roc:\t0.98347+/-0.02523\n",
      "  valid auc-pr:\t\t0.81382+/-0.29256\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_5.pickle\n",
      "Epoch 7 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.10764 -- accuracy=98.65%  \n",
      "  valid loss:\t\t0.10527\n",
      "  valid accuracy:\t0.98627+/-0.01551\n",
      "  valid auc-roc:\t0.98250+/-0.02685\n",
      "  valid auc-pr:\t\t0.81443+/-0.29260\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_6.pickle\n",
      "Epoch 8 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.10419 -- accuracy=98.67%  \n",
      "  valid loss:\t\t0.10194\n",
      "  valid accuracy:\t0.98679+/-0.01529\n",
      "  valid auc-roc:\t0.98398+/-0.02489\n",
      "  valid auc-pr:\t\t0.82373+/-0.28045\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_7.pickle\n",
      "Epoch 9 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.10230 -- accuracy=98.68%  \n",
      "  valid loss:\t\t0.09927\n",
      "  valid accuracy:\t0.98725+/-0.01490\n",
      "  valid auc-roc:\t0.98428+/-0.02425\n",
      "  valid auc-pr:\t\t0.82385+/-0.28300\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_8.pickle\n",
      "Epoch 10 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.09969 -- accuracy=98.70%  \n",
      "  valid loss:\t\t0.09792\n",
      "  valid accuracy:\t0.98707+/-0.01511\n",
      "  valid auc-roc:\t0.98456+/-0.02350\n",
      "  valid auc-pr:\t\t0.81926+/-0.28782\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_9.pickle\n",
      "Epoch 11 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.09786 -- accuracy=98.71%  \n",
      "  valid loss:\t\t0.09608\n",
      "  valid accuracy:\t0.98730+/-0.01487\n",
      "  valid auc-roc:\t0.98479+/-0.02382\n",
      "  valid auc-pr:\t\t0.82462+/-0.28366\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_10.pickle\n",
      "Epoch 12 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.09647 -- accuracy=98.72%  \n",
      "  valid loss:\t\t0.09496\n",
      "  valid accuracy:\t0.98721+/-0.01525\n",
      "  valid auc-roc:\t0.98384+/-0.02573\n",
      "  valid auc-pr:\t\t0.82310+/-0.28549\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_11.pickle\n",
      "Epoch 13 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.09419 -- accuracy=98.75%  \n",
      "  valid loss:\t\t0.09212\n",
      "  valid accuracy:\t0.98738+/-0.01504\n",
      "  valid auc-roc:\t0.98422+/-0.02432\n",
      "  valid auc-pr:\t\t0.82376+/-0.28366\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_12.pickle\n",
      "Epoch 14 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.09293 -- accuracy=98.75%  \n",
      "  valid loss:\t\t0.09143\n",
      "  valid accuracy:\t0.98762+/-0.01456\n",
      "  valid auc-roc:\t0.98427+/-0.02514\n",
      "  valid auc-pr:\t\t0.82750+/-0.28271\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_13.pickle\n",
      "Epoch 15 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.09121 -- accuracy=98.77%  \n",
      "  valid loss:\t\t0.09027\n",
      "  valid accuracy:\t0.98776+/-0.01474\n",
      "  valid auc-roc:\t0.98373+/-0.02680\n",
      "  valid auc-pr:\t\t0.82465+/-0.28716\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_14.pickle\n",
      "Epoch 16 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.09070 -- accuracy=98.76%  \n",
      "  valid loss:\t\t0.09059\n",
      "  valid accuracy:\t0.98719+/-0.01487\n",
      "  valid auc-roc:\t0.98422+/-0.02436\n",
      "  valid auc-pr:\t\t0.82520+/-0.28240\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_15.pickle\n",
      "Epoch 17 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08933 -- accuracy=98.78%  \n",
      "  valid loss:\t\t0.08927\n",
      "  valid accuracy:\t0.98725+/-0.01514\n",
      "  valid auc-roc:\t0.98443+/-0.02478\n",
      "  valid auc-pr:\t\t0.82872+/-0.28103\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_16.pickle\n",
      "Epoch 18 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08868 -- accuracy=98.79%  \n",
      "  valid loss:\t\t0.08707\n",
      "  valid accuracy:\t0.98766+/-0.01492\n",
      "  valid auc-roc:\t0.98517+/-0.02356\n",
      "  valid auc-pr:\t\t0.82853+/-0.28162\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_17.pickle\n",
      "Epoch 19 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08757 -- accuracy=98.79%  \n",
      "  valid loss:\t\t0.08711\n",
      "  valid accuracy:\t0.98748+/-0.01516\n",
      "  valid auc-roc:\t0.98538+/-0.02298\n",
      "  valid auc-pr:\t\t0.82794+/-0.27865\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_18.pickle\n",
      "Epoch 20 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08666 -- accuracy=98.81%  \n",
      "  valid loss:\t\t0.08742\n",
      "  valid accuracy:\t0.98746+/-0.01475\n",
      "  valid auc-roc:\t0.98429+/-0.02430\n",
      "  valid auc-pr:\t\t0.82737+/-0.28247\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_19.pickle\n",
      "Epoch 21 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08621 -- accuracy=98.80%  \n",
      "  valid loss:\t\t0.08595\n",
      "  valid accuracy:\t0.98773+/-0.01446\n",
      "  valid auc-roc:\t0.98495+/-0.02358\n",
      "  valid auc-pr:\t\t0.82585+/-0.28527\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_20.pickle\n",
      "Epoch 22 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08557 -- accuracy=98.81%  \n",
      "  valid loss:\t\t0.08589\n",
      "  valid accuracy:\t0.98766+/-0.01500\n",
      "  valid auc-roc:\t0.98514+/-0.02325\n",
      "  valid auc-pr:\t\t0.82744+/-0.28105\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_21.pickle\n",
      "Epoch 23 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08496 -- accuracy=98.82%  \n",
      "  valid loss:\t\t0.08558\n",
      "  valid accuracy:\t0.98767+/-0.01477\n",
      "  valid auc-roc:\t0.98462+/-0.02445\n",
      "  valid auc-pr:\t\t0.82819+/-0.28234\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_22.pickle\n",
      "Epoch 24 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08400 -- accuracy=98.84%  \n",
      "  valid loss:\t\t0.08508\n",
      "  valid accuracy:\t0.98759+/-0.01515\n",
      "  valid auc-roc:\t0.98413+/-0.02552\n",
      "  valid auc-pr:\t\t0.82701+/-0.28328\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_23.pickle\n",
      "Epoch 25 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08420 -- accuracy=98.82%  \n",
      "  valid loss:\t\t0.08568\n",
      "  valid accuracy:\t0.98732+/-0.01522\n",
      "  valid auc-roc:\t0.98468+/-0.02470\n",
      "  valid auc-pr:\t\t0.82847+/-0.28271\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_24.pickle\n",
      "Epoch 26 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08352 -- accuracy=98.83%  \n",
      "  valid loss:\t\t0.08435\n",
      "  valid accuracy:\t0.98750+/-0.01484\n",
      "  valid auc-roc:\t0.98454+/-0.02403\n",
      "  valid auc-pr:\t\t0.82635+/-0.28385\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_25.pickle\n",
      "Epoch 27 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08273 -- accuracy=98.84%  \n",
      "  valid loss:\t\t0.08349\n",
      "  valid accuracy:\t0.98767+/-0.01466\n",
      "  valid auc-roc:\t0.98421+/-0.02412\n",
      "  valid auc-pr:\t\t0.83042+/-0.28126\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_26.pickle\n",
      "Epoch 28 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08260 -- accuracy=98.84%  \n",
      "  valid loss:\t\t0.08331\n",
      "  valid accuracy:\t0.98798+/-0.01434\n",
      "  valid auc-roc:\t0.98501+/-0.02389\n",
      "  valid auc-pr:\t\t0.82899+/-0.28255\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_27.pickle\n",
      "Epoch 29 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08218 -- accuracy=98.85%  \n",
      "  valid loss:\t\t0.08270\n",
      "  valid accuracy:\t0.98794+/-0.01461\n",
      "  valid auc-roc:\t0.98512+/-0.02380\n",
      "  valid auc-pr:\t\t0.82922+/-0.28164\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_28.pickle\n",
      "Epoch 30 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08150 -- accuracy=98.86%  \n",
      "  valid loss:\t\t0.08394\n",
      "  valid accuracy:\t0.98732+/-0.01540\n",
      "  valid auc-roc:\t0.98472+/-0.02365\n",
      "  valid auc-pr:\t\t0.82310+/-0.28417\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_29.pickle\n",
      "Epoch 31 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08154 -- accuracy=98.86%  \n",
      "  valid loss:\t\t0.08390\n",
      "  valid accuracy:\t0.98761+/-0.01471\n",
      "  valid auc-roc:\t0.98429+/-0.02436\n",
      "  valid auc-pr:\t\t0.82618+/-0.28209\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_30.pickle\n",
      "Epoch 32 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08142 -- accuracy=98.86%  \n",
      "  valid loss:\t\t0.08225\n",
      "  valid accuracy:\t0.98788+/-0.01452\n",
      "  valid auc-roc:\t0.98504+/-0.02424\n",
      "  valid auc-pr:\t\t0.83175+/-0.27970\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_31.pickle\n",
      "Epoch 33 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08110 -- accuracy=98.85%  \n",
      "  valid loss:\t\t0.08223\n",
      "  valid accuracy:\t0.98777+/-0.01480\n",
      "  valid auc-roc:\t0.98481+/-0.02432\n",
      "  valid auc-pr:\t\t0.82928+/-0.28151\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_32.pickle\n",
      "Epoch 34 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08074 -- accuracy=98.87%  \n",
      "  valid loss:\t\t0.08182\n",
      "  valid accuracy:\t0.98788+/-0.01453\n",
      "  valid auc-roc:\t0.98491+/-0.02462\n",
      "  valid auc-pr:\t\t0.82979+/-0.28202\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_33.pickle\n",
      "Epoch 35 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08037 -- accuracy=98.88%  \n",
      "  valid loss:\t\t0.08262\n",
      "  valid accuracy:\t0.98767+/-0.01464\n",
      "  valid auc-roc:\t0.98508+/-0.02364\n",
      "  valid auc-pr:\t\t0.82897+/-0.28133\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_34.pickle\n",
      "Epoch 36 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08013 -- accuracy=98.88%  \n",
      "  valid loss:\t\t0.08218\n",
      "  valid accuracy:\t0.98810+/-0.01391\n",
      "  valid auc-roc:\t0.98464+/-0.02429\n",
      "  valid auc-pr:\t\t0.82851+/-0.28196\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_35.pickle\n",
      "Epoch 37 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08009 -- accuracy=98.89%  \n",
      "  valid loss:\t\t0.08193\n",
      "  valid accuracy:\t0.98809+/-0.01394\n",
      "  valid auc-roc:\t0.98464+/-0.02483\n",
      "  valid auc-pr:\t\t0.82969+/-0.28218\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_36.pickle\n",
      "Epoch 38 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07954 -- accuracy=98.91%  \n",
      "  valid loss:\t\t0.08191\n",
      "  valid accuracy:\t0.98805+/-0.01338\n",
      "  valid auc-roc:\t0.98487+/-0.02449\n",
      "  valid auc-pr:\t\t0.83042+/-0.28149\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_37.pickle\n",
      "Epoch 39 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07946 -- accuracy=98.91%  \n",
      "  valid loss:\t\t0.08154\n",
      "  valid accuracy:\t0.98825+/-0.01326\n",
      "  valid auc-roc:\t0.98482+/-0.02476\n",
      "  valid auc-pr:\t\t0.83333+/-0.27725\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_38.pickle\n",
      "Epoch 40 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07931 -- accuracy=98.91%  \n",
      "  valid loss:\t\t0.08080\n",
      "  valid accuracy:\t0.98840+/-0.01323\n",
      "  valid auc-roc:\t0.98557+/-0.02298\n",
      "  valid auc-pr:\t\t0.83749+/-0.27446\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_39.pickle\n",
      "Epoch 41 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07878 -- accuracy=98.94%  \n",
      "  valid loss:\t\t0.08228\n",
      "  valid accuracy:\t0.98790+/-0.01368\n",
      "  valid auc-roc:\t0.98467+/-0.02462\n",
      "  valid auc-pr:\t\t0.83743+/-0.27366\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_40.pickle\n",
      "Epoch 42 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07881 -- accuracy=98.94%  \n",
      "  valid loss:\t\t0.08052\n",
      "  valid accuracy:\t0.98841+/-0.01344\n",
      "  valid auc-roc:\t0.98570+/-0.02293\n",
      "  valid auc-pr:\t\t0.84151+/-0.27178\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_41.pickle\n",
      "Epoch 43 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07866 -- accuracy=98.92%  \n",
      "  valid loss:\t\t0.08090\n",
      "  valid accuracy:\t0.98815+/-0.01313\n",
      "  valid auc-roc:\t0.98501+/-0.02440\n",
      "  valid auc-pr:\t\t0.83853+/-0.27216\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_42.pickle\n",
      "Epoch 44 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07838 -- accuracy=98.94%  \n",
      "  valid loss:\t\t0.08077\n",
      "  valid accuracy:\t0.98812+/-0.01357\n",
      "  valid auc-roc:\t0.98592+/-0.02240\n",
      "  valid auc-pr:\t\t0.83548+/-0.27350\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_43.pickle\n",
      "Epoch 45 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07811 -- accuracy=98.95%  \n",
      "  valid loss:\t\t0.08185\n",
      "  valid accuracy:\t0.98801+/-0.01336\n",
      "  valid auc-roc:\t0.98540+/-0.02320\n",
      "  valid auc-pr:\t\t0.83556+/-0.27381\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_44.pickle\n",
      "Epoch 46 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07797 -- accuracy=98.95%  \n",
      "  valid loss:\t\t0.08244\n",
      "  valid accuracy:\t0.98795+/-0.01345\n",
      "  valid auc-roc:\t0.98452+/-0.02487\n",
      "  valid auc-pr:\t\t0.83552+/-0.27268\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_45.pickle\n",
      "Epoch 47 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07742 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.08110\n",
      "  valid accuracy:\t0.98816+/-0.01353\n",
      "  valid auc-roc:\t0.98597+/-0.02183\n",
      "  valid auc-pr:\t\t0.84079+/-0.26732\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_46.pickle\n",
      "Epoch 48 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07785 -- accuracy=98.95%  \n",
      "  valid loss:\t\t0.08106\n",
      "  valid accuracy:\t0.98815+/-0.01354\n",
      "  valid auc-roc:\t0.98530+/-0.02366\n",
      "  valid auc-pr:\t\t0.83648+/-0.27325\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_47.pickle\n",
      "Epoch 49 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07763 -- accuracy=98.95%  \n",
      "  valid loss:\t\t0.08077\n",
      "  valid accuracy:\t0.98820+/-0.01345\n",
      "  valid auc-roc:\t0.98539+/-0.02284\n",
      "  valid auc-pr:\t\t0.83748+/-0.27190\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_48.pickle\n",
      "Epoch 50 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07721 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.08137\n",
      "  valid accuracy:\t0.98801+/-0.01397\n",
      "  valid auc-roc:\t0.98489+/-0.02398\n",
      "  valid auc-pr:\t\t0.84042+/-0.26896\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=40_G=20_model.pickle_epoch_49.pickle\n",
      "Patience ran out... Early stopping.\n"
     ]
    }
   ],
   "source": [
    "nnmodel = fit.train_minibatch(nnmodel, train, valid, batch_size=128, num_epochs=500, \n",
    "                        patience=5, verbose=1, filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_output(X,layer):\n",
    "    num_data = len(X)\n",
    "    feature_maps = theano.function([nnmodel.input_var], layers.get_output(layer,deterministic=True), allow_input_downcast=True)\n",
    "    map_shape = get_output_shape(layer)\n",
    "\n",
    "    # get feature maps in batches for speed (large batches may be too much memory for GPU)\n",
    "    batch_size=500\n",
    "    num_batches = num_data // batch_size\n",
    "    shape = list(map_shape)\n",
    "    shape[0] = num_data\n",
    "    output = np.empty(tuple(shape))\n",
    "    for i in range(num_batches):\n",
    "        index = range(i*batch_size, (i+1)*batch_size)    \n",
    "        output[index] = feature_maps(X[index])\n",
    "\n",
    "    # get the rest of the feature maps\n",
    "    excess = num_data-num_batches*batch_size\n",
    "    if excess:\n",
    "        index = range(num_data-excess, num_data)  \n",
    "        output[index] = feature_maps(X[index])\n",
    "    return output\n",
    "\n",
    "\n",
    "X = train[0]\n",
    "layer = network['output']\n",
    "output = get_output(X,layer)\n",
    "output2 = get_output(test[0],layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.42133057e-04,   7.29363237e-04,   1.44153927e-03, ...,\n",
       "          2.07574718e-04,   6.90939371e-04,   2.08730984e-04],\n",
       "       [  1.40754730e-06,   6.33123500e-06,   9.45567137e-07, ...,\n",
       "          4.03337845e-06,   8.93052766e-06,   2.23316010e-06],\n",
       "       [  1.74100319e-06,   4.26506676e-06,   5.72989346e-04, ...,\n",
       "          4.08649271e-07,   9.98816967e-01,   1.49824473e-06],\n",
       "       ..., \n",
       "       [  8.79703276e-03,   3.57074663e-03,   5.59500568e-02, ...,\n",
       "          3.42945714e-04,   1.86340720e-03,   2.18206551e-03],\n",
       "       [  9.29904927e-04,   5.79840445e-04,   8.81870627e-01, ...,\n",
       "          1.19490389e-04,   4.58262078e-02,   3.74924624e-04],\n",
       "       [  9.83201200e-04,   1.18163205e-03,   3.83789539e-02, ...,\n",
       "          1.53973815e-04,   1.17378626e-02,   7.43854500e-04]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape2 = list(output.shape)\n",
    "shape2[0] = None\n",
    "input_var2 = T.dmatrix('input')\n",
    "input_var2 = T.cast(input_var2, 'float32')\n",
    "\n",
    "\n",
    "deconv = {}\n",
    "deconv['input'] = InputLayer(tuple(shape2), input_var=input_var2)\n",
    "num_units = list(get_output_shape(network['dense1']))[1]\n",
    "deconv['dense3'] = layers.DenseLayer(deconv['input'], num_units=num_units, W=network['dense3'].W.dimshuffle([1,0]), \n",
    "                                     b=init.Constant(0.05), nonlinearity=nonlinearities.rectify)\n",
    "num_units = np.prod(list(get_output_shape(network['conv2_pool']))[1:])\n",
    "deconv['dense2'] = layers.DenseLayer(deconv['dense3'], num_units=num_units, W=network['dense2'].W.dimshuffle([1,0]), \n",
    "                                     b=init.Constant(0.05), nonlinearity=nonlinearities.rectify)\n",
    "num_units = np.prod(list(get_output_shape(network['conv2_pool']))[1:])\n",
    "deconv['dense1'] = layers.DenseLayer(deconv['dense2'], num_units=num_units, W=network['dense1'].W.dimshuffle([1,0]), \n",
    "                                     b=init.Constant(0.05), nonlinearity=nonlinearities.rectify)\n",
    "\n",
    "shape = list(get_output_shape(network['conv7_pool']))\n",
    "shape[0] = -1\n",
    "deconv['reshape'] = layers.ReshapeLayer(deconv['dense1'], shape=tuple(shape))\n",
    "deconv['pool7'] = layers.Upscale2DLayer(deconv['reshape'], (2,1))\n",
    "deconv['conv7']  = Conv2DLayer(deconv['pool7'], num_filters=network['conv7'].input_shape[1],\n",
    "                                          filter_size=network['conv7'].filter_size,\n",
    "                                          W=network['conv7'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['pool6'] = layers.Upscale2DLayer(deconv['conv7'], (2,1))\n",
    "deconv['conv6']  = Conv2DLayer(deconv['pool6'], num_filters=network['conv6'].input_shape[1],\n",
    "                                          filter_size=network['conv6'].filter_size,\n",
    "                                          W=network['conv6'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['conv5']  = Conv2DLayer(deconv['conv6'], num_filters=network['conv5'].input_shape[1],\n",
    "                                         filter_size=network['conv5'].filter_size,\n",
    "                                          W=network['conv5'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['pool4'] = layers.Upscale2DLayer(deconv['conv5'], (2,1))\n",
    "deconv['conv4']  = Conv2DLayer(deconv['pool7'], num_filters=network['conv4'].input_shape[1],\n",
    "                                          filter_size=network['conv4'].filter_size,\n",
    "                                          W=network['conv4'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['conv3']  = Conv2DLayer(deconv['conv4'], num_filters=network['conv3'].input_shape[1],\n",
    "                                          filter_size=network['conv3'].filter_size,\n",
    "                                          W=network['conv3'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['pool2'] = layers.Upscale2DLayer(deconv['conv3'], (2,1))\n",
    "deconv['conv2']  = Conv2DLayer(deconv['pool2'], num_filters=network['conv2'].input_shape[1],\n",
    "                                          filter_size=network['conv2'].filter_size,\n",
    "                                          W=network['conv2'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['conv1']  = Conv2DLayer(deconv['conv2'], num_filters=network['conv1'].input_shape[1],\n",
    "                                          filter_size=network['conv1'].filter_size,\n",
    "                                          W=network['conv1'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.sigmoid, flip_filters=True)\n",
    "deconv['output'] = deconv['conv1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 20)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1028)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_output_shape(deconv['dense2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 768, 12, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_output_shape(network['conv7_pool'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/peter/.theano/compiledir_Linux-4.2--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.11-64/lock_dir/lock\n"
     ]
    }
   ],
   "source": [
    "target_var = T.tensor4('targets')\n",
    "prediction = layers.get_output(deconv['output'], deterministic=False)\n",
    "\n",
    "loss = (target_var - prediction) ** 2\n",
    "loss = loss.mean()\n",
    "\n",
    "params = layers.get_all_params(deconv['output'], trainable=True)    \n",
    "grad = T.grad(loss, params)\n",
    "\n",
    "update_op = updates.adam(grad, params, learning_rate=0.001)\n",
    "train_fun = theano.function([input_var2, target_var], [loss, prediction], updates=update_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 1 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch in args to gemm (128,20)x(512,1028)->(128,1028)\nApply node that caused the error: GpuDot22(GpuFromHost.0, GpuDimShuffle{1,0}.0)\nToposort index: 49\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(128, 20), (512, 1028)]\nInputs strides: [(20, 1), (1, 512)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Add}[(0, 0)](GpuDot22.0, GpuDimShuffle{x,0}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-303d9378f9ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r  loss = %f \\n\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    869\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 871\u001b[1;33m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[0;32m    872\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m                 \u001b[1;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/theano/gof/link.pyc\u001b[0m in \u001b[0;36mraise_with_op\u001b[1;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# extra long error message in that case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch in args to gemm (128,20)x(512,1028)->(128,1028)\nApply node that caused the error: GpuDot22(GpuFromHost.0, GpuDimShuffle{1,0}.0)\nToposort index: 49\nInputs types: [CudaNdarrayType(float32, matrix), CudaNdarrayType(float32, matrix)]\nInputs shapes: [(128, 20), (512, 1028)]\nInputs strides: [(20, 1), (1, 512)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[GpuElemwise{Add}[(0, 0)](GpuDot22.0, GpuDimShuffle{x,0}.0)]]\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "def batch_generator(X, y, batch_size=128):\n",
    "    for start_idx in range(0, len(X)-batch_size+1, batch_size):\n",
    "        excerpt = slice(start_idx, start_idx+batch_size)\n",
    "        yield X[excerpt].astype(np.float32), y[excerpt].astype(np.float32)\n",
    "\n",
    "batch_size = 128        \n",
    "for epoch in range(50):\n",
    "    sys.stdout.write(\"\\rEpoch %d \\n\"%(epoch+1))\n",
    "\n",
    "    num_batches = output.shape[0] // batch_size\n",
    "    batches = batch_generator(output, train[0], batch_size)\n",
    "    value = 0\n",
    "    for i in range(num_batches):\n",
    "        X,y = next(batches)\n",
    "        loss, prediction = train_fun(X, y)\n",
    "        value += np.mean(loss)\n",
    "    sys.stdout.write(\"\\r  loss = %f \\n\"%(value/num_batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_logo(pwm, height=100, nt_width=20, norm=0, rna=1, filepath='.'):\n",
    "    \"\"\"generate a sequence logo from a pwm\"\"\"\n",
    "    \n",
    "    def load_alphabet(filepath, rna):\n",
    "        \"\"\"load images of nucleotide alphabet \"\"\"\n",
    "        df = pd.read_table(os.path.join(filepath, 'A.txt'), header=None);\n",
    "        A_img = df.as_matrix()\n",
    "        A_img = np.reshape(A_img, [72, 65, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        df = pd.read_table(os.path.join(filepath, 'C.txt'), header=None);\n",
    "        C_img = df.as_matrix()\n",
    "        C_img = np.reshape(C_img, [76, 64, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        df = pd.read_table(os.path.join(filepath, 'G.txt'), header=None);\n",
    "        G_img = df.as_matrix()\n",
    "        G_img = np.reshape(G_img, [76, 67, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        if rna == 1:\n",
    "            df = pd.read_table(os.path.join(filepath, 'U.txt'), header=None);\n",
    "            T_img = df.as_matrix()\n",
    "            T_img = np.reshape(T_img, [74, 57, 3], order=\"F\").astype(np.uint8)\n",
    "        else:\n",
    "            df = pd.read_table(os.path.join(filepath, 'T.txt'), header=None);\n",
    "            T_img = df.as_matrix()\n",
    "            T_img = np.reshape(T_img, [72, 59, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        return A_img, C_img, G_img, T_img\n",
    "\n",
    "\n",
    "    def get_nt_height(pwm, height, norm):\n",
    "        \"\"\"get the heights of each nucleotide\"\"\"\n",
    "\n",
    "        def entropy(p):\n",
    "            \"\"\"calculate entropy of each nucleotide\"\"\"\n",
    "            s = 0\n",
    "            for i in range(4):\n",
    "                if p[i] > 0:\n",
    "                    s -= p[i]*np.log2(p[i])\n",
    "            return s\n",
    "\n",
    "        num_nt, num_seq = pwm.shape\n",
    "        heights = np.zeros((num_nt,num_seq));\n",
    "        for i in range(num_seq):\n",
    "            if norm == 1:\n",
    "                total_height = height\n",
    "            else:\n",
    "                total_height = (np.log2(4) - entropy(pwm[:, i]))*height;\n",
    "            heights[:,i] = np.floor(pwm[:,i]*total_height);\n",
    "        return heights.astype(int)\n",
    "\n",
    "    \n",
    "    # get the alphabet images of each nucleotide\n",
    "    A_img, C_img, G_img, T_img = load_alphabet(filepath='.', rna=1)\n",
    "    \n",
    "    \n",
    "    # get the heights of each nucleotide\n",
    "    heights = get_nt_height(pwm, height, norm)\n",
    "    \n",
    "    # resize nucleotide images for each base of sequence and stack\n",
    "    num_nt, num_seq = pwm.shape\n",
    "    width = np.ceil(nt_width*num_seq).astype(int)\n",
    "    \n",
    "    total_height = np.sum(heights,axis=0)\n",
    "    max_height = np.max(total_height)\n",
    "    logo = np.ones((height*2, width, 3)).astype(int)*255;\n",
    "    for i in range(num_seq):\n",
    "        remaining_height = total_height[i];\n",
    "        offset = max_height-remaining_height\n",
    "        nt_height = np.sort(heights[:,i]);\n",
    "        index = np.argsort(heights[:,i])\n",
    "\n",
    "        for j in range(num_nt):\n",
    "            if nt_height[j] > 0:\n",
    "                # resized dimensions of image\n",
    "                resize = (nt_height[j], nt_width)\n",
    "                if index[j] == 0:\n",
    "                    nt_img = imresize(A_img, resize)\n",
    "                elif index[j] == 1:\n",
    "                    nt_img = imresize(C_img, resize)\n",
    "                elif index[j] == 2:\n",
    "                    nt_img = imresize(G_img, resize)\n",
    "                elif index[j] == 3:\n",
    "                    nt_img = imresize(T_img, resize)\n",
    "\n",
    "                # determine location of image\n",
    "                height_range = range(remaining_height-nt_height[j], remaining_height)\n",
    "                width_range = range(i*nt_width, i*nt_width+nt_width)\n",
    "\n",
    "                # 'annoying' way to broadcast resized nucleotide image\n",
    "                if height_range:\n",
    "                    for k in range(3):\n",
    "                        for m in range(len(width_range)):\n",
    "                            logo[height_range+offset, width_range[m],k] = nt_img[:,m,k];\n",
    "\n",
    "                remaining_height -= nt_height[j]\n",
    "\n",
    "    return logo.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = layers.get_output(deconv['output'], deterministic=False)\n",
    "test_fun = theano.function([input_var2], prediction)\n",
    "\n",
    "class_index = 17\n",
    "\n",
    "labels = np.argmax(test[1],axis=1)\n",
    "map_index = np.where(labels == class_index)[0]\n",
    "for index in map_index[:20]:\n",
    "    \n",
    "    y = np.expand_dims(output2[index,:],0)\n",
    "    prediction = test_fun(y.astype(np.float32))\n",
    "    class_index = np.argmax(test[1][index,:])\n",
    "\n",
    "    height=100\n",
    "    bp_width=20\n",
    "    size = (25.,10.0)\n",
    "\n",
    "    logo = seq_logo(np.squeeze(test[0][index]), height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "\n",
    "    logo = seq_logo(test[2][index], height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "    plt.title(str(class_index),fontsize=20)\n",
    "\n",
    "    logo = seq_logo(np.squeeze(prediction[0]), height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "    plt.title(str(np.argmax(output2[index,:]))+'; p='+str(np.max(output2[index,:])),fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = layers.get_output(deconv['output'], deterministic=False)\n",
    "test_fun = theano.function([input_var2], prediction)\n",
    "\n",
    "\n",
    "for index in range(40,60):\n",
    "\n",
    "    y = np.expand_dims(output2[index,:],0)\n",
    "    prediction = test_fun(y.astype(np.float32))\n",
    "    class_index = np.argmax(test[1][index,:])\n",
    "\n",
    "    height=100\n",
    "    bp_width=20\n",
    "    size = (25.,10.0)\n",
    "\n",
    "    logo = seq_logo(np.squeeze(test[0][index]), height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "\n",
    "    logo = seq_logo(test[2][index], height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "    plt.title(str(class_index),fontsize=20)\n",
    "\n",
    "    logo = seq_logo(np.squeeze(prediction[0]), height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "    plt.title(str(np.argmax(output2[index,:]))+'; p='+str(np.max(output2[index,:])),fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savename = 'unlocalized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_conv_filter(layer,size):\n",
    "    W =  np.squeeze(layer.W.get_value())\n",
    "    num_filters = W.shape[0]\n",
    "\n",
    "    num_rows = int(np.ceil(np.sqrt(num_filters)))    \n",
    "    grid = mpl.gridspec.GridSpec(num_rows, num_rows)\n",
    "    grid.update(wspace=0.2, hspace=0.2, left=0.1, right=0.2, bottom=0.1, top=0.2) \n",
    "    \n",
    "    fig = plt.figure(figsize=size);\n",
    "    for i in range(num_filters):\n",
    "        MIN = np.min(W[i])\n",
    "        MAX = np.max(W[i])\n",
    "        pwm = (W[i] - MIN)#/(MAX-MIN)\n",
    "        norm = np.outer(np.ones(4), np.sum(pwm, axis=0))\n",
    "        pwm = pwm/norm\n",
    "\n",
    "        logo = seq_logo(pwm, height=100, nt_width=25, norm=0, rna=1, filepath='.')\n",
    "        plt.subplot(grid[i]);\n",
    "        plt.imshow(logo);\n",
    "        plt.axis('off');\n",
    "    return fig, plt\n",
    "%config InlineBackend.close_figures = False\n",
    "fig, plt = plot_conv_filter(network['conv1'],size=(100.,100.))\n",
    "fig.set_size_inches(100,100)\n",
    "\n",
    "outfile = savename +'_filter1.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = test[0]\n",
    "input_var = nnmodel.input_var\n",
    "layer = network['conv1_active']\n",
    "\n",
    "# setup theano function to get feature map of a given layer\n",
    "num_data = len(X)\n",
    "feature_maps = theano.function([input_var], layers.get_output(layer), allow_input_downcast=True)\n",
    "map_shape = get_output_shape(layer)\n",
    "\n",
    "# get feature maps in batches for speed (large batches may be too much memory for GPU)\n",
    "num_batches = num_data // batch_size\n",
    "shape = list(map_shape)\n",
    "shape[0] = num_data\n",
    "fmaps = np.empty(tuple(shape))\n",
    "for i in range(num_batches):\n",
    "    index = range(i*batch_size, (i+1)*batch_size)    \n",
    "    fmaps[index] = feature_maps(X[index])\n",
    "\n",
    "# get the rest of the feature maps\n",
    "excess = num_data-num_batches*batch_size\n",
    "index = range(num_data-excess, num_data)    \n",
    "fmaps[index] = feature_maps(X[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_class_activation(fmaps, y, batch_size=512):\n",
    "    fmaps = np.squeeze(fmaps)\n",
    "    mean_activation = []\n",
    "    std_activation = []\n",
    "    for i in range(max(y)+1):\n",
    "        index = np.where(y == i)[0]\n",
    "        mean_activation.append(np.mean(fmaps[index], axis=0))\n",
    "        std_activation.append(np.std(fmaps[index], axis=0))\n",
    "    return np.array(mean_activation), np.array(std_activation)\n",
    "\n",
    "\n",
    "def plot_mean_activations(mean_activation, options):\n",
    "    num_labels = len(mean_activation)\n",
    "    nrows = np.ceil(np.sqrt(num_labels)).astype(int)\n",
    "    ncols = nrows\n",
    "\n",
    "    plt.figure()\n",
    "    grid = mpl.gridspec.GridSpec(nrows, ncols)\n",
    "    grid.update(wspace=0.2, hspace=0.2, left=0.1, right=0.2, bottom=0.1, top=0.2) \n",
    "    \n",
    "    for i in range(num_labels):\n",
    "        plt.subplot(grid[i])\n",
    "        plt.plot(mean_activation[i].T)\n",
    "        fig_options(plt, options)\n",
    "    return plt\n",
    "\n",
    "def fig_options(plt, options):\n",
    "    if 'figsize' in options:\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(options['figsize'][0], options['figsize'][1], forward=True)\n",
    "    if 'ylim' in options:\n",
    "        plt.ylim(options['ylim'][0],options['ylim'][1])\n",
    "    if 'yticks' in options:\n",
    "        plt.yticks(options['yticks'])\n",
    "    if 'xticks' in options:\n",
    "        plt.xticks(options['xticks'])\n",
    "    if 'labelsize' in options:        \n",
    "        ax = plt.gca()\n",
    "        ax.tick_params(axis='x', labelsize=options['labelsize'])\n",
    "        ax.tick_params(axis='y', labelsize=options['labelsize'])\n",
    "    if 'axis' in options:\n",
    "        plt.axis(options['axis'])\n",
    "    if 'xlabel' in options:\n",
    "        plt.xlabel(options['xlabel'], fontsize=options['fontsize'])\n",
    "    if 'ylabel' in options:\n",
    "        plt.ylabel(options['ylabel'], fontsize=options['fontsize'])\n",
    "    if 'linewidth' in options:\n",
    "        plt.rc('axes', linewidth=options['linewidth'])\n",
    "        \n",
    "\n",
    "        \n",
    "mean_activation, std_activation = get_class_activation(fmaps, np.argmax(test[1],axis=1))\n",
    "options = { 'ylim': [0, 4],\n",
    "            'xticks': [0, 50, 100, 150],\n",
    "            'yticks': [0.5, 1.5, 2.5, 3.5], \n",
    "            'labelsize': 18,\n",
    "            'figsize': (150,100)}\n",
    "plt = plot_mean_activations(mean_activation, options)\n",
    "#plt.savefig('categorical_l1_activation.eps', format='eps', dpi=1000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
