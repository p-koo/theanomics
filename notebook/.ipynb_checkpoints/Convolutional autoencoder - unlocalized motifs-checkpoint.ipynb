{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from src import NeuralNet\n",
    "from src import train as fit\n",
    "from src import make_directory \n",
    "from models import load_model\n",
    "from data import load_data\n",
    "from six.moves import cPickle\n",
    "from subprocess import call\n",
    "\n",
    "np.random.seed(247) # for reproducibility\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from lasagne import layers, nonlinearities, updates, objectives, init \n",
    "from lasagne.layers import Conv2DLayer, TransposedConv2DLayer, DenseLayer, InputLayer, ExpressionLayer, BiasLayer\n",
    "\n",
    "from lasagne.layers import get_output, get_output_shape, get_all_params\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "np.random.seed(247) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle\n",
      "loading train data\n",
      "loading cross-validation data\n",
      "loading test data\n"
     ]
    }
   ],
   "source": [
    "filename = 'Unlocalized_N=300000_S=200_M=40_G=20_data.pickle'\n",
    "datapath = '/home/peter/Data/SequenceMotif'\n",
    "filepath = os.path.join(datapath, filename)\n",
    "\n",
    "# load training set\n",
    "print \"loading data from: \" + filepath\n",
    "f = open(filepath, 'rb')\n",
    "print \"loading train data\"\n",
    "train = cPickle.load(f)\n",
    "print \"loading cross-validation data\"\n",
    "cross_validation = cPickle.load(f)\n",
    "print \"loading test data\"\n",
    "test = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "X_train = train[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_train = train[1].astype(np.int32)\n",
    "X_val = cross_validation[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_val = cross_validation[1].astype(np.int32)\n",
    "X_test = test[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_test = test[1].astype(np.int32)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_val = np.expand_dims(X_val, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "train = (X_train, y_train, train[2])\n",
    "valid = (X_val, y_val, cross_validation[2])\n",
    "test = (X_test, y_test, test[2])\n",
    "\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = \"genome_motif_model\"\n",
    "nnmodel = NeuralNet(model_name, shape, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv1': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7f8b26a58750>,\n",
       " 'conv1_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7f8b1d07cd10>,\n",
       " 'conv1_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7f8b1d0e0c10>,\n",
       " 'conv1_bias': <lasagne.layers.special.BiasLayer at 0x7f8b26a58790>,\n",
       " 'conv2': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7f8b26acc610>,\n",
       " 'conv2_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7f8b1d08a710>,\n",
       " 'conv2_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7f8b1d08a050>,\n",
       " 'conv2_bias': <lasagne.layers.special.BiasLayer at 0x7f8b1d07cd50>,\n",
       " 'conv2_pool': <lasagne.layers.pool.MaxPool2DLayer at 0x7f8b1d08a1d0>,\n",
       " 'conv3': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7f8b1d08a750>,\n",
       " 'conv3_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7f8b1d093150>,\n",
       " 'conv3_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7f8b1d08aa50>,\n",
       " 'conv3_bias': <lasagne.layers.special.BiasLayer at 0x7f8b1d08a910>,\n",
       " 'conv4': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7f8b1d08abd0>,\n",
       " 'conv4_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7f8b1d093bd0>,\n",
       " 'conv4_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7f8b1d093450>,\n",
       " 'conv4_bias': <lasagne.layers.special.BiasLayer at 0x7f8b1d093190>,\n",
       " 'conv4_pool': <lasagne.layers.pool.MaxPool2DLayer at 0x7f8b1d0935d0>,\n",
       " 'conv5': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7f8b1d093c10>,\n",
       " 'conv5_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7f8b1d0a2610>,\n",
       " 'conv5_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7f8b1d093f10>,\n",
       " 'conv5_bias': <lasagne.layers.special.BiasLayer at 0x7f8b1d093dd0>,\n",
       " 'conv6': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7f8b1d0a20d0>,\n",
       " 'conv6_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7f8b1d0a2fd0>,\n",
       " 'conv6_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7f8b1d0a2910>,\n",
       " 'conv6_bias': <lasagne.layers.special.BiasLayer at 0x7f8b1d0a2650>,\n",
       " 'conv6_pool': <lasagne.layers.pool.MaxPool2DLayer at 0x7f8b1d0a2a90>,\n",
       " 'conv7': <lasagne.layers.dnn.Conv2DDNNLayer at 0x7f8b1d0ae050>,\n",
       " 'conv7_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7f8b1d0aea10>,\n",
       " 'conv7_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7f8b1d0ae350>,\n",
       " 'conv7_bias': <lasagne.layers.special.BiasLayer at 0x7f8b1d0ae210>,\n",
       " 'conv7_pool': <lasagne.layers.pool.MaxPool2DLayer at 0x7f8b1d0ae4d0>,\n",
       " 'dense1': <lasagne.layers.dense.DenseLayer at 0x7f8b1d0aea50>,\n",
       " 'dense1_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7f8b1d03c810>,\n",
       " 'dense1_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7f8b1d03c110>,\n",
       " 'dense1_bias': <lasagne.layers.special.BiasLayer at 0x7f8b1d0aec10>,\n",
       " 'dense1_dropout': <lasagne.layers.noise.DropoutLayer at 0x7f8b1d03c290>,\n",
       " 'dense2': <lasagne.layers.dense.DenseLayer at 0x7f8b1d0936d0>,\n",
       " 'dense2_active': <lasagne.layers.special.ParametricRectifierLayer at 0x7f8b1d046310>,\n",
       " 'dense2_batch': <lasagne.layers.normalization.BatchNormLayer at 0x7f8b1d03cb90>,\n",
       " 'dense2_bias': <lasagne.layers.special.BiasLayer at 0x7f8b1d03ca50>,\n",
       " 'dense2_dropout': <lasagne.layers.noise.DropoutLayer at 0x7f8b1d03cd50>,\n",
       " 'dense3': <lasagne.layers.dense.DenseLayer at 0x7f8b1d046550>,\n",
       " 'dense3_active': <lasagne.layers.special.NonlinearityLayer at 0x7f8b1d0466d0>,\n",
       " 'dense3_bias': <lasagne.layers.special.BiasLayer at 0x7f8b1d046590>,\n",
       " 'input': <lasagne.layers.input.InputLayer at 0x7f8b26a58710>,\n",
       " 'output': <lasagne.layers.special.NonlinearityLayer at 0x7f8b1d0466d0>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nnmodel.network\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.51418 -- accuracy=97.64%  \n",
      "  valid loss:\t\t0.21820\n",
      "  valid accuracy:\t0.98405+/-0.01211\n",
      "  valid auc-roc:\t0.98460+/-0.01541\n",
      "  valid auc-pr:\t\t0.85658+/-0.14689\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_0.pickle\n",
      "Epoch 2 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.15455 -- accuracy=98.63%  \n",
      "  valid loss:\t\t0.11211\n",
      "  valid accuracy:\t0.98828+/-0.01133\n",
      "  valid auc-roc:\t0.99055+/-0.01028\n",
      "  valid auc-pr:\t\t0.90228+/-0.10904\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_1.pickle\n",
      "Epoch 3 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.10353 -- accuracy=98.79%  \n",
      "  valid loss:\t\t0.09141\n",
      "  valid accuracy:\t0.98893+/-0.01108\n",
      "  valid auc-roc:\t0.99166+/-0.00944\n",
      "  valid auc-pr:\t\t0.91001+/-0.10443\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_2.pickle\n",
      "Epoch 4 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.09036 -- accuracy=98.85%  \n",
      "  valid loss:\t\t0.08161\n",
      "  valid accuracy:\t0.98992+/-0.01046\n",
      "  valid auc-roc:\t0.99247+/-0.00836\n",
      "  valid auc-pr:\t\t0.91625+/-0.09800\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_3.pickle\n",
      "Epoch 5 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08416 -- accuracy=98.89%  \n",
      "  valid loss:\t\t0.07800\n",
      "  valid accuracy:\t0.99003+/-0.01021\n",
      "  valid auc-roc:\t0.99292+/-0.00809\n",
      "  valid auc-pr:\t\t0.91937+/-0.09641\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_4.pickle\n",
      "Epoch 6 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07990 -- accuracy=98.91%  \n",
      "  valid loss:\t\t0.07451\n",
      "  valid accuracy:\t0.99001+/-0.01035\n",
      "  valid auc-roc:\t0.99298+/-0.00815\n",
      "  valid auc-pr:\t\t0.92141+/-0.09520\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_5.pickle\n",
      "Epoch 7 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07716 -- accuracy=98.92%  \n",
      "  valid loss:\t\t0.07141\n",
      "  valid accuracy:\t0.99031+/-0.01040\n",
      "  valid auc-roc:\t0.99309+/-0.00823\n",
      "  valid auc-pr:\t\t0.92350+/-0.09277\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_6.pickle\n",
      "Epoch 8 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07443 -- accuracy=98.94%  \n",
      "  valid loss:\t\t0.06978\n",
      "  valid accuracy:\t0.99007+/-0.01040\n",
      "  valid auc-roc:\t0.99286+/-0.00832\n",
      "  valid auc-pr:\t\t0.92137+/-0.09497\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_7.pickle\n",
      "Epoch 9 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07267 -- accuracy=98.93%  \n",
      "  valid loss:\t\t0.06746\n",
      "  valid accuracy:\t0.99029+/-0.01050\n",
      "  valid auc-roc:\t0.99332+/-0.00783\n",
      "  valid auc-pr:\t\t0.92510+/-0.09054\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_8.pickle\n",
      "Epoch 10 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07104 -- accuracy=98.94%  \n",
      "  valid loss:\t\t0.06626\n",
      "  valid accuracy:\t0.99037+/-0.01024\n",
      "  valid auc-roc:\t0.99328+/-0.00770\n",
      "  valid auc-pr:\t\t0.92433+/-0.09129\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_9.pickle\n",
      "Epoch 11 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06989 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.06615\n",
      "  valid accuracy:\t0.99020+/-0.01040\n",
      "  valid auc-roc:\t0.99303+/-0.00803\n",
      "  valid auc-pr:\t\t0.92311+/-0.09336\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_10.pickle\n",
      "Epoch 12 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06913 -- accuracy=98.95%  \n",
      "  valid loss:\t\t0.06432\n",
      "  valid accuracy:\t0.99043+/-0.01006\n",
      "  valid auc-roc:\t0.99338+/-0.00792\n",
      "  valid auc-pr:\t\t0.92578+/-0.09081\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_11.pickle\n",
      "Epoch 13 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06811 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.06357\n",
      "  valid accuracy:\t0.99052+/-0.01001\n",
      "  valid auc-roc:\t0.99348+/-0.00765\n",
      "  valid auc-pr:\t\t0.92672+/-0.09000\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_12.pickle\n",
      "Epoch 14 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06736 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.06229\n",
      "  valid accuracy:\t0.99065+/-0.00998\n",
      "  valid auc-roc:\t0.99353+/-0.00781\n",
      "  valid auc-pr:\t\t0.92582+/-0.09137\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_13.pickle\n",
      "Epoch 15 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06697 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.06221\n",
      "  valid accuracy:\t0.99057+/-0.01013\n",
      "  valid auc-roc:\t0.99342+/-0.00775\n",
      "  valid auc-pr:\t\t0.92622+/-0.08964\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_14.pickle\n",
      "Epoch 16 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06621 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.06188\n",
      "  valid accuracy:\t0.99052+/-0.01019\n",
      "  valid auc-roc:\t0.99344+/-0.00751\n",
      "  valid auc-pr:\t\t0.92626+/-0.08927\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_15.pickle\n",
      "Epoch 17 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06573 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.06111\n",
      "  valid accuracy:\t0.99070+/-0.01005\n",
      "  valid auc-roc:\t0.99346+/-0.00765\n",
      "  valid auc-pr:\t\t0.92474+/-0.09307\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_16.pickle\n",
      "Epoch 18 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06558 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.06064\n",
      "  valid accuracy:\t0.99075+/-0.00984\n",
      "  valid auc-roc:\t0.99356+/-0.00755\n",
      "  valid auc-pr:\t\t0.92672+/-0.08967\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_17.pickle\n",
      "Epoch 19 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06507 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.06104\n",
      "  valid accuracy:\t0.99037+/-0.01028\n",
      "  valid auc-roc:\t0.99326+/-0.00784\n",
      "  valid auc-pr:\t\t0.92538+/-0.09169\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_18.pickle\n",
      "Epoch 20 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06487 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.06050\n",
      "  valid accuracy:\t0.99056+/-0.01043\n",
      "  valid auc-roc:\t0.99369+/-0.00745\n",
      "  valid auc-pr:\t\t0.92637+/-0.09193\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_19.pickle\n",
      "Epoch 21 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06459 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05987\n",
      "  valid accuracy:\t0.99065+/-0.01010\n",
      "  valid auc-roc:\t0.99349+/-0.00780\n",
      "  valid auc-pr:\t\t0.92631+/-0.09217\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_20.pickle\n",
      "Epoch 22 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06432 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05957\n",
      "  valid accuracy:\t0.99070+/-0.00997\n",
      "  valid auc-roc:\t0.99361+/-0.00755\n",
      "  valid auc-pr:\t\t0.92669+/-0.09045\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_21.pickle\n",
      "Epoch 23 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06413 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05981\n",
      "  valid accuracy:\t0.99056+/-0.01013\n",
      "  valid auc-roc:\t0.99355+/-0.00756\n",
      "  valid auc-pr:\t\t0.92597+/-0.09142\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_22.pickle\n",
      "Epoch 24 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06397 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05931\n",
      "  valid accuracy:\t0.99061+/-0.01009\n",
      "  valid auc-roc:\t0.99358+/-0.00751\n",
      "  valid auc-pr:\t\t0.92603+/-0.09124\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_23.pickle\n",
      "Epoch 25 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06371 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05914\n",
      "  valid accuracy:\t0.99068+/-0.00980\n",
      "  valid auc-roc:\t0.99352+/-0.00755\n",
      "  valid auc-pr:\t\t0.92687+/-0.08943\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_24.pickle\n",
      "Epoch 26 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06353 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05951\n",
      "  valid accuracy:\t0.99047+/-0.01034\n",
      "  valid auc-roc:\t0.99327+/-0.00810\n",
      "  valid auc-pr:\t\t0.92532+/-0.09339\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_25.pickle\n",
      "Epoch 27 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06344 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05881\n",
      "  valid accuracy:\t0.99068+/-0.01011\n",
      "  valid auc-roc:\t0.99350+/-0.00766\n",
      "  valid auc-pr:\t\t0.92681+/-0.09082\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_26.pickle\n",
      "Epoch 28 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06334 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05836\n",
      "  valid accuracy:\t0.99070+/-0.01010\n",
      "  valid auc-roc:\t0.99363+/-0.00750\n",
      "  valid auc-pr:\t\t0.92778+/-0.08921\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_27.pickle\n",
      "Epoch 29 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06316 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05906\n",
      "  valid accuracy:\t0.99045+/-0.01015\n",
      "  valid auc-roc:\t0.99355+/-0.00772\n",
      "  valid auc-pr:\t\t0.92617+/-0.09101\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_28.pickle\n",
      "Epoch 30 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06292 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05828\n",
      "  valid accuracy:\t0.99069+/-0.00987\n",
      "  valid auc-roc:\t0.99356+/-0.00749\n",
      "  valid auc-pr:\t\t0.92757+/-0.08954\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_29.pickle\n",
      "Epoch 31 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06254 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05901\n",
      "  valid accuracy:\t0.99044+/-0.00988\n",
      "  valid auc-roc:\t0.99351+/-0.00767\n",
      "  valid auc-pr:\t\t0.92718+/-0.08968\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_30.pickle\n",
      "Epoch 32 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06258 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05731\n",
      "  valid accuracy:\t0.99084+/-0.00979\n",
      "  valid auc-roc:\t0.99381+/-0.00738\n",
      "  valid auc-pr:\t\t0.92816+/-0.08974\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_31.pickle\n",
      "Epoch 33 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06242 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05820\n",
      "  valid accuracy:\t0.99044+/-0.01045\n",
      "  valid auc-roc:\t0.99338+/-0.00797\n",
      "  valid auc-pr:\t\t0.92563+/-0.09252\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_32.pickle\n",
      "Epoch 34 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06218 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05738\n",
      "  valid accuracy:\t0.99067+/-0.01009\n",
      "  valid auc-roc:\t0.99376+/-0.00725\n",
      "  valid auc-pr:\t\t0.92847+/-0.08822\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_33.pickle\n",
      "Epoch 35 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06200 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05750\n",
      "  valid accuracy:\t0.99063+/-0.01023\n",
      "  valid auc-roc:\t0.99340+/-0.00772\n",
      "  valid auc-pr:\t\t0.92672+/-0.09054\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_34.pickle\n",
      "Epoch 36 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06206 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05730\n",
      "  valid accuracy:\t0.99074+/-0.00991\n",
      "  valid auc-roc:\t0.99349+/-0.00763\n",
      "  valid auc-pr:\t\t0.92766+/-0.08969\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_35.pickle\n",
      "Epoch 37 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06172 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05693\n",
      "  valid accuracy:\t0.99066+/-0.01007\n",
      "  valid auc-roc:\t0.99359+/-0.00727\n",
      "  valid auc-pr:\t\t0.92787+/-0.08917\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_36.pickle\n",
      "Epoch 38 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06175 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05681\n",
      "  valid accuracy:\t0.99081+/-0.00986\n",
      "  valid auc-roc:\t0.99350+/-0.00780\n",
      "  valid auc-pr:\t\t0.92750+/-0.09013\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_37.pickle\n",
      "Epoch 39 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06163 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05723\n",
      "  valid accuracy:\t0.99071+/-0.00989\n",
      "  valid auc-roc:\t0.99370+/-0.00730\n",
      "  valid auc-pr:\t\t0.92760+/-0.08876\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_38.pickle\n",
      "Epoch 40 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06153 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05757\n",
      "  valid accuracy:\t0.99047+/-0.01021\n",
      "  valid auc-roc:\t0.99358+/-0.00764\n",
      "  valid auc-pr:\t\t0.92682+/-0.09108\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_39.pickle\n",
      "Epoch 41 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06141 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05672\n",
      "  valid accuracy:\t0.99061+/-0.01019\n",
      "  valid auc-roc:\t0.99386+/-0.00735\n",
      "  valid auc-pr:\t\t0.92849+/-0.08931\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_40.pickle\n",
      "Epoch 42 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06127 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05641\n",
      "  valid accuracy:\t0.99066+/-0.01017\n",
      "  valid auc-roc:\t0.99353+/-0.00768\n",
      "  valid auc-pr:\t\t0.92778+/-0.09000\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_41.pickle\n",
      "Epoch 43 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06097 -- accuracy=98.98%  \n",
      "  valid loss:\t\t0.05688\n",
      "  valid accuracy:\t0.99046+/-0.01031\n",
      "  valid auc-roc:\t0.99356+/-0.00740\n",
      "  valid auc-pr:\t\t0.92696+/-0.08845\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_42.pickle\n",
      "Epoch 44 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06113 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05616\n",
      "  valid accuracy:\t0.99072+/-0.00997\n",
      "  valid auc-roc:\t0.99360+/-0.00763\n",
      "  valid auc-pr:\t\t0.92755+/-0.08983\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_43.pickle\n",
      "Epoch 45 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06089 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05640\n",
      "  valid accuracy:\t0.99061+/-0.01015\n",
      "  valid auc-roc:\t0.99348+/-0.00779\n",
      "  valid auc-pr:\t\t0.92621+/-0.09201\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_44.pickle\n",
      "Epoch 46 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06074 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05579\n",
      "  valid accuracy:\t0.99077+/-0.00990\n",
      "  valid auc-roc:\t0.99388+/-0.00733\n",
      "  valid auc-pr:\t\t0.92904+/-0.08769\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_45.pickle\n",
      "Epoch 47 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06068 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05553\n",
      "  valid accuracy:\t0.99088+/-0.00979\n",
      "  valid auc-roc:\t0.99382+/-0.00734\n",
      "  valid auc-pr:\t\t0.92821+/-0.08827\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_46.pickle\n",
      "Epoch 48 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06067 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05591\n",
      "  valid accuracy:\t0.99070+/-0.00990\n",
      "  valid auc-roc:\t0.99378+/-0.00728\n",
      "  valid auc-pr:\t\t0.92799+/-0.08817\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_47.pickle\n",
      "Epoch 49 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06052 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05574\n",
      "  valid accuracy:\t0.99088+/-0.00995\n",
      "  valid auc-roc:\t0.99381+/-0.00748\n",
      "  valid auc-pr:\t\t0.92836+/-0.08828\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_48.pickle\n",
      "Epoch 50 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06059 -- accuracy=98.96%  \n",
      "  valid loss:\t\t0.05610\n",
      "  valid accuracy:\t0.99084+/-0.00993\n",
      "  valid auc-roc:\t0.99352+/-0.00752\n",
      "  valid auc-pr:\t\t0.92739+/-0.08908\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_49.pickle\n",
      "Epoch 51 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06035 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05659\n",
      "  valid accuracy:\t0.99041+/-0.01034\n",
      "  valid auc-roc:\t0.99351+/-0.00759\n",
      "  valid auc-pr:\t\t0.92726+/-0.08946\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_50.pickle\n",
      "Epoch 52 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06033 -- accuracy=98.97%  \n",
      "  valid loss:\t\t0.05586\n",
      "  valid accuracy:\t0.99062+/-0.01001\n",
      "  valid auc-roc:\t0.99361+/-0.00756\n",
      "  valid auc-pr:\t\t0.92760+/-0.08971\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=300000_S=200_M=40_G=20_data.pickle_epoch_51.pickle\n",
      "Patience ran out... Early stopping.\n"
     ]
    }
   ],
   "source": [
    "nnmodel = fit.train_minibatch(nnmodel, train, valid, batch_size=128, num_epochs=500, \n",
    "                        patience=4, verbose=1, filepath=filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_output(X,layer):\n",
    "    num_data = len(X)\n",
    "    feature_maps = theano.function([nnmodel.input_var], layers.get_output(layer,deterministic=True), allow_input_downcast=True)\n",
    "    map_shape = get_output_shape(layer)\n",
    "\n",
    "    # get feature maps in batches for speed (large batches may be too much memory for GPU)\n",
    "    batch_size=500\n",
    "    num_batches = num_data // batch_size\n",
    "    shape = list(map_shape)\n",
    "    shape[0] = num_data\n",
    "    output = np.empty(tuple(shape))\n",
    "    for i in range(num_batches):\n",
    "        index = range(i*batch_size, (i+1)*batch_size)    \n",
    "        output[index] = feature_maps(X[index])\n",
    "\n",
    "    # get the rest of the feature maps\n",
    "    excess = num_data-num_batches*batch_size\n",
    "    if excess:\n",
    "        index = range(num_data-excess, num_data)  \n",
    "        output[index] = feature_maps(X[index])\n",
    "    return output\n",
    "\n",
    "\n",
    "X = train[0]\n",
    "layer = network['output']\n",
    "output = get_output(X,layer)\n",
    "output2 = get_output(test[0],layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.30614335e-08,   2.61282690e-10,   1.91731502e-07, ...,\n",
       "          7.93220956e-09,   1.13317249e-07,   1.93049049e-11],\n",
       "       [  4.82785617e-05,   3.58435273e-06,   2.21820199e-04, ...,\n",
       "          6.33252639e-05,   1.08677712e-04,   4.05831497e-06],\n",
       "       [  2.35297748e-07,   9.99946475e-01,   6.42168961e-05, ...,\n",
       "          1.03690398e-08,   1.65541896e-05,   1.17887220e-08],\n",
       "       ..., \n",
       "       [  9.99962568e-01,   3.38800155e-10,   1.72957170e-05, ...,\n",
       "          2.24123817e-10,   7.72673943e-08,   1.72863557e-12],\n",
       "       [  2.80625816e-03,   4.28134954e-04,   3.05374831e-01, ...,\n",
       "          8.19235458e-04,   3.67251784e-02,   3.90481233e-04],\n",
       "       [  1.40958204e-04,   3.42122294e-05,   1.03746810e-04, ...,\n",
       "          2.42993701e-03,   6.16136298e-04,   4.51855431e-06]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape2 = list(output.shape)\n",
    "shape2[0] = None\n",
    "input_var2 = T.dmatrix('input')\n",
    "input_var2 = T.cast(input_var2, 'float32')\n",
    "\n",
    "\n",
    "deconv = {}\n",
    "deconv['input'] = InputLayer(tuple(shape2), input_var=input_var2)\n",
    "num_units = list(get_output_shape(network['dense2']))[1]\n",
    "deconv['dense3'] = layers.DenseLayer(deconv['input'], num_units=num_units, W=network['dense3'].W.dimshuffle([1,0]), \n",
    "                                     b=init.Constant(0.05), nonlinearity=nonlinearities.rectify)\n",
    "num_units = np.prod(list(get_output_shape(network['dense1']))[1:])\n",
    "deconv['dense2'] = layers.DenseLayer(deconv['dense3'], num_units=num_units, W=network['dense2'].W.dimshuffle([1,0]), \n",
    "                                     b=init.Constant(0.05), nonlinearity=nonlinearities.rectify)\n",
    "num_units = np.prod(list(get_output_shape(network['conv7_pool']))[1:])\n",
    "deconv['dense1'] = layers.DenseLayer(deconv['dense2'], num_units=num_units, W=network['dense1'].W.dimshuffle([1,0]), \n",
    "                                     b=init.Constant(0.05), nonlinearity=nonlinearities.rectify)\n",
    "\n",
    "shape = list(get_output_shape(network['conv7_pool']))\n",
    "shape[0] = -1\n",
    "deconv['reshape'] = layers.ReshapeLayer(deconv['dense1'], shape=tuple(shape))\n",
    "deconv['pool7'] = layers.Upscale2DLayer(deconv['reshape'], (5,1))\n",
    "deconv['conv7']  = Conv2DLayer(deconv['pool7'], num_filters=network['conv7'].input_shape[1],\n",
    "                                          filter_size=network['conv7'].filter_size,\n",
    "                                          W=network['conv7'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['pool6'] = layers.Upscale2DLayer(deconv['conv7'], (2,1))\n",
    "deconv['conv6']  = Conv2DLayer(deconv['pool6'], num_filters=network['conv6'].input_shape[1],\n",
    "                                          filter_size=network['conv6'].filter_size,\n",
    "                                          W=network['conv6'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['conv5']  = Conv2DLayer(deconv['conv6'], num_filters=network['conv5'].input_shape[1],\n",
    "                                         filter_size=network['conv5'].filter_size,\n",
    "                                          W=network['conv5'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['pool4'] = layers.Upscale2DLayer(deconv['conv5'], (2,1))\n",
    "deconv['conv4']  = Conv2DLayer(deconv['pool4'], num_filters=network['conv4'].input_shape[1],\n",
    "                                          filter_size=network['conv4'].filter_size,\n",
    "                                          W=network['conv4'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['conv3']  = Conv2DLayer(deconv['conv4'], num_filters=network['conv3'].input_shape[1],\n",
    "                                          filter_size=network['conv3'].filter_size,\n",
    "                                          W=network['conv3'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['pool2'] = layers.Upscale2DLayer(deconv['conv3'], (2,1))\n",
    "deconv['conv2']  = Conv2DLayer(deconv['pool2'], num_filters=network['conv2'].input_shape[1],\n",
    "                                          filter_size=network['conv2'].filter_size,\n",
    "                                          W=network['conv2'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.rectify, flip_filters=True)\n",
    "\n",
    "deconv['conv1']  = Conv2DLayer(deconv['conv2'], num_filters=network['conv1'].input_shape[1],\n",
    "                                          filter_size=network['conv1'].filter_size,\n",
    "                                          W=network['conv1'].W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=init.Constant(0.05), \n",
    "                                          pad='same',\n",
    "                                          nonlinearity=nonlinearities.sigmoid, flip_filters=True)\n",
    "deconv['output'] = deconv['conv1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_var = T.tensor4('targets')\n",
    "prediction = layers.get_output(deconv['output'], deterministic=False)\n",
    "loss = objectives.squared_error(input_var2, prediction)\n",
    "loss = objectives.aggregate(loss)\n",
    "\n",
    "params = layers.get_all_params(deconv['output'], trainable=True)    \n",
    "grad = T.grad(loss, params)\n",
    "\n",
    "update_op = updates.adam(grad, params, learning_rate=0.001)\n",
    "train_fun = theano.function([input_var2], [loss, prediction], updates=update_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \n",
      "  loss = 19221.326850 \n",
      "Epoch 2 \n",
      "  loss = 19126.212508 \n",
      "Epoch 3 \n",
      "  loss = 19122.596793 \n",
      "Epoch 4 \n",
      "  loss = 19120.314215 \n",
      "Epoch 5 \n",
      "  loss = 19118.159457 \n",
      "Epoch 6 \n",
      "  loss = 19116.540221 \n",
      "Epoch 7 \n",
      "  loss = 19115.148875 \n",
      "Epoch 8 \n",
      "  loss = 19113.994042 \n",
      "Epoch 9 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-651440ff5e2f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\r  loss = %f \\n\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def batch_generator(X, y, batch_size=128):\n",
    "    for start_idx in range(0, len(X)-batch_size+1, batch_size):\n",
    "        excerpt = slice(start_idx, start_idx+batch_size)\n",
    "        yield X[excerpt].astype(np.float32))\n",
    "\n",
    "batch_size = 128        \n",
    "for epoch in range(200):\n",
    "    sys.stdout.write(\"\\rEpoch %d \\n\"%(epoch+1))\n",
    "\n",
    "    num_batches = output.shape[0] // batch_size\n",
    "    batches = batch_generator(train[0], batch_size)\n",
    "    value = 0\n",
    "    for i in range(num_batches):\n",
    "        X = next(batches)\n",
    "        loss, prediction = train_fun(X)\n",
    "        value += np.mean(loss)\n",
    "    sys.stdout.write(\"\\r  loss = %f \\n\"%(value/num_batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq_logo(pwm, height=100, nt_width=20, norm=0, rna=1, filepath='.'):\n",
    "    \"\"\"generate a sequence logo from a pwm\"\"\"\n",
    "    \n",
    "    def load_alphabet(filepath, rna):\n",
    "        \"\"\"load images of nucleotide alphabet \"\"\"\n",
    "        df = pd.read_table(os.path.join(filepath, 'A.txt'), header=None);\n",
    "        A_img = df.as_matrix()\n",
    "        A_img = np.reshape(A_img, [72, 65, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        df = pd.read_table(os.path.join(filepath, 'C.txt'), header=None);\n",
    "        C_img = df.as_matrix()\n",
    "        C_img = np.reshape(C_img, [76, 64, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        df = pd.read_table(os.path.join(filepath, 'G.txt'), header=None);\n",
    "        G_img = df.as_matrix()\n",
    "        G_img = np.reshape(G_img, [76, 67, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        if rna == 1:\n",
    "            df = pd.read_table(os.path.join(filepath, 'U.txt'), header=None);\n",
    "            T_img = df.as_matrix()\n",
    "            T_img = np.reshape(T_img, [74, 57, 3], order=\"F\").astype(np.uint8)\n",
    "        else:\n",
    "            df = pd.read_table(os.path.join(filepath, 'T.txt'), header=None);\n",
    "            T_img = df.as_matrix()\n",
    "            T_img = np.reshape(T_img, [72, 59, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        return A_img, C_img, G_img, T_img\n",
    "\n",
    "\n",
    "    def get_nt_height(pwm, height, norm):\n",
    "        \"\"\"get the heights of each nucleotide\"\"\"\n",
    "\n",
    "        def entropy(p):\n",
    "            \"\"\"calculate entropy of each nucleotide\"\"\"\n",
    "            s = 0\n",
    "            for i in range(4):\n",
    "                if p[i] > 0:\n",
    "                    s -= p[i]*np.log2(p[i])\n",
    "            return s\n",
    "\n",
    "        num_nt, num_seq = pwm.shape\n",
    "        heights = np.zeros((num_nt,num_seq));\n",
    "        for i in range(num_seq):\n",
    "            if norm == 1:\n",
    "                total_height = height\n",
    "            else:\n",
    "                total_height = (np.log2(4) - entropy(pwm[:, i]))*height;\n",
    "            heights[:,i] = np.floor(pwm[:,i]*total_height);\n",
    "        return heights.astype(int)\n",
    "\n",
    "    \n",
    "    # get the alphabet images of each nucleotide\n",
    "    A_img, C_img, G_img, T_img = load_alphabet(filepath='.', rna=1)\n",
    "    \n",
    "    \n",
    "    # get the heights of each nucleotide\n",
    "    heights = get_nt_height(pwm, height, norm)\n",
    "    \n",
    "    # resize nucleotide images for each base of sequence and stack\n",
    "    num_nt, num_seq = pwm.shape\n",
    "    width = np.ceil(nt_width*num_seq).astype(int)\n",
    "    \n",
    "    total_height = np.sum(heights,axis=0)\n",
    "    max_height = np.max(total_height)\n",
    "    logo = np.ones((height*2, width, 3)).astype(int)*255;\n",
    "    for i in range(num_seq):\n",
    "        remaining_height = total_height[i];\n",
    "        offset = max_height-remaining_height\n",
    "        nt_height = np.sort(heights[:,i]);\n",
    "        index = np.argsort(heights[:,i])\n",
    "\n",
    "        for j in range(num_nt):\n",
    "            if nt_height[j] > 0:\n",
    "                # resized dimensions of image\n",
    "                resize = (nt_height[j], nt_width)\n",
    "                if index[j] == 0:\n",
    "                    nt_img = imresize(A_img, resize)\n",
    "                elif index[j] == 1:\n",
    "                    nt_img = imresize(C_img, resize)\n",
    "                elif index[j] == 2:\n",
    "                    nt_img = imresize(G_img, resize)\n",
    "                elif index[j] == 3:\n",
    "                    nt_img = imresize(T_img, resize)\n",
    "\n",
    "                # determine location of image\n",
    "                height_range = range(remaining_height-nt_height[j], remaining_height)\n",
    "                width_range = range(i*nt_width, i*nt_width+nt_width)\n",
    "\n",
    "                # 'annoying' way to broadcast resized nucleotide image\n",
    "                if height_range:\n",
    "                    for k in range(3):\n",
    "                        for m in range(len(width_range)):\n",
    "                            logo[height_range+offset, width_range[m],k] = nt_img[:,m,k];\n",
    "\n",
    "                remaining_height -= nt_height[j]\n",
    "\n",
    "    return logo.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = layers.get_output(deconv['output'], deterministic=False)\n",
    "test_fun = theano.function([input_var2], prediction)\n",
    "\n",
    "class_index = 17\n",
    "\n",
    "labels = np.argmax(test[1],axis=1)\n",
    "map_index = np.where(labels == class_index)[0]\n",
    "for index in map_index[:20]:\n",
    "    \n",
    "    y = np.expand_dims(output2[index,:],0)\n",
    "    prediction = test_fun(y.astype(np.float32))\n",
    "    class_index = np.argmax(test[1][index,:])\n",
    "\n",
    "    height=100\n",
    "    bp_width=20\n",
    "    size = (25.,10.0)\n",
    "\n",
    "    logo = seq_logo(np.squeeze(test[0][index]), height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "\n",
    "    logo = seq_logo(test[2][index], height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "    plt.title(str(class_index),fontsize=20)\n",
    "\n",
    "    logo = seq_logo(np.squeeze(prediction[0]), height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "    plt.title(str(np.argmax(output2[index,:]))+'; p='+str(np.max(output2[index,:])),fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = layers.get_output(deconv['output'], deterministic=False)\n",
    "test_fun = theano.function([input_var2], prediction)\n",
    "\n",
    "\n",
    "for index in range(40,60):\n",
    "\n",
    "    y = np.expand_dims(output2[index,:],0)\n",
    "    prediction = test_fun(y.astype(np.float32))\n",
    "    class_index = np.argmax(test[1][index,:])\n",
    "\n",
    "    height=100\n",
    "    bp_width=20\n",
    "    size = (25.,10.0)\n",
    "\n",
    "    logo = seq_logo(np.squeeze(test[0][index]), height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "\n",
    "    logo = seq_logo(test[2][index], height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "    plt.title(str(class_index),fontsize=20)\n",
    "\n",
    "    logo = seq_logo(np.squeeze(prediction[0]), height, bp_width, norm=0, rna=1, filepath='.')\n",
    "    fig = plt.figure(figsize=size);\n",
    "    plt.imshow(logo, interpolation='none');\n",
    "    plt.axis('off');\n",
    "    plt.title(str(np.argmax(output2[index,:]))+'; p='+str(np.max(output2[index,:])),fontsize=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savename = 'unlocalized'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_conv_filter(layer,size):\n",
    "    W =  np.squeeze(layer.W.get_value())\n",
    "    num_filters = W.shape[0]\n",
    "\n",
    "    num_rows = int(np.ceil(np.sqrt(num_filters)))    \n",
    "    grid = mpl.gridspec.GridSpec(num_rows, num_rows)\n",
    "    grid.update(wspace=0.2, hspace=0.2, left=0.1, right=0.2, bottom=0.1, top=0.2) \n",
    "    \n",
    "    fig = plt.figure(figsize=size);\n",
    "    for i in range(num_filters):\n",
    "        MIN = np.min(W[i])\n",
    "        MAX = np.max(W[i])\n",
    "        pwm = (W[i] - MIN)#/(MAX-MIN)\n",
    "        norm = np.outer(np.ones(4), np.sum(pwm, axis=0))\n",
    "        pwm = pwm/norm\n",
    "\n",
    "        logo = seq_logo(pwm, height=100, nt_width=25, norm=0, rna=1, filepath='.')\n",
    "        plt.subplot(grid[i]);\n",
    "        plt.imshow(logo);\n",
    "        plt.axis('off');\n",
    "    return fig, plt\n",
    "%config InlineBackend.close_figures = False\n",
    "fig, plt = plot_conv_filter(network['conv1'],size=(100.,100.))\n",
    "fig.set_size_inches(100,100)\n",
    "\n",
    "outfile = savename +'_filter1.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = test[0]\n",
    "input_var = nnmodel.input_var\n",
    "layer = network['conv1_active']\n",
    "\n",
    "# setup theano function to get feature map of a given layer\n",
    "num_data = len(X)\n",
    "feature_maps = theano.function([input_var], layers.get_output(layer), allow_input_downcast=True)\n",
    "map_shape = get_output_shape(layer)\n",
    "\n",
    "# get feature maps in batches for speed (large batches may be too much memory for GPU)\n",
    "num_batches = num_data // batch_size\n",
    "shape = list(map_shape)\n",
    "shape[0] = num_data\n",
    "fmaps = np.empty(tuple(shape))\n",
    "for i in range(num_batches):\n",
    "    index = range(i*batch_size, (i+1)*batch_size)    \n",
    "    fmaps[index] = feature_maps(X[index])\n",
    "\n",
    "# get the rest of the feature maps\n",
    "excess = num_data-num_batches*batch_size\n",
    "index = range(num_data-excess, num_data)    \n",
    "fmaps[index] = feature_maps(X[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_class_activation(fmaps, y, batch_size=512):\n",
    "    fmaps = np.squeeze(fmaps)\n",
    "    mean_activation = []\n",
    "    std_activation = []\n",
    "    for i in range(max(y)+1):\n",
    "        index = np.where(y == i)[0]\n",
    "        mean_activation.append(np.mean(fmaps[index], axis=0))\n",
    "        std_activation.append(np.std(fmaps[index], axis=0))\n",
    "    return np.array(mean_activation), np.array(std_activation)\n",
    "\n",
    "\n",
    "def plot_mean_activations(mean_activation, options):\n",
    "    num_labels = len(mean_activation)\n",
    "    nrows = np.ceil(np.sqrt(num_labels)).astype(int)\n",
    "    ncols = nrows\n",
    "\n",
    "    plt.figure()\n",
    "    grid = mpl.gridspec.GridSpec(nrows, ncols)\n",
    "    grid.update(wspace=0.2, hspace=0.2, left=0.1, right=0.2, bottom=0.1, top=0.2) \n",
    "    \n",
    "    for i in range(num_labels):\n",
    "        plt.subplot(grid[i])\n",
    "        plt.plot(mean_activation[i].T)\n",
    "        fig_options(plt, options)\n",
    "    return plt\n",
    "\n",
    "def fig_options(plt, options):\n",
    "    if 'figsize' in options:\n",
    "        fig = plt.gcf()\n",
    "        fig.set_size_inches(options['figsize'][0], options['figsize'][1], forward=True)\n",
    "    if 'ylim' in options:\n",
    "        plt.ylim(options['ylim'][0],options['ylim'][1])\n",
    "    if 'yticks' in options:\n",
    "        plt.yticks(options['yticks'])\n",
    "    if 'xticks' in options:\n",
    "        plt.xticks(options['xticks'])\n",
    "    if 'labelsize' in options:        \n",
    "        ax = plt.gca()\n",
    "        ax.tick_params(axis='x', labelsize=options['labelsize'])\n",
    "        ax.tick_params(axis='y', labelsize=options['labelsize'])\n",
    "    if 'axis' in options:\n",
    "        plt.axis(options['axis'])\n",
    "    if 'xlabel' in options:\n",
    "        plt.xlabel(options['xlabel'], fontsize=options['fontsize'])\n",
    "    if 'ylabel' in options:\n",
    "        plt.ylabel(options['ylabel'], fontsize=options['fontsize'])\n",
    "    if 'linewidth' in options:\n",
    "        plt.rc('axes', linewidth=options['linewidth'])\n",
    "        \n",
    "\n",
    "        \n",
    "mean_activation, std_activation = get_class_activation(fmaps, np.argmax(test[1],axis=1))\n",
    "options = { 'ylim': [0, 4],\n",
    "            'xticks': [0, 50, 100, 150],\n",
    "            'yticks': [0.5, 1.5, 2.5, 3.5], \n",
    "            'labelsize': 18,\n",
    "            'figsize': (150,100)}\n",
    "plt = plot_mean_activations(mean_activation, options)\n",
    "#plt.savefig('categorical_l1_activation.eps', format='eps', dpi=1000)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
