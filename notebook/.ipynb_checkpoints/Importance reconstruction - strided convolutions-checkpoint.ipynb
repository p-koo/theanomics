{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980 (CNMeM is disabled, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from src import NeuralNet\n",
    "from src import train as fit\n",
    "from src import make_directory \n",
    "from models import load_model\n",
    "from data import load_data\n",
    "from six.moves import cPickle\n",
    "\n",
    "from subprocess import call\n",
    "\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rcParams\n",
    "rcParams.update({'figure.autolayout': True})\n",
    "%matplotlib inline\n",
    "from scipy.misc import imresize\n",
    "\n",
    "from lasagne import layers, nonlinearities, updates, objectives, init \n",
    "from lasagne.layers import Conv2DLayer, TransposedConv2DLayer, DenseLayer, InputLayer, ExpressionLayer, BiasLayer\n",
    "from lasagne import regularization\n",
    "\n",
    "from lasagne.layers import get_output, get_output_shape, get_all_params\n",
    "import theano.tensor as T\n",
    "import theano\n",
    "np.random.seed(247) # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=50_G=20_data.pickle\n",
      "loading train data\n",
      "loading cross-validation data\n",
      "loading test data\n"
     ]
    }
   ],
   "source": [
    "filename = 'Unlocalized_N=100000_S=200_M=50_G=20_data.pickle'\n",
    "datapath = '/home/peter/Data/SequenceMotif'\n",
    "filepath = os.path.join(datapath, filename)\n",
    "\n",
    "# load training set\n",
    "print \"loading data from: \" + filepath\n",
    "f = open(filepath, 'rb')\n",
    "print \"loading train data\"\n",
    "train = cPickle.load(f)\n",
    "print \"loading cross-validation data\"\n",
    "cross_validation = cPickle.load(f)\n",
    "print \"loading test data\"\n",
    "test = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "X_train = train[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_train = train[1].astype(np.int32)\n",
    "X_val = cross_validation[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_val = cross_validation[1].astype(np.int32)\n",
    "X_test = test[0].transpose((0,1,2)).astype(np.float32)\n",
    "y_test = test[1].astype(np.int32)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "X_val = np.expand_dims(X_val, axis=3)\n",
    "X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "train = (X_train, y_train, train[2])\n",
    "valid = (X_val, y_val, cross_validation[2])\n",
    "test = (X_test, y_test, test[2])\n",
    "\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = train[1].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.16810 -- accuracy=95.43%  \n",
      "  valid loss:\t\t0.10836\n",
      "  valid accuracy:\t0.96512+/-0.02346\n",
      "  valid auc-roc:\t0.88218+/-0.08356\n",
      "  valid auc-pr:\t\t0.45783+/-0.30789\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=50_G=20_data.pickle_epoch_0.pickle\n",
      "Epoch 2 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.10479 -- accuracy=96.64%  \n",
      "  valid loss:\t\t0.08551\n",
      "  valid accuracy:\t0.97184+/-0.02001\n",
      "  valid auc-roc:\t0.92430+/-0.06495\n",
      "  valid auc-pr:\t\t0.57479+/-0.30039\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=50_G=20_data.pickle_epoch_1.pickle\n",
      "Epoch 3 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.08662 -- accuracy=97.14%  \n",
      "  valid loss:\t\t0.07535\n",
      "  valid accuracy:\t0.97486+/-0.01851\n",
      "  valid auc-roc:\t0.94304+/-0.05219\n",
      "  valid auc-pr:\t\t0.63295+/-0.28660\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=50_G=20_data.pickle_epoch_2.pickle\n",
      "Epoch 4 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.07498 -- accuracy=97.47%  \n",
      "  valid loss:\t\t0.06966\n",
      "  valid accuracy:\t0.97630+/-0.01874\n",
      "  valid auc-roc:\t0.95291+/-0.04368\n",
      "  valid auc-pr:\t\t0.67014+/-0.27180\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=50_G=20_data.pickle_epoch_3.pickle\n",
      "Epoch 5 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.06623 -- accuracy=97.74%  \n",
      "  valid loss:\t\t0.06600\n",
      "  valid accuracy:\t0.97769+/-0.01739\n",
      "  valid auc-roc:\t0.95610+/-0.04194\n",
      "  valid auc-pr:\t\t0.69219+/-0.26460\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=50_G=20_data.pickle_epoch_4.pickle\n",
      "Epoch 6 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.05888 -- accuracy=97.95%  \n",
      "  valid loss:\t\t0.06414\n",
      "  valid accuracy:\t0.97824+/-0.01722\n",
      "  valid auc-roc:\t0.96018+/-0.03526\n",
      "  valid auc-pr:\t\t0.70494+/-0.25486\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=50_G=20_data.pickle_epoch_5.pickle\n",
      "Epoch 7 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.05225 -- accuracy=98.15%  \n",
      "  valid loss:\t\t0.06287\n",
      "  valid accuracy:\t0.97897+/-0.01640\n",
      "  valid auc-roc:\t0.96152+/-0.03634\n",
      "  valid auc-pr:\t\t0.71658+/-0.25145\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=50_G=20_data.pickle_epoch_6.pickle\n",
      "Epoch 8 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.04655 -- accuracy=98.33%  \n",
      "  valid loss:\t\t0.06262\n",
      "  valid accuracy:\t0.97910+/-0.01686\n",
      "  valid auc-roc:\t0.96343+/-0.03311\n",
      "  valid auc-pr:\t\t0.72154+/-0.24797\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=50_G=20_data.pickle_epoch_7.pickle\n",
      "Epoch 9 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.04093 -- accuracy=98.51%  \n",
      "  valid loss:\t\t0.06403\n",
      "  valid accuracy:\t0.97918+/-0.01677\n",
      "  valid auc-roc:\t0.96242+/-0.03457\n",
      "  valid auc-pr:\t\t0.72550+/-0.24073\n",
      "saving model parameters to: /home/peter/Data/SequenceMotif/Unlocalized_N=100000_S=200_M=50_G=20_data.pickle_epoch_8.pickle\n",
      "Epoch 10 out of 500 \n",
      "[===============               ] 49.3% -- time=86s -- loss=0.03365 -- accuracy=98.76%  "
     ]
    }
   ],
   "source": [
    "model_name = \"test_motif_model\"\n",
    "nnmodel = NeuralNet(model_name, shape, num_labels)\n",
    "nnmodel = fit.train_minibatch(nnmodel, train, valid, batch_size=128, num_epochs=500, \n",
    "                        patience=3, verbose=1, filepath=filepath)\n",
    "network = nnmodel.network\n",
    "network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def seq_logo(pwm, height=100, nt_width=20, norm=0, rna=0, filepath='.'):\n",
    "    \"\"\"generate a sequence logo from a pwm\"\"\"\n",
    "    \n",
    "    def load_alphabet(filepath, rna):\n",
    "        \"\"\"load images of nucleotide alphabet \"\"\"\n",
    "        df = pd.read_table(os.path.join(filepath, 'A.txt'), header=None);\n",
    "        A_img = df.as_matrix()\n",
    "        A_img = np.reshape(A_img, [72, 65, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        df = pd.read_table(os.path.join(filepath, 'C.txt'), header=None);\n",
    "        C_img = df.as_matrix()\n",
    "        C_img = np.reshape(C_img, [76, 64, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        df = pd.read_table(os.path.join(filepath, 'G.txt'), header=None);\n",
    "        G_img = df.as_matrix()\n",
    "        G_img = np.reshape(G_img, [76, 67, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        if rna == 1:\n",
    "            df = pd.read_table(os.path.join(filepath, 'U.txt'), header=None);\n",
    "            T_img = df.as_matrix()\n",
    "            T_img = np.reshape(T_img, [74, 57, 3], order=\"F\").astype(np.uint8)\n",
    "        else:\n",
    "            df = pd.read_table(os.path.join(filepath, 'T.txt'), header=None);\n",
    "            T_img = df.as_matrix()\n",
    "            T_img = np.reshape(T_img, [72, 59, 3], order=\"F\").astype(np.uint8)\n",
    "\n",
    "        return A_img, C_img, G_img, T_img\n",
    "\n",
    "\n",
    "    def get_nt_height(pwm, height, norm):\n",
    "        \"\"\"get the heights of each nucleotide\"\"\"\n",
    "\n",
    "        def entropy(p):\n",
    "            \"\"\"calculate entropy of each nucleotide\"\"\"\n",
    "            s = 0\n",
    "            for i in range(4):\n",
    "                if p[i] > 0:\n",
    "                    s -= p[i]*np.log2(p[i])\n",
    "            return s\n",
    "\n",
    "        num_nt, num_seq = pwm.shape\n",
    "        heights = np.zeros((num_nt,num_seq));\n",
    "        for i in range(num_seq):\n",
    "            if norm == 1:\n",
    "                total_height = height\n",
    "            else:\n",
    "                total_height = (np.log2(4) - entropy(pwm[:, i]))*height;\n",
    "            heights[:,i] = np.floor(pwm[:,i]*total_height);\n",
    "        return heights.astype(int)\n",
    "\n",
    "    \n",
    "    # get the alphabet images of each nucleotide\n",
    "    A_img, C_img, G_img, T_img = load_alphabet(filepath='.', rna=1)\n",
    "    \n",
    "    \n",
    "    # get the heights of each nucleotide\n",
    "    heights = get_nt_height(pwm, height, norm)\n",
    "    \n",
    "    # resize nucleotide images for each base of sequence and stack\n",
    "    num_nt, num_seq = pwm.shape\n",
    "    width = np.ceil(nt_width*num_seq).astype(int)\n",
    "    \n",
    "    total_height = np.sum(heights,axis=0)\n",
    "    max_height = np.max(total_height)\n",
    "    logo = np.ones((height*2, width, 3)).astype(int)*255;\n",
    "    for i in range(num_seq):\n",
    "        remaining_height = total_height[i];\n",
    "        offset = max_height-remaining_height\n",
    "        nt_height = np.sort(heights[:,i]);\n",
    "        index = np.argsort(heights[:,i])\n",
    "\n",
    "        for j in range(num_nt):\n",
    "            if nt_height[j] > 0:\n",
    "                # resized dimensions of image\n",
    "                resize = (nt_height[j], nt_width)\n",
    "                if index[j] == 0:\n",
    "                    nt_img = imresize(A_img, resize)\n",
    "                elif index[j] == 1:\n",
    "                    nt_img = imresize(C_img, resize)\n",
    "                elif index[j] == 2:\n",
    "                    nt_img = imresize(G_img, resize)\n",
    "                elif index[j] == 3:\n",
    "                    nt_img = imresize(T_img, resize)\n",
    "\n",
    "                # determine location of image\n",
    "                height_range = range(remaining_height-nt_height[j], remaining_height)\n",
    "                width_range = range(i*nt_width, i*nt_width+nt_width)\n",
    "\n",
    "                # 'annoying' way to broadcast resized nucleotide image\n",
    "                if height_range:\n",
    "                    for k in range(3):\n",
    "                        for m in range(len(width_range)):\n",
    "                            logo[height_range+offset, width_range[m],k] = nt_img[:,m,k];\n",
    "\n",
    "                remaining_height -= nt_height[j]\n",
    "\n",
    "    return logo.astype(np.uint8)\n",
    "def maxunpool(X, pool, active):\n",
    "    pool_size = active.shape[2]/pool.shape[2]\n",
    "    fmap1 = []\n",
    "    for k in range(active.shape[0]):\n",
    "        x = np.squeeze(active[k],axis=(2,))\n",
    "        mymap = np.squeeze(pool[k],axis=(2,))\n",
    "\n",
    "        max_index = []\n",
    "        for i in range(x.shape[1]/pool_size):\n",
    "            index = range(i*pool_size,(i+1)*pool_size)\n",
    "            max_index.append(np.argmax(x[:,index],axis=1))\n",
    "        max_index = np.array(max_index)\n",
    "        max_index\n",
    "\n",
    "        dim,seq_length = mymap.shape\n",
    "        fmap_unpool = np.zeros((dim,seq_length*pool_size))\n",
    "        for i in range(x.shape[1]/pool_size):\n",
    "            index = range(i*pool_size,(i+1)*pool_size)\n",
    "            for j in range(dim):\n",
    "                fmap_unpool[j,index[max_index[i][j]]] = mymap[j,i]\n",
    "        fmap1.append(fmap_unpool)\n",
    "\n",
    "    fmap1 = np.array(fmap1)\n",
    "    fmap1 = np.expand_dims(fmap1, 3)\n",
    "    return fmap1 \n",
    "\n",
    "def deconvolution(fmap, layer):\n",
    "    # psuedo-inverse filters\n",
    "    W4 = layer.W.get_value()\n",
    "\n",
    "    # deconvolution layer 2\n",
    "    input_var4 = T.tensor4('conv4')\n",
    "    shape4 = list(fmap.shape)\n",
    "    shape4[0] = None\n",
    "    input4 = InputLayer(shape=tuple(shape4), input_var=input_var4)\n",
    "    #unpool4 = ExpressionLayer(input4, lambda X: T.log(T.exp(X)-1 + 1e-7), output_shape='auto')\n",
    "    #unpool4 = BiasLayer(unpool4, b=-network['conv2_bias'].b)\n",
    "    if layer.pad == 'valid':\n",
    "        pad = 'full'\n",
    "    else:\n",
    "        pad = 'same'\n",
    "    deconv4 = Conv2DLayer(input4, num_filters=layer.input_shape[1],\n",
    "                                          filter_size=layer.filter_size,\n",
    "                                          W=layer.W.dimshuffle([1,0,2,3]), #W2_inv, #\n",
    "                                          b=None, \n",
    "                                          stride=layer.stride,\n",
    "                                          pad= 'full' if layer.pad==(0,0) else 'same',\n",
    "                                          nonlinearity=None, flip_filters=False)\n",
    "    predict = theano.function([input_var4], get_output(deconv4, deterministic=True), allow_input_downcast=True)\n",
    "\n",
    "    intermediate = predict(fmap.astype(np.float32))\n",
    "    return np.array(intermediate)\n",
    "\n",
    "def get_feature_map_all(layer, input_var, X):\n",
    "    get_map = theano.function([input_var], get_output(layer), allow_input_downcast=True)\n",
    "    return get_map(X)\n",
    "\n",
    " \n",
    "def activation_filter(layer, percentile, window=0, norm=0):\n",
    "    pool = np.squeeze(layer[0], axis=2)\n",
    "    if norm:\n",
    "        pool = np.abs(pool)\n",
    "        \n",
    "    pool_flat = pool.reshape([-1,])\n",
    "    num_data = len(pool_flat)\n",
    "    cutoff = np.round(num_data*percentile).astype(int)\n",
    "    threshold = np.sort(pool_flat)[-cutoff]\n",
    "\n",
    "    if norm:\n",
    "        sum_spikes = np.max(np.abs(pool),axis=0)\n",
    "    else:\n",
    "        sum_spikes = np.max(pool,axis=0)\n",
    "        \n",
    "    index = np.where(sum_spikes > threshold)[0]\n",
    "    fmap = np.zeros(pool.shape)\n",
    "    for i in index:\n",
    "        MIN = np.maximum(0, i-window)\n",
    "        MAX = np.minimum(pool.shape[1],i+window+1)\n",
    "        fmap[:,MIN:MAX] = pool[:,MIN:MAX]\n",
    "    fmap = np.expand_dims(fmap,0)\n",
    "    fmap = np.expand_dims(fmap,3)\n",
    "    return fmap, threshold\n",
    "\n",
    "def max_filter(layer, percentile, window=0, norm=0):\n",
    "    pool = np.squeeze(layer[0], axis=2)\n",
    "    if norm:\n",
    "        pool = np.abs(pool)\n",
    "    max_pool = np.max(pool, axis=0)\n",
    "    num_data = len(max_pool)\n",
    "    cutoff = np.round(num_data*percentile).astype(int)\n",
    "    threshold = np.sort(max_pool)[-cutoff]\n",
    "    \n",
    "    index = np.where(max_pool > threshold)[0]\n",
    "    fmap = np.zeros(pool.shape)\n",
    "    for i in index:\n",
    "        MIN = np.maximum(0, i-window)\n",
    "        MAX = np.minimum(pool.shape[1],i+window+1)\n",
    "        fmap[:,MIN:MAX] = pool[:,MIN:MAX]\n",
    "    fmap = np.expand_dims(fmap,0)\n",
    "    fmap = np.expand_dims(fmap,3)\n",
    "    return fmap, threshold\n",
    "\n",
    "def same_unpool_fmap(layer, seq_length):\n",
    "    activation = np.squeeze(layer[0], axis=2)\n",
    "    num_channels, num_map = activation.shape\n",
    "\n",
    "    num_unpool = np.floor(seq_length/num_map).astype(int)\n",
    "    amap = np.zeros((num_channels, seq_length))\n",
    "    for i in range(num_map):\n",
    "        amap[:,range(i*num_unpool,(i+1)*num_unpool)] = np.outer(activation[:,i], np.ones(num_unpool))\n",
    "    return amap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_index = 172#14, 16, 22, 17, 172\n",
    "\n",
    "savename = 'Unlocalized_strided_'+str(map_index)+'_'\n",
    "savedir = '/home/peter/Documents/'+savename\n",
    "\n",
    "X = test[0][map_index]\n",
    "X = np.expand_dims(X,0)\n",
    "y = test[1][map_index]\n",
    "model = test[2][map_index]\n",
    "print X.shape\n",
    "\n",
    "seq_length = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get prediction\n",
    "get_prediction = theano.function([nnmodel.input_var], layers.get_output(network['output'], deterministic=True), allow_input_downcast=True)\n",
    "prediction = get_prediction(X)\n",
    "print 'ground truth = ' + str(np.argmax(y))\n",
    "print 'prediction = ' + str(np.argmax(prediction))\n",
    "\n",
    "class_index = np.argmax(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conv5 = np.zeros(20)\n",
    "conv5[class_index]=10\n",
    "conv5 = np.expand_dims(conv5,0)\n",
    "conv5 = np.expand_dims(conv5,2)\n",
    "conv5 = np.expand_dims(conv5,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get dense layer\n",
    "conv4 = deconvolution(conv5, network['conv4'])\n",
    "conv4_flat = np.squeeze(conv4[0],axis=2)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(conv4_flat);\n",
    "plt.scatter(range(20),conv4_flat);\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('layer4 neurons (200 nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "outfile = savedir+ 'conv4_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "        \n",
    "threshold = np.max(conv4)*.9\n",
    "conv4[conv4<threshold] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conv4 = np.zeros(20)\n",
    "conv4[class_index]=10\n",
    "conv4 = np.expand_dims(conv4,0)\n",
    "conv4 = np.expand_dims(conv4,2)\n",
    "conv4 = np.expand_dims(conv4,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv3 = deconvolution(conv4, network['conv4'])\n",
    "conv3_flat = np.squeeze(conv3[0],axis=2)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(conv3_flat);\n",
    "plt.scatter(range(len(conv3_flat)),conv3_flat);\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('layer3 neurons (200 nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "threshold = np.max(conv3)*.5\n",
    "conv3[conv3<threshold] = 0\n",
    "plt.plot(range(len(conv3_flat)), np.ones(len(conv3_flat))*threshold, color='k', linestyle='--')\n",
    "outfile = savedir+ 'deconv3_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "conv3_flat = np.squeeze(conv3[0],axis=2)\n",
    "fig = plt.figure()\n",
    "plt.plot(conv3_flat);\n",
    "plt.scatter(range(len(conv3_flat)),conv3_flat);\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('layer3 neurons (200 nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "outfile = savedir+ 'deconv3_filter_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "\n",
    "\n",
    "conv3_active = get_feature_map_all(network['conv3'], nnmodel.input_var, X)\n",
    "fig = plt.figure()\n",
    "plt.plot(np.squeeze(conv3_active[0]));\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('layer3 neurons (200 nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "outfile = savedir+ 'conv3_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get dense layer\n",
    "#get_conv2 = theano.function([nnmodel.input_var], layers.get_output(network['conv2'], deterministic=True), allow_input_downcast=True)\n",
    "#conv2 = get_conv2(X)\n",
    "\n",
    "conv2_pool = deconvolution(conv3, network['conv3'])\n",
    "conv2_active = get_feature_map_all(network['conv2'], nnmodel.input_var, X)\n",
    "conv2 = maxunpool(X, conv2_pool, conv2_active)\n",
    "\n",
    "conv2_flat = np.squeeze(conv2[0],axis=2)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(conv2_flat.T);\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('layer2 neurons (16 nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "\n",
    "\n",
    "threshold = np.max(conv2)*.4\n",
    "conv2[conv2<threshold] = 0\n",
    "plt.plot(range(len(conv2_flat)), np.ones(len(conv2_flat))*threshold, color='k', linestyle='--')\n",
    "outfile = savedir+ 'deconv2_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "conv2_flat = np.squeeze(conv2[0],axis=2)\n",
    "fig = plt.figure()\n",
    "plt.plot(conv2_flat.T);\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('layer2 neurons (16 nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "outfile = savedir+ 'deconv2_filter_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(np.squeeze(conv2_active[0],axis=2).T);\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('layer2 neurons (16 nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "outfile = savedir+ 'conv2_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "conv1_pool = deconvolution(conv2, network['conv2'])\n",
    "pool = np.squeeze(conv1_pool[0])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pool.T);\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('pooled 1st layer neurons (12 nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "\n",
    "\n",
    "\n",
    "threshold = np.max(conv1_pool)*.4\n",
    "conv1_pool[conv1_pool<threshold] = 0\n",
    "plt.plot(range(pool.shape[1]), np.ones(pool.shape[1])*threshold, color='k', linestyle='--')\n",
    "outfile = savedir+ 'deconv1_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.squeeze(conv1_pool[0]).T);\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('pooled 1st layer neurons (12 nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "outfile = savedir+ 'deconv1_filter_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "\n",
    "\n",
    "pool = get_feature_map_all(network['conv1_pool'], nnmodel.input_var, X)\n",
    "plt.figure()\n",
    "plt.plot(np.squeeze(pool[0]).T);\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('pooled 1st layer neurons (12 nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "outfile = savedir+ 'conv1pool_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1_active = get_feature_map_all(network['conv1'], nnmodel.input_var, X)\n",
    "conv1 = maxunpool(X, conv1_pool, conv1_active)\n",
    "reconstruction = deconvolution(conv1, network['conv1'])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.squeeze(conv1_active[0]).T)\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('sequence (nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "outfile = savedir+ 'conv1_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.squeeze(reconstruction[0]).T)\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('sequence (nt)', fontsize=20)\n",
    "plt.ylabel('activation', fontsize=20)\n",
    "outfile = savedir+ 'deconv0_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "#reconstruction[reconstruction<0]=0\n",
    "\n",
    "pwm = np.squeeze(reconstruction[0])\n",
    "pwm = pwm/np.max(pwm)\n",
    "pwm += .1\n",
    "pwm[pwm<0] = 0\n",
    "#pwm = pwm + np.mean(pwm)\n",
    "norm = np.outer(np.ones(4), np.sum(pwm, axis=0))\n",
    "pwm = pwm/norm\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pwm.T);\n",
    "plt.axis('tight')\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', labelsize=16)\n",
    "ax.tick_params(axis='y', labelsize=16)\n",
    "plt.xlabel('sequence (nt)', fontsize=20)\n",
    "plt.ylabel('normalized activation', fontsize=20)\n",
    "outfile = savedir+ 'deconv0_normalized_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=100\n",
    "bp_width=20\n",
    "size = (25.,10.0)\n",
    "\n",
    "logo = seq_logo(np.squeeze(X[0]), height, bp_width, norm=0, rna=1, filepath='.')\n",
    "fig = plt.figure(figsize=size);\n",
    "plt.imshow(logo, interpolation='none');\n",
    "plt.axis('off');\n",
    "outfile = savedir+ 'input_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "\n",
    "logo = seq_logo(model, height, bp_width, norm=0, rna=1, filepath='.')\n",
    "fig = plt.figure(figsize=size);\n",
    "plt.imshow(logo, interpolation='none');\n",
    "plt.axis('off');\n",
    "#plt.title(str(y),fontsize=20)\n",
    "outfile = savedir+ 'model_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])\n",
    "\n",
    "\n",
    "logo = seq_logo(pwm, height, bp_width, norm=0, rna=1, filepath='.')\n",
    "fig = plt.figure(figsize=size);\n",
    "plt.imshow(logo, interpolation='none');\n",
    "plt.axis('off');\n",
    "outfile = savedir+ 'reconstructed_'+ str(class_index)  + '.pdf'\n",
    "fig.savefig(outfile, format='pdf', dpi=1000)  \n",
    "call(['pdfcrop', outfile, outfile])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
