{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('/Users/juliankimura/Desktop/deepomics')\n",
    "import deepomics.neuralnetwork as nn\n",
    "from deepomics import learn, utils\n",
    "from models import MNIST_model\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne import layers\n",
    "\n",
    "np.random.seed(247)   # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset(data_path):\n",
    "    import gzip\n",
    "    def load_mnist_images(filename):\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        data = data.reshape(-1, 28*28)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        return data\n",
    "\n",
    "    # We can now download and read the training and test set images and labels.\n",
    "    X_train = load_mnist_images(os.path.join(data_path,'train-images-idx3-ubyte.gz')).reshape([-1, 1, 28, 28])\n",
    "    y_train_index = load_mnist_labels(os.path.join(data_path,'train-labels-idx1-ubyte.gz'))\n",
    "    X_test = load_mnist_images(os.path.join(data_path,'t10k-images-idx3-ubyte.gz')).reshape([-1, 1, 28, 28])\n",
    "    y_test_index = load_mnist_labels(os.path.join(data_path,'t10k-labels-idx1-ubyte.gz'))\n",
    "\n",
    "    y_train = np.zeros((y_train_index.shape[0], 10)).astype(np.float32)\n",
    "    for i in range(y_train.shape[0]):\n",
    "        y_train[i,y_train_index[i]] = 1\n",
    "    y_test = np.zeros((y_test_index.shape[0], 10)).astype(np.float32)\n",
    "    for i in range(y_test.shape[0]):\n",
    "        y_test[i,y_test_index[i]] = 1\n",
    "    \n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    train = (X_train, y_train)\n",
    "    valid = (X_val, y_val)\n",
    "    test = (X_test, y_test)\n",
    "\n",
    "    return train, valid, test\n",
    "\n",
    "data_path = '/Users/juliankimura/Desktop/data/MNIST'\n",
    "train, valid, test = load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build model\n",
    "input_shape = list(train[0].shape)\n",
    "input_shape[0] = None\n",
    "output_shape = train[1].shape\n",
    "network, placeholders, optimization = MNIST_model.model(input_shape, output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "Network architecture:\n",
      "----------------------------------------------------------------------------\n",
      "layer1: \n",
      "<lasagne.layers.input.InputLayer object at 0x11abcb5c0>\n",
      "shape:(None, 1, 28, 28)\n",
      "layer2: \n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11abcb3c8>\n",
      "shape:(None, 16, 28, 28)\n",
      "parameters: W\n",
      "layer3: \n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x10d342710>\n",
      "shape:(None, 16, 28, 28)\n",
      "parameters: beta, gamma, mean, inv_std\n",
      "layer4: \n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x11ad3e160>\n",
      "shape:(None, 16, 28, 28)\n",
      "layer5: \n",
      "<lasagne.layers.noise.DropoutLayer object at 0x11ad3e320>\n",
      "shape:(None, 16, 28, 28)\n",
      "layer6: \n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x11ad3e390>\n",
      "shape:(None, 16, 14, 14)\n",
      "layer7: \n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11ad3e400>\n",
      "shape:(None, 32, 14, 14)\n",
      "parameters: W\n",
      "layer8: \n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x11ad3e3c8>\n",
      "shape:(None, 32, 14, 14)\n",
      "parameters: beta, gamma, mean, inv_std\n",
      "layer9: \n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x11ad3eb00>\n",
      "shape:(None, 32, 14, 14)\n",
      "layer10: \n",
      "<lasagne.layers.noise.DropoutLayer object at 0x11ad3ecc0>\n",
      "shape:(None, 32, 14, 14)\n",
      "layer11: \n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x11ad3ed30>\n",
      "shape:(None, 32, 7, 7)\n",
      "layer12: \n",
      "<lasagne.layers.dense.DenseLayer object at 0x11ad3edd8>\n",
      "shape:(None, 512)\n",
      "parameters: W\n",
      "layer13: \n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x11ad3ed68>\n",
      "shape:(None, 512)\n",
      "parameters: beta, gamma, mean, inv_std\n",
      "layer14: \n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x120ce1550>\n",
      "shape:(None, 512)\n",
      "layer15: \n",
      "<lasagne.layers.dense.DenseLayer object at 0x120ce1780>\n",
      "shape:(None, 10)\n",
      "parameters: W\n",
      "layer16: \n",
      "<lasagne.layers.special.BiasLayer object at 0x120ce17b8>\n",
      "shape:(None, 10)\n",
      "parameters: b\n",
      "layer17: \n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x120ce1978>\n",
      "shape:(None, 10)\n",
      "----------------------------------------------------------------------------\n",
      "compiling model\n"
     ]
    }
   ],
   "source": [
    "# build neural network class\n",
    "nnmodel = nn.NeuralNet(network, placeholders)\n",
    "nnmodel.inspect_layers()\n",
    "\n",
    "# set output file paths\n",
    "output_name = 'MNIST_vae'\n",
    "results_path = utils.make_directory(data_path, 'Results')\n",
    "results_path = utils.make_directory(results_path, output_name)\n",
    "file_path = os.path.join(results_path, output_name)\n",
    "nntrainer = nn.NeuralTrainer(nnmodel, optimization, save='best', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 500 \n",
      "[==============================] 100.0% -- time=0s -- loss=0.11105 -- accuracy=96.67%  \n",
      "  valid loss:\t\t0.11625\n",
      "  valid accuracy:\t0.99321+/-0.00453\n",
      "  valid auc-roc:\t0.99949+/-0.00045\n",
      "  valid auc-pr:\t\t0.99699+/-0.00207\n",
      "saving model parameters to: /Users/juliankimura/Desktop/data/MNIST/Results/MNIST_vae/MNIST_vae_best.pickle\n",
      "Epoch 2 out of 500 \n",
      "[===                           ] 10.8% -- time=117s -- loss=0.04190 -- accuracy=98.72%  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c9da8a6f53a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m learn.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n\u001b[0;32m----> 3\u001b[0;31m                               batch_size=100, num_epochs=500, patience=10, verbose=1)\n\u001b[0m",
      "\u001b[0;32m/Users/juliankimura/Desktop/deepomics/deepomics/learn.py\u001b[0m in \u001b[0;36mtrain_minibatch\u001b[0;34m(nntrainer, data, batch_size, num_epochs, patience, verbose, shuffle)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;31m# training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnntrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mnntrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliankimura/Desktop/deepomics/deepomics/neuralnetwork.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, train, batch_size, verbose, shuffle)\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                         \u001b[0mvalue\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m                         \u001b[0mperformance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/juliankimura/anaconda/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "learn.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=100, num_epochs=500, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load best model --> lowest cross-validation error\n",
    "nntrainer.set_best_parameters()\n",
    "\n",
    "# test model\n",
    "nntrainer.test_model(test, name=\"test\", batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
