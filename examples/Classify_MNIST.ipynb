{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('/Users/juliankimura/Desktop/deepomics')\n",
    "import deepomics.neuralnetwork as nn\n",
    "from deepomics import learn, utils\n",
    "from models import MNIST_model\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from lasagne import layers\n",
    "\n",
    "np.random.seed(247)   # for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset(data_path):\n",
    "    import gzip\n",
    "    def load_mnist_images(filename):\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        data = data.reshape(-1, 28*28)\n",
    "        return data / np.float32(256)\n",
    "\n",
    "    def load_mnist_labels(filename):\n",
    "        with gzip.open(filename, 'rb') as f:\n",
    "            data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "        return data\n",
    "\n",
    "    # We can now download and read the training and test set images and labels.\n",
    "    X_train = load_mnist_images(os.path.join(data_path,'train-images-idx3-ubyte.gz')).reshape([-1, 1, 28, 28])\n",
    "    y_train_index = load_mnist_labels(os.path.join(data_path,'train-labels-idx1-ubyte.gz'))\n",
    "    X_test = load_mnist_images(os.path.join(data_path,'t10k-images-idx3-ubyte.gz')).reshape([-1, 1, 28, 28])\n",
    "    y_test_index = load_mnist_labels(os.path.join(data_path,'t10k-labels-idx1-ubyte.gz'))\n",
    "\n",
    "    y_train = np.zeros((y_train_index.shape[0], 10)).astype(np.float32)\n",
    "    for i in range(y_train.shape[0]):\n",
    "        y_train[i,y_train_index[i]] = 1\n",
    "    y_test = np.zeros((y_test_index.shape[0], 10)).astype(np.float32)\n",
    "    for i in range(y_test.shape[0]):\n",
    "        y_test[i,y_test_index[i]] = 1\n",
    "    \n",
    "    # We reserve the last 10000 training examples for validation.\n",
    "    X_train, X_val = X_train[:-10000], X_train[-10000:]\n",
    "    y_train, y_val = y_train[:-10000], y_train[-10000:]\n",
    "\n",
    "    train = (X_train, y_train)\n",
    "    valid = (X_val, y_val)\n",
    "    test = (X_test, y_test)\n",
    "\n",
    "    return train, valid, test\n",
    "\n",
    "\n",
    "data_path = '/Users/juliankimura/Desktop/data/MNIST'\n",
    "train, valid, test = load_dataset(data_path)\n",
    "\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "network, placeholders, optimization = MNIST_model.model(shape, train[1].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "Network architecture:\n",
      "----------------------------------------------------------------------------\n",
      "layer1: \n",
      "<lasagne.layers.input.InputLayer object at 0x11a7d76a0>\n",
      "shape:(None, 1, 28, 28)\n",
      "layer2: \n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11a7d7710>\n",
      "shape:(None, 16, 28, 28)\n",
      "parameters: W\n",
      "layer3: \n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x10d2336d8>\n",
      "shape:(None, 16, 28, 28)\n",
      "parameters: beta, gamma, mean, inv_std\n",
      "layer4: \n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x11af8e358>\n",
      "shape:(None, 16, 28, 28)\n",
      "layer5: \n",
      "<lasagne.layers.noise.DropoutLayer object at 0x11af8e518>\n",
      "shape:(None, 16, 28, 28)\n",
      "layer6: \n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x11af8e588>\n",
      "shape:(None, 16, 14, 14)\n",
      "layer7: \n",
      "<lasagne.layers.conv.Conv2DLayer object at 0x11af8e5f8>\n",
      "shape:(None, 32, 14, 14)\n",
      "parameters: W\n",
      "layer8: \n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x11af8e5c0>\n",
      "shape:(None, 32, 14, 14)\n",
      "parameters: beta, gamma, mean, inv_std\n",
      "layer9: \n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x11af8ecf8>\n",
      "shape:(None, 32, 14, 14)\n",
      "layer10: \n",
      "<lasagne.layers.noise.DropoutLayer object at 0x11af8eeb8>\n",
      "shape:(None, 32, 14, 14)\n",
      "layer11: \n",
      "<lasagne.layers.pool.MaxPool2DLayer object at 0x11af8ef28>\n",
      "shape:(None, 32, 7, 7)\n",
      "layer12: \n",
      "<lasagne.layers.dense.DenseLayer object at 0x11af8ef98>\n",
      "shape:(None, 512)\n",
      "parameters: W\n",
      "layer13: \n",
      "<lasagne.layers.normalization.BatchNormLayer object at 0x11af8ef60>\n",
      "shape:(None, 512)\n",
      "parameters: beta, gamma, mean, inv_std\n",
      "layer14: \n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x11af9b710>\n",
      "shape:(None, 512)\n",
      "layer15: \n",
      "<lasagne.layers.dense.DenseLayer object at 0x11af9b908>\n",
      "shape:(None, 10)\n",
      "parameters: W\n",
      "layer16: \n",
      "<lasagne.layers.special.BiasLayer object at 0x11af9b940>\n",
      "shape:(None, 10)\n",
      "parameters: b\n",
      "layer17: \n",
      "<lasagne.layers.special.NonlinearityLayer object at 0x11af9bb00>\n",
      "shape:(None, 10)\n",
      "----------------------------------------------------------------------------\n",
      "compiling model\n"
     ]
    }
   ],
   "source": [
    "# build neural network class\n",
    "nnmodel = nn.NeuralNet(network, placeholders)\n",
    "nnmodel.inspect_layers()\n",
    "\n",
    "# set output file paths\n",
    "output_name = 'MNIST_vae'\n",
    "results_path = utils.make_directory(data_path, 'Results')\n",
    "results_path = utils.make_directory(results_path, output_name)\n",
    "file_path = os.path.join(results_path, output_name)\n",
    "nntrainer = nn.NeuralTrainer(nnmodel, optimization, save='best', file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 out of 500 \n",
      "[=======================       ] 75.6% -- time=31s -- loss=0.07244 -- accuracy=97.81%  "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "learn.train_minibatch(nntrainer, data={'train': train, 'valid': valid}, \n",
    "                              batch_size=100, num_epochs=500, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load best model --> lowest cross-validation error\n",
    "nntrainer.set_best_parameters()\n",
    "\n",
    "# test model\n",
    "nntrainer.test_model(test, name=\"test\", batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
