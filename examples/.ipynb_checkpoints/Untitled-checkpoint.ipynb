{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from: /home/peter/Data/SequenceMotif/N=100000_S=200_M=10_G=20_data.pickle\n",
      "loading train data\n",
      "loading cross-validation data\n",
      "loading test data\n"
     ]
    }
   ],
   "source": [
    "#/bin/python\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append('..')\n",
    "from src import NeuralNet\n",
    "from src import train as fit\n",
    "from src import make_directory \n",
    "from models import load_model\n",
    "from data import load_data\n",
    "np.random.seed(247) # for reproducibility\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# load data\n",
    "\n",
    "\n",
    "name = 'MotifSimulation_binary'\n",
    "datapath = '/home/peter/Data/SequenceMotif'\n",
    "filepath = os.path.join(datapath, 'N=100000_S=200_M=10_G=20_data.pickle')\n",
    "train, valid, test = load_data(name, filepath)\n",
    "shape = (None, train[0].shape[1], train[0].shape[2], train[0].shape[3])\n",
    "num_labels = np.round(train[1].shape[1])\n",
    "\n",
    "#-------------------------------------------------------------------------------------\n",
    "\n",
    "# load model parameters\n",
    "model_name = \"binary_genome_motif_model\"\n",
    "nnmodel = NeuralNet(model_name, shape, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "Network architecture:\n",
      "-----------------------------------------------------------------------\n",
      "layer1: <lasagne.layers.input.InputLayer object at 0x7f0ba44198d0>\n",
      "shape:(None, 4, 200, 1)\n",
      "layer2: <lasagne.layers.conv.Conv2DLayer object at 0x7f0ba4419850>\n",
      "shape:(None, 200, 193, 1)\n",
      "parameters: W\n",
      "layer3: <lasagne.layers.normalization.BatchNormLayer object at 0x7f0ba4b34650>\n",
      "shape:(None, 200, 193, 1)\n",
      "parameters: beta, gamma, mean, inv_std\n",
      "layer4: <lasagne.layers.special.NonlinearityLayer object at 0x7f0ba4419610>\n",
      "shape:(None, 200, 193, 1)\n",
      "layer5: <lasagne.layers.pool.MaxPool2DLayer object at 0x7f0ba548d9d0>\n",
      "shape:(None, 200, 48, 1)\n",
      "layer6: <lasagne.layers.conv.Conv2DLayer object at 0x7f0ba548d4d0>\n",
      "shape:(None, 200, 41, 1)\n",
      "parameters: W\n",
      "layer7: <lasagne.layers.normalization.BatchNormLayer object at 0x7f0ba548dd90>\n",
      "shape:(None, 200, 41, 1)\n",
      "parameters: beta, gamma, mean, inv_std\n",
      "layer8: <lasagne.layers.special.NonlinearityLayer object at 0x7f0ba548dd10>\n",
      "shape:(None, 200, 41, 1)\n",
      "layer9: <lasagne.layers.pool.MaxPool2DLayer object at 0x7f0b58816e50>\n",
      "shape:(None, 200, 10, 1)\n",
      "layer10: <lasagne.layers.dense.DenseLayer object at 0x7f0b58816810>\n",
      "shape:(None, 200)\n",
      "parameters: W\n",
      "layer11: <lasagne.layers.normalization.BatchNormLayer object at 0x7f0ba4b340d0>\n",
      "shape:(None, 200)\n",
      "parameters: beta, gamma, mean, inv_std\n",
      "layer12: <lasagne.layers.special.ParametricRectifierLayer object at 0x7f0b58816fd0>\n",
      "shape:(None, 200)\n",
      "parameters: alpha\n",
      "layer13: <lasagne.layers.dense.DenseLayer object at 0x7f0b58816bd0>\n",
      "shape:(None, 20)\n",
      "parameters: W, b\n",
      "layer14: <lasagne.layers.special.NonlinearityLayer object at 0x7f0b58816cd0>\n",
      "shape:(None, 20)\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from lasagne.layers import get_all_layers\n",
    "all_layers = get_all_layers(nnmodel.network['output'])\n",
    "\n",
    "def print_layers():\n",
    "    print '-----------------------------------------------------------------------'\n",
    "    print 'Network architecture:'\n",
    "    print '-----------------------------------------------------------------------'\n",
    "    counter = 1\n",
    "    for layer in all_layers:\n",
    "        output_shape = layer.output_shape\n",
    "        params = layer.get_params()\n",
    "\n",
    "        print 'layer'+str(counter) + ': '+ str(layer)\n",
    "        print 'shape:' +  str(output_shape)\n",
    "        if params:\n",
    "            all_params = ''\n",
    "            for param in params:\n",
    "                all_params += str(param) + ', '\n",
    "            print 'parameters: ' + str(all_params[0:-2])\n",
    "        counter += 1\n",
    "    print '-----------------------------------------------------------------------'\n",
    "\n",
    "print_layers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle\n",
    "outputname = 'binary'\n",
    "filepath = os.path.join(datapath, 'Results', outputname)\n",
    "savepath = filepath + \"_best.pickle\"\n",
    "f = open(savepath, 'rb')\n",
    "best_parameters = cPickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnmodel.reinitialize()\n",
    "\n",
    "# load model parameters for a given training epoch\n",
    "savepath = filepath + \"_epoch_\" + str(1) + \".pickle\"\n",
    "f = open(savepath, 'rb')\n",
    "best_parameters = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# get test metrics \n",
    "nnmodel.set_model_parameters(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_performance(savepath):\n",
    "    with open(savepath, 'rb') as f:\n",
    "        name = cPickle.load(f)\n",
    "        cost = cPickle.load(f)\n",
    "        metric = cPickle.load(f)\n",
    "        metric_std = cPickle.load(f)\n",
    "        roc = cPickle.load(f)\n",
    "        pr = cPickle.load(f)\n",
    "    return cost, metric, metric_std, roc, pr\n",
    "\n",
    "savepath = filepath + \"_train_performance.pickle\"\n",
    "train_cost, train_metric, train_metric_std, train_roc, trian_pr = get_performance(savepath)\n",
    "\n",
    "savepath = filepath + \"_cross-validation_performance.pickle\"\n",
    "valid_cost, valid_metric, valid_metric_std, valid_roc, valid_pr = get_performance(savepath)\n",
    "\n",
    "savepath = filepath + \"_test_all_performance.pickle\"\n",
    "test_cost, test_metric, test_metric_std, test_roc, test_pr = get_performance(savepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "def plot_loss(loss):\n",
    "    \"\"\"Plot trainig/validation/test loss during training\"\"\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    num_data_types = len(loss)\n",
    "    if num_data_types == 2:\n",
    "        plt.plot(loss[0], label='train loss', linewidth=2)\n",
    "        plt.plot(loss[1], label='valid loss', linewidth=2)\n",
    "    elif num_data_types == 3:\n",
    "        plt.plot(loss[0], label='train loss', linewidth=2)\n",
    "        plt.plot(loss[1], label='valid loss', linewidth=2)\n",
    "        plt.plot(loss[2], label='test loss', linewidth=2)\n",
    "\n",
    "    plt.xlabel('epoch', fontsize=22)\n",
    "    plt.ylabel('loss', fontsize=22)\n",
    "    plt.legend(loc='best', frameon=False, fontsize=18)\n",
    "    return fig, plt\n",
    "\n",
    "fig, plt = plot_loss([train_cost, valid_cost, test_cost])\n",
    "plt.show()\n",
    "fig.savefig('test.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "savepath = filepath + \"_test_performance.pickle\"\n",
    "final_cost, final_metric, final_metric_std, final_roc, final_pr = get_performance(savepath)\n",
    "\n",
    "def plot_roc_all(final_roc):\n",
    "    \"\"\"Plot trainig/validation/test loss during training\"\"\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for i in range(len(final_roc)):\n",
    "        plt.plot(final_roc[i][0],final_roc[i][1], label=str(i))\n",
    "    plt.xlabel('False positive rate', fontsize=22)\n",
    "    plt.ylabel('True positive rate', fontsize=22)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.label.set_fontsize(17)\n",
    "    ax.yaxis.label.set_fontsize(17)\n",
    "    map(lambda xl: xl.set_fontsize(13), ax.get_xticklabels())\n",
    "    map(lambda yl: yl.set_fontsize(13), ax.get_yticklabels())\n",
    "    plt.tight_layout()\n",
    "    plt.legend(loc='best', frameon=False, fontsize=14)\n",
    "    return fig, plt\n",
    "\n",
    "fig, plt = plot_roc_all(final_roc)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_pr_all(final_pr):\n",
    "    \"\"\"Plot trainig/validation/test loss during training\"\"\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for i in range(len(final_roc)):\n",
    "        plt.plot(final_pr[i][0],final_pr[i][1])\n",
    "    plt.xlabel('Recall', fontsize=22)\n",
    "    plt.ylabel('Product', fontsize=22)\n",
    "    #plt.legend(loc='best', frameon=False, fontsize=14)\n",
    "    return fig, plt\n",
    "\n",
    "fig, plt = plot_pr_all(final_pr)\n",
    "ax = plt.gca()\n",
    "ax.xaxis.label.set_fontsize(17)\n",
    "ax.yaxis.label.set_fontsize(17)\n",
    "map(lambda xl: xl.set_fontsize(13), ax.get_xticklabels())\n",
    "map(lambda yl: yl.set_fontsize(13), ax.get_yticklabels())\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "out_pdf = 'my.pdf'\n",
    "#plt.savefig(out_pdf)\n",
    "#plt.close()\n",
    "\n",
    "\n",
    "#fig.savefig('test.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv2', 'conv1']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nnmodel.network\n",
    "keys = network.keys()\n",
    "filter_layers = []\n",
    "for key in keys:\n",
    "    if 'conv' in key:\n",
    "        if hasattr(network[key], 'W'):\n",
    "            filter_layers.append(key) \n",
    "filter_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as img\n",
    "\n",
    "def plot_conv_weights(layer, figsize=(6, 6)):\n",
    "    \"\"\"nolearn's plot the weights of a specific layer\"\"\"\n",
    "\n",
    "    W =  np.squeeze(layer.W.get_value())\n",
    "    shape = W.shape\n",
    "    nrows = np.ceil(np.sqrt(shape[0])).astype(int)\n",
    "    ncols = nrows\n",
    "\n",
    "    figs, axes = plt.subplots(nrows, ncols, figsize=figsize,frameon=False)\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        if i >= shape[0]:\n",
    "            break\n",
    "        im = ax.imshow(W[i], cmap='gray', interpolation='nearest')\n",
    "\n",
    "    return figs, axes\n",
    "\n",
    "layer = network['conv2']\n",
    "figs, axes = plot_conv_weights(layer)\n",
    "figs.tight_layout()\n",
    "plt.subplots_adjust(wspace=.001)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dense']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nnmodel.network\n",
    "keys = network.keys()\n",
    "filter_layers = []\n",
    "for key in keys:\n",
    "    if 'dense' in key:\n",
    "        if hasattr(network[key], 'W'):\n",
    "            filter_layers.append(key) \n",
    "filter_layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_weights(weights):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(weights.T, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "layer = network['dense']\n",
    "weights = layer.W.get_value()\n",
    "plt = plot_weights(weights)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano.tensor as T\n",
    "import theano\n",
    "from lasagne.layers import get_output\n",
    "\n",
    "def plot_conv_activity(activity, figsize=(6, 8)):\n",
    "    \"\"\"nolearn's plot the acitivities of a specific layer.\n",
    "        x : numpy.ndarray (1 data point) \"\"\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    shape = activity.shape\n",
    "    nrows = np.ceil(np.sqrt(shape[1])).astype(int)\n",
    "    ncols = nrows\n",
    "\n",
    "    figs, axes = plt.subplots(nrows + 1, ncols, figsize=figsize)\n",
    "    axes[0, ncols // 2].imshow(1 - x[0][0], cmap='gray', interpolation='nearest')\n",
    "    axes[0, ncols // 2].set_title('original')\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.axis('off')\n",
    "\n",
    "    for i, ax in enumerate(axes.ravel()):    \n",
    "        if i >= shape[1]:\n",
    "            break\n",
    "        ndim = activity[0][i].ndim\n",
    "        if ndim != 2:\n",
    "            raise ValueError(\"Wrong number of dimensions, image data should \"\n",
    "                             \"have 2, instead got {}\".format(ndim))\n",
    "        ax.imshow(-activity[0][i], cmap='gray', interpolation='nearest')\n",
    "    plt.show()\n",
    "    return plt\n",
    "\n",
    "layer = network['conv1']\n",
    "x = np.expand_dims(test[0][0].astype(np.float32), axis=0)\n",
    "\n",
    "# compile theano function\n",
    "input_var = T.tensor4('input').astype(theano.config.floatX)\n",
    "get_activity = theano.function([input_var], get_output(layer, input_var))\n",
    "\n",
    "# get activation info\n",
    "activity = get_activity(x)\n",
    "plot_conv_activity(activity)\n",
    "activity.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "activity = np.squeeze(activity)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.imshow(activity, cmap='gray')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "activity.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "layer = network['conv1']\n",
    "W =  np.squeeze(layer.W.get_value())\n",
    "weights = W[0]\n",
    "\n",
    "weights = weights/sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('test.table', W[0], delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'input_layer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-0d07e75e3492>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlasagne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minput_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mactivity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/peter/Lasagne/lasagne/layers/helper.pyc\u001b[0m in \u001b[0;36mget_output\u001b[1;34m(layer_or_layers, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m                                     for input_layer in layer.input_layers]\n\u001b[0;32m    182\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                     \u001b[0mlayer_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                 \u001b[1;31m# one of the input_layer attributes must have been `None`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'input_layer'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def occlusion_heatmap(net, x, target, square_length=7):\n",
    "    \"\"\"An occlusion test that checks an image for its critical parts.\n",
    "    In this function, a square part of the image is occluded (i.e. set\n",
    "    to 0) and then the net is tested for its propensity to predict the\n",
    "    correct label. One should expect that this propensity shrinks of\n",
    "    critical parts of the image are occluded. If not, this indicates\n",
    "    overfitting.\n",
    "    Depending on the depth of the net and the size of the image, this\n",
    "    function may take awhile to finish, since one prediction for each\n",
    "    pixel of the image is made.\n",
    "    Currently, all color channels are occluded at the same time. Also,\n",
    "    this does not really work if images are randomly distorted by the\n",
    "    batch iterator.\n",
    "    See paper: Zeiler, Fergus 2013\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : NeuralNet instance\n",
    "      The neural net to test.\n",
    "    x : np.array\n",
    "      The input data, should be of shape (1, c, x, y). Only makes\n",
    "      sense with image data.\n",
    "    target : int\n",
    "      The true value of the image. If the net makes several\n",
    "      predictions, say 10 classes, this indicates which one to look\n",
    "      at.\n",
    "    square_length : int (default=7)\n",
    "      The length of the side of the square that occludes the image.\n",
    "      Must be an odd number.\n",
    "    Results\n",
    "    -------\n",
    "    heat_array : np.array (with same size as image)\n",
    "      An 2D np.array that at each point (i, j) contains the predicted\n",
    "      probability of the correct class if the image is occluded by a\n",
    "      square with center (i, j).\n",
    "    \"\"\"\n",
    "    if (x.ndim != 4) or x.shape[0] != 1:\n",
    "        raise ValueError(\"This function requires the input data to be of \"\n",
    "                         \"shape (1, c, x, y), instead got {}\".format(x.shape))\n",
    "    if square_length % 2 == 0:\n",
    "        raise ValueError(\"Square length has to be an odd number, instead \"\n",
    "                         \"got {}.\".format(square_length))\n",
    "\n",
    "    num_classes = get_output_shape(net.layers_[-1])[1]\n",
    "    img = x[0].copy()\n",
    "    bs, col, s0, s1 = x.shape\n",
    "\n",
    "    heat_array = np.zeros((s0, s1))\n",
    "    pad = square_length // 2 + 1\n",
    "    x_occluded = np.zeros((s1, col, s0, s1), dtype=img.dtype)\n",
    "    probs = np.zeros((s0, s1, num_classes))\n",
    "\n",
    "    # generate occluded images\n",
    "    for i in range(s0):\n",
    "        # batch s1 occluded images for faster prediction\n",
    "        for j in range(s1):\n",
    "            x_pad = np.pad(img, ((0, 0), (pad, pad), (pad, pad)), 'constant')\n",
    "            x_pad[:, i:i + square_length, j:j + square_length] = 0.\n",
    "            x_occluded[j] = x_pad[:, pad:-pad, pad:-pad]\n",
    "        y_proba = net.predict_proba(x_occluded)\n",
    "        probs[i] = y_proba.reshape(s1, num_classes)\n",
    "\n",
    "    # from predicted probabilities, pick only those of target class\n",
    "    for i in range(s0):\n",
    "        for j in range(s1):\n",
    "            heat_array[i, j] = probs[i, j, target]\n",
    "    return heat_array\n",
    "\n",
    "\n",
    "\n",
    "def plot_occlusion(net, X, target, square_length=7, figsize=(9, None)):\n",
    "    \"\"\"Plot which parts of an image are particularly import for the\n",
    "    net to classify the image correctly.\n",
    "    See paper: Zeiler, Fergus 2013\n",
    "    Parameters\n",
    "    ----------\n",
    "    net : NeuralNet instance\n",
    "      The neural net to test.\n",
    "    X : numpy.array\n",
    "      The input data, should be of shape (b, c, 0, 1). Only makes\n",
    "      sense with image data.\n",
    "    target : list or numpy.array of ints\n",
    "      The true values of the image. If the net makes several\n",
    "      predictions, say 10 classes, this indicates which one to look\n",
    "      at. If more than one sample is passed to X, each of them needs\n",
    "      its own target.\n",
    "    square_length : int (default=7)\n",
    "      The length of the side of the square that occludes the image.\n",
    "      Must be an odd number.\n",
    "    figsize : tuple (int, int)\n",
    "      Size of the figure.\n",
    "    Plots\n",
    "    -----\n",
    "    Figure with 3 subplots: the original image, the occlusion heatmap,\n",
    "    and both images super-imposed.\n",
    "    \"\"\"\n",
    "    return _plot_heat_map(net, X, figsize, lambda net, X, n: occlusion_heatmap(net, X, target[n], square_length))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
